{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "precision_metric = Precision()\n",
    "recall_metric = Recall()\n",
    "\n",
    "# F1-score 계산 함수\n",
    "def f1_score(y_true, y_pred):\n",
    "    precision = precision_metric(y_true, y_pred)\n",
    "    recall = recall_metric(y_true, y_pred)\n",
    "    \n",
    "    # F1-score 계산: 2 * (precision * recall) / (precision + recall)\n",
    "    return 2 * (precision * recall) / (precision + recall + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('spam(k).csv', encoding='utf-8')\n",
    "X_data = data['v2']\n",
    "y_data = data['v1']\n",
    "X_data = [sample if sample == sample else '0' for sample in X_data]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=0, stratify=y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 메일 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로그인 성공!\n",
      "1/970 번째 메일 처리 중...\n",
      "2/970 번째 메일 처리 중...\n",
      "3/970 번째 메일 처리 중...\n",
      "4/970 번째 메일 처리 중...\n",
      "5/970 번째 메일 처리 중...\n",
      "6/970 번째 메일 처리 중...\n",
      "7/970 번째 메일 처리 중...\n",
      "8/970 번째 메일 처리 중...\n",
      "9/970 번째 메일 처리 중...\n",
      "10/970 번째 메일 처리 중...\n",
      "11/970 번째 메일 처리 중...\n",
      "12/970 번째 메일 처리 중...\n",
      "13/970 번째 메일 처리 중...\n",
      "14/970 번째 메일 처리 중...\n",
      "15/970 번째 메일 처리 중...\n",
      "16/970 번째 메일 처리 중...\n",
      "17/970 번째 메일 처리 중...\n",
      "18/970 번째 메일 처리 중...\n",
      "19/970 번째 메일 처리 중...\n",
      "20/970 번째 메일 처리 중...\n",
      "21/970 번째 메일 처리 중...\n",
      "22/970 번째 메일 처리 중...\n",
      "23/970 번째 메일 처리 중...\n",
      "24/970 번째 메일 처리 중...\n",
      "25/970 번째 메일 처리 중...\n",
      "26/970 번째 메일 처리 중...\n",
      "27/970 번째 메일 처리 중...\n",
      "28/970 번째 메일 처리 중...\n",
      "29/970 번째 메일 처리 중...\n",
      "30/970 번째 메일 처리 중...\n",
      "31/970 번째 메일 처리 중...\n",
      "32/970 번째 메일 처리 중...\n",
      "33/970 번째 메일 처리 중...\n",
      "34/970 번째 메일 처리 중...\n",
      "35/970 번째 메일 처리 중...\n",
      "36/970 번째 메일 처리 중...\n",
      "37/970 번째 메일 처리 중...\n",
      "38/970 번째 메일 처리 중...\n",
      "39/970 번째 메일 처리 중...\n",
      "40/970 번째 메일 처리 중...\n",
      "41/970 번째 메일 처리 중...\n",
      "42/970 번째 메일 처리 중...\n",
      "43/970 번째 메일 처리 중...\n",
      "44/970 번째 메일 처리 중...\n",
      "45/970 번째 메일 처리 중...\n",
      "46/970 번째 메일 처리 중...\n",
      "47/970 번째 메일 처리 중...\n",
      "48/970 번째 메일 처리 중...\n",
      "49/970 번째 메일 처리 중...\n",
      "50/970 번째 메일 처리 중...\n",
      "51/970 번째 메일 처리 중...\n",
      "52/970 번째 메일 처리 중...\n",
      "53/970 번째 메일 처리 중...\n",
      "54/970 번째 메일 처리 중...\n",
      "55/970 번째 메일 처리 중...\n",
      "56/970 번째 메일 처리 중...\n",
      "57/970 번째 메일 처리 중...\n",
      "58/970 번째 메일 처리 중...\n",
      "59/970 번째 메일 처리 중...\n",
      "60/970 번째 메일 처리 중...\n",
      "61/970 번째 메일 처리 중...\n",
      "62/970 번째 메일 처리 중...\n",
      "63/970 번째 메일 처리 중...\n",
      "64/970 번째 메일 처리 중...\n",
      "65/970 번째 메일 처리 중...\n",
      "66/970 번째 메일 처리 중...\n",
      "67/970 번째 메일 처리 중...\n",
      "68/970 번째 메일 처리 중...\n",
      "69/970 번째 메일 처리 중...\n",
      "70/970 번째 메일 처리 중...\n",
      "71/970 번째 메일 처리 중...\n",
      "72/970 번째 메일 처리 중...\n",
      "73/970 번째 메일 처리 중...\n",
      "74/970 번째 메일 처리 중...\n",
      "75/970 번째 메일 처리 중...\n",
      "76/970 번째 메일 처리 중...\n",
      "77/970 번째 메일 처리 중...\n",
      "78/970 번째 메일 처리 중...\n",
      "79/970 번째 메일 처리 중...\n",
      "80/970 번째 메일 처리 중...\n",
      "81/970 번째 메일 처리 중...\n",
      "82/970 번째 메일 처리 중...\n",
      "83/970 번째 메일 처리 중...\n",
      "84/970 번째 메일 처리 중...\n",
      "85/970 번째 메일 처리 중...\n",
      "86/970 번째 메일 처리 중...\n",
      "87/970 번째 메일 처리 중...\n",
      "88/970 번째 메일 처리 중...\n",
      "89/970 번째 메일 처리 중...\n",
      "90/970 번째 메일 처리 중...\n",
      "91/970 번째 메일 처리 중...\n",
      "92/970 번째 메일 처리 중...\n",
      "93/970 번째 메일 처리 중...\n",
      "94/970 번째 메일 처리 중...\n",
      "95/970 번째 메일 처리 중...\n",
      "96/970 번째 메일 처리 중...\n",
      "97/970 번째 메일 처리 중...\n",
      "98/970 번째 메일 처리 중...\n",
      "99/970 번째 메일 처리 중...\n",
      "100/970 번째 메일 처리 중...\n",
      "101/970 번째 메일 처리 중...\n",
      "102/970 번째 메일 처리 중...\n",
      "103/970 번째 메일 처리 중...\n",
      "104/970 번째 메일 처리 중...\n",
      "105/970 번째 메일 처리 중...\n",
      "106/970 번째 메일 처리 중...\n",
      "107/970 번째 메일 처리 중...\n",
      "108/970 번째 메일 처리 중...\n",
      "109/970 번째 메일 처리 중...\n",
      "110/970 번째 메일 처리 중...\n",
      "111/970 번째 메일 처리 중...\n",
      "112/970 번째 메일 처리 중...\n",
      "113/970 번째 메일 처리 중...\n",
      "114/970 번째 메일 처리 중...\n",
      "115/970 번째 메일 처리 중...\n",
      "116/970 번째 메일 처리 중...\n",
      "117/970 번째 메일 처리 중...\n",
      "118/970 번째 메일 처리 중...\n",
      "119/970 번째 메일 처리 중...\n",
      "120/970 번째 메일 처리 중...\n",
      "121/970 번째 메일 처리 중...\n",
      "122/970 번째 메일 처리 중...\n",
      "123/970 번째 메일 처리 중...\n",
      "124/970 번째 메일 처리 중...\n",
      "125/970 번째 메일 처리 중...\n",
      "126/970 번째 메일 처리 중...\n",
      "127/970 번째 메일 처리 중...\n",
      "128/970 번째 메일 처리 중...\n",
      "129/970 번째 메일 처리 중...\n",
      "130/970 번째 메일 처리 중...\n",
      "131/970 번째 메일 처리 중...\n",
      "132/970 번째 메일 처리 중...\n",
      "133/970 번째 메일 처리 중...\n",
      "134/970 번째 메일 처리 중...\n",
      "135/970 번째 메일 처리 중...\n",
      "136/970 번째 메일 처리 중...\n",
      "137/970 번째 메일 처리 중...\n",
      "138/970 번째 메일 처리 중...\n",
      "139/970 번째 메일 처리 중...\n",
      "140/970 번째 메일 처리 중...\n",
      "141/970 번째 메일 처리 중...\n",
      "142/970 번째 메일 처리 중...\n",
      "143/970 번째 메일 처리 중...\n",
      "144/970 번째 메일 처리 중...\n",
      "145/970 번째 메일 처리 중...\n",
      "146/970 번째 메일 처리 중...\n",
      "147/970 번째 메일 처리 중...\n",
      "148/970 번째 메일 처리 중...\n",
      "149/970 번째 메일 처리 중...\n",
      "150/970 번째 메일 처리 중...\n",
      "151/970 번째 메일 처리 중...\n",
      "152/970 번째 메일 처리 중...\n",
      "153/970 번째 메일 처리 중...\n",
      "154/970 번째 메일 처리 중...\n",
      "155/970 번째 메일 처리 중...\n",
      "156/970 번째 메일 처리 중...\n",
      "157/970 번째 메일 처리 중...\n",
      "158/970 번째 메일 처리 중...\n",
      "159/970 번째 메일 처리 중...\n",
      "160/970 번째 메일 처리 중...\n",
      "161/970 번째 메일 처리 중...\n",
      "162/970 번째 메일 처리 중...\n",
      "163/970 번째 메일 처리 중...\n",
      "164/970 번째 메일 처리 중...\n",
      "165/970 번째 메일 처리 중...\n",
      "166/970 번째 메일 처리 중...\n",
      "167/970 번째 메일 처리 중...\n",
      "168/970 번째 메일 처리 중...\n",
      "169/970 번째 메일 처리 중...\n",
      "170/970 번째 메일 처리 중...\n",
      "171/970 번째 메일 처리 중...\n",
      "172/970 번째 메일 처리 중...\n",
      "173/970 번째 메일 처리 중...\n",
      "174/970 번째 메일 처리 중...\n",
      "175/970 번째 메일 처리 중...\n",
      "176/970 번째 메일 처리 중...\n",
      "177/970 번째 메일 처리 중...\n",
      "178/970 번째 메일 처리 중...\n",
      "179/970 번째 메일 처리 중...\n",
      "180/970 번째 메일 처리 중...\n",
      "181/970 번째 메일 처리 중...\n",
      "182/970 번째 메일 처리 중...\n",
      "183/970 번째 메일 처리 중...\n",
      "184/970 번째 메일 처리 중...\n",
      "185/970 번째 메일 처리 중...\n",
      "186/970 번째 메일 처리 중...\n",
      "187/970 번째 메일 처리 중...\n",
      "188/970 번째 메일 처리 중...\n",
      "189/970 번째 메일 처리 중...\n",
      "190/970 번째 메일 처리 중...\n",
      "191/970 번째 메일 처리 중...\n",
      "192/970 번째 메일 처리 중...\n",
      "193/970 번째 메일 처리 중...\n",
      "194/970 번째 메일 처리 중...\n",
      "195/970 번째 메일 처리 중...\n",
      "196/970 번째 메일 처리 중...\n",
      "197/970 번째 메일 처리 중...\n",
      "198/970 번째 메일 처리 중...\n",
      "199/970 번째 메일 처리 중...\n",
      "200/970 번째 메일 처리 중...\n",
      "201/970 번째 메일 처리 중...\n",
      "202/970 번째 메일 처리 중...\n",
      "203/970 번째 메일 처리 중...\n",
      "204/970 번째 메일 처리 중...\n",
      "205/970 번째 메일 처리 중...\n",
      "206/970 번째 메일 처리 중...\n",
      "207/970 번째 메일 처리 중...\n",
      "208/970 번째 메일 처리 중...\n",
      "209/970 번째 메일 처리 중...\n",
      "210/970 번째 메일 처리 중...\n",
      "211/970 번째 메일 처리 중...\n",
      "212/970 번째 메일 처리 중...\n",
      "213/970 번째 메일 처리 중...\n",
      "214/970 번째 메일 처리 중...\n",
      "215/970 번째 메일 처리 중...\n",
      "216/970 번째 메일 처리 중...\n",
      "217/970 번째 메일 처리 중...\n",
      "218/970 번째 메일 처리 중...\n",
      "219/970 번째 메일 처리 중...\n",
      "220/970 번째 메일 처리 중...\n",
      "221/970 번째 메일 처리 중...\n",
      "222/970 번째 메일 처리 중...\n",
      "223/970 번째 메일 처리 중...\n",
      "224/970 번째 메일 처리 중...\n",
      "225/970 번째 메일 처리 중...\n",
      "226/970 번째 메일 처리 중...\n",
      "227/970 번째 메일 처리 중...\n",
      "228/970 번째 메일 처리 중...\n",
      "229/970 번째 메일 처리 중...\n",
      "230/970 번째 메일 처리 중...\n",
      "231/970 번째 메일 처리 중...\n",
      "232/970 번째 메일 처리 중...\n",
      "233/970 번째 메일 처리 중...\n",
      "234/970 번째 메일 처리 중...\n",
      "235/970 번째 메일 처리 중...\n",
      "236/970 번째 메일 처리 중...\n",
      "237/970 번째 메일 처리 중...\n",
      "238/970 번째 메일 처리 중...\n",
      "239/970 번째 메일 처리 중...\n",
      "240/970 번째 메일 처리 중...\n",
      "241/970 번째 메일 처리 중...\n",
      "242/970 번째 메일 처리 중...\n",
      "243/970 번째 메일 처리 중...\n",
      "244/970 번째 메일 처리 중...\n",
      "245/970 번째 메일 처리 중...\n",
      "246/970 번째 메일 처리 중...\n",
      "247/970 번째 메일 처리 중...\n",
      "248/970 번째 메일 처리 중...\n",
      "249/970 번째 메일 처리 중...\n",
      "250/970 번째 메일 처리 중...\n",
      "251/970 번째 메일 처리 중...\n",
      "252/970 번째 메일 처리 중...\n",
      "253/970 번째 메일 처리 중...\n",
      "254/970 번째 메일 처리 중...\n",
      "255/970 번째 메일 처리 중...\n",
      "256/970 번째 메일 처리 중...\n",
      "257/970 번째 메일 처리 중...\n",
      "258/970 번째 메일 처리 중...\n",
      "259/970 번째 메일 처리 중...\n",
      "260/970 번째 메일 처리 중...\n",
      "261/970 번째 메일 처리 중...\n",
      "262/970 번째 메일 처리 중...\n",
      "263/970 번째 메일 처리 중...\n",
      "264/970 번째 메일 처리 중...\n",
      "265/970 번째 메일 처리 중...\n",
      "266/970 번째 메일 처리 중...\n",
      "267/970 번째 메일 처리 중...\n",
      "268/970 번째 메일 처리 중...\n",
      "269/970 번째 메일 처리 중...\n",
      "270/970 번째 메일 처리 중...\n",
      "271/970 번째 메일 처리 중...\n",
      "272/970 번째 메일 처리 중...\n",
      "273/970 번째 메일 처리 중...\n",
      "274/970 번째 메일 처리 중...\n",
      "275/970 번째 메일 처리 중...\n",
      "276/970 번째 메일 처리 중...\n",
      "277/970 번째 메일 처리 중...\n",
      "278/970 번째 메일 처리 중...\n",
      "279/970 번째 메일 처리 중...\n",
      "280/970 번째 메일 처리 중...\n",
      "281/970 번째 메일 처리 중...\n",
      "282/970 번째 메일 처리 중...\n",
      "283/970 번째 메일 처리 중...\n",
      "284/970 번째 메일 처리 중...\n",
      "285/970 번째 메일 처리 중...\n",
      "286/970 번째 메일 처리 중...\n",
      "287/970 번째 메일 처리 중...\n",
      "288/970 번째 메일 처리 중...\n",
      "289/970 번째 메일 처리 중...\n",
      "290/970 번째 메일 처리 중...\n",
      "291/970 번째 메일 처리 중...\n",
      "292/970 번째 메일 처리 중...\n",
      "293/970 번째 메일 처리 중...\n",
      "294/970 번째 메일 처리 중...\n",
      "295/970 번째 메일 처리 중...\n",
      "296/970 번째 메일 처리 중...\n",
      "297/970 번째 메일 처리 중...\n",
      "298/970 번째 메일 처리 중...\n",
      "299/970 번째 메일 처리 중...\n",
      "300/970 번째 메일 처리 중...\n",
      "301/970 번째 메일 처리 중...\n",
      "302/970 번째 메일 처리 중...\n",
      "303/970 번째 메일 처리 중...\n",
      "304/970 번째 메일 처리 중...\n",
      "305/970 번째 메일 처리 중...\n",
      "306/970 번째 메일 처리 중...\n",
      "307/970 번째 메일 처리 중...\n",
      "308/970 번째 메일 처리 중...\n",
      "309/970 번째 메일 처리 중...\n",
      "310/970 번째 메일 처리 중...\n",
      "311/970 번째 메일 처리 중...\n",
      "312/970 번째 메일 처리 중...\n",
      "313/970 번째 메일 처리 중...\n",
      "314/970 번째 메일 처리 중...\n",
      "315/970 번째 메일 처리 중...\n",
      "316/970 번째 메일 처리 중...\n",
      "317/970 번째 메일 처리 중...\n",
      "318/970 번째 메일 처리 중...\n",
      "319/970 번째 메일 처리 중...\n",
      "320/970 번째 메일 처리 중...\n",
      "321/970 번째 메일 처리 중...\n",
      "322/970 번째 메일 처리 중...\n",
      "323/970 번째 메일 처리 중...\n",
      "324/970 번째 메일 처리 중...\n",
      "325/970 번째 메일 처리 중...\n",
      "326/970 번째 메일 처리 중...\n",
      "327/970 번째 메일 처리 중...\n",
      "328/970 번째 메일 처리 중...\n",
      "329/970 번째 메일 처리 중...\n",
      "330/970 번째 메일 처리 중...\n",
      "331/970 번째 메일 처리 중...\n",
      "332/970 번째 메일 처리 중...\n",
      "333/970 번째 메일 처리 중...\n",
      "334/970 번째 메일 처리 중...\n",
      "335/970 번째 메일 처리 중...\n",
      "336/970 번째 메일 처리 중...\n",
      "337/970 번째 메일 처리 중...\n",
      "338/970 번째 메일 처리 중...\n",
      "339/970 번째 메일 처리 중...\n",
      "340/970 번째 메일 처리 중...\n",
      "341/970 번째 메일 처리 중...\n",
      "342/970 번째 메일 처리 중...\n",
      "343/970 번째 메일 처리 중...\n",
      "344/970 번째 메일 처리 중...\n",
      "345/970 번째 메일 처리 중...\n",
      "346/970 번째 메일 처리 중...\n",
      "347/970 번째 메일 처리 중...\n",
      "348/970 번째 메일 처리 중...\n",
      "349/970 번째 메일 처리 중...\n",
      "350/970 번째 메일 처리 중...\n",
      "351/970 번째 메일 처리 중...\n",
      "352/970 번째 메일 처리 중...\n",
      "353/970 번째 메일 처리 중...\n",
      "354/970 번째 메일 처리 중...\n",
      "355/970 번째 메일 처리 중...\n",
      "356/970 번째 메일 처리 중...\n",
      "357/970 번째 메일 처리 중...\n",
      "358/970 번째 메일 처리 중...\n",
      "359/970 번째 메일 처리 중...\n",
      "360/970 번째 메일 처리 중...\n",
      "361/970 번째 메일 처리 중...\n",
      "362/970 번째 메일 처리 중...\n",
      "363/970 번째 메일 처리 중...\n",
      "364/970 번째 메일 처리 중...\n",
      "365/970 번째 메일 처리 중...\n",
      "366/970 번째 메일 처리 중...\n",
      "367/970 번째 메일 처리 중...\n",
      "368/970 번째 메일 처리 중...\n",
      "369/970 번째 메일 처리 중...\n",
      "370/970 번째 메일 처리 중...\n",
      "371/970 번째 메일 처리 중...\n",
      "372/970 번째 메일 처리 중...\n",
      "373/970 번째 메일 처리 중...\n",
      "374/970 번째 메일 처리 중...\n",
      "375/970 번째 메일 처리 중...\n",
      "376/970 번째 메일 처리 중...\n",
      "377/970 번째 메일 처리 중...\n",
      "378/970 번째 메일 처리 중...\n",
      "379/970 번째 메일 처리 중...\n",
      "380/970 번째 메일 처리 중...\n",
      "381/970 번째 메일 처리 중...\n",
      "382/970 번째 메일 처리 중...\n",
      "383/970 번째 메일 처리 중...\n",
      "384/970 번째 메일 처리 중...\n",
      "385/970 번째 메일 처리 중...\n",
      "386/970 번째 메일 처리 중...\n",
      "387/970 번째 메일 처리 중...\n",
      "388/970 번째 메일 처리 중...\n",
      "389/970 번째 메일 처리 중...\n",
      "390/970 번째 메일 처리 중...\n",
      "391/970 번째 메일 처리 중...\n",
      "392/970 번째 메일 처리 중...\n",
      "393/970 번째 메일 처리 중...\n",
      "394/970 번째 메일 처리 중...\n",
      "395/970 번째 메일 처리 중...\n",
      "396/970 번째 메일 처리 중...\n",
      "397/970 번째 메일 처리 중...\n",
      "398/970 번째 메일 처리 중...\n",
      "399/970 번째 메일 처리 중...\n",
      "400/970 번째 메일 처리 중...\n",
      "401/970 번째 메일 처리 중...\n",
      "402/970 번째 메일 처리 중...\n",
      "403/970 번째 메일 처리 중...\n",
      "404/970 번째 메일 처리 중...\n",
      "405/970 번째 메일 처리 중...\n",
      "406/970 번째 메일 처리 중...\n",
      "407/970 번째 메일 처리 중...\n",
      "408/970 번째 메일 처리 중...\n",
      "409/970 번째 메일 처리 중...\n",
      "410/970 번째 메일 처리 중...\n",
      "411/970 번째 메일 처리 중...\n",
      "412/970 번째 메일 처리 중...\n",
      "413/970 번째 메일 처리 중...\n",
      "414/970 번째 메일 처리 중...\n",
      "415/970 번째 메일 처리 중...\n",
      "416/970 번째 메일 처리 중...\n",
      "417/970 번째 메일 처리 중...\n",
      "418/970 번째 메일 처리 중...\n",
      "419/970 번째 메일 처리 중...\n",
      "420/970 번째 메일 처리 중...\n",
      "421/970 번째 메일 처리 중...\n",
      "422/970 번째 메일 처리 중...\n",
      "423/970 번째 메일 처리 중...\n",
      "424/970 번째 메일 처리 중...\n",
      "425/970 번째 메일 처리 중...\n",
      "426/970 번째 메일 처리 중...\n",
      "427/970 번째 메일 처리 중...\n",
      "428/970 번째 메일 처리 중...\n",
      "429/970 번째 메일 처리 중...\n",
      "430/970 번째 메일 처리 중...\n",
      "431/970 번째 메일 처리 중...\n",
      "432/970 번째 메일 처리 중...\n",
      "433/970 번째 메일 처리 중...\n",
      "434/970 번째 메일 처리 중...\n",
      "435/970 번째 메일 처리 중...\n",
      "436/970 번째 메일 처리 중...\n",
      "437/970 번째 메일 처리 중...\n",
      "438/970 번째 메일 처리 중...\n",
      "439/970 번째 메일 처리 중...\n",
      "440/970 번째 메일 처리 중...\n",
      "441/970 번째 메일 처리 중...\n",
      "442/970 번째 메일 처리 중...\n",
      "443/970 번째 메일 처리 중...\n",
      "444/970 번째 메일 처리 중...\n",
      "445/970 번째 메일 처리 중...\n",
      "446/970 번째 메일 처리 중...\n",
      "447/970 번째 메일 처리 중...\n",
      "448/970 번째 메일 처리 중...\n",
      "449/970 번째 메일 처리 중...\n",
      "450/970 번째 메일 처리 중...\n",
      "451/970 번째 메일 처리 중...\n",
      "452/970 번째 메일 처리 중...\n",
      "453/970 번째 메일 처리 중...\n",
      "454/970 번째 메일 처리 중...\n",
      "455/970 번째 메일 처리 중...\n",
      "456/970 번째 메일 처리 중...\n",
      "457/970 번째 메일 처리 중...\n",
      "458/970 번째 메일 처리 중...\n",
      "459/970 번째 메일 처리 중...\n",
      "460/970 번째 메일 처리 중...\n",
      "461/970 번째 메일 처리 중...\n",
      "462/970 번째 메일 처리 중...\n",
      "463/970 번째 메일 처리 중...\n",
      "464/970 번째 메일 처리 중...\n",
      "465/970 번째 메일 처리 중...\n",
      "466/970 번째 메일 처리 중...\n",
      "467/970 번째 메일 처리 중...\n",
      "468/970 번째 메일 처리 중...\n",
      "469/970 번째 메일 처리 중...\n",
      "470/970 번째 메일 처리 중...\n",
      "471/970 번째 메일 처리 중...\n",
      "472/970 번째 메일 처리 중...\n",
      "473/970 번째 메일 처리 중...\n",
      "474/970 번째 메일 처리 중...\n",
      "475/970 번째 메일 처리 중...\n",
      "476/970 번째 메일 처리 중...\n",
      "477/970 번째 메일 처리 중...\n",
      "478/970 번째 메일 처리 중...\n",
      "479/970 번째 메일 처리 중...\n",
      "480/970 번째 메일 처리 중...\n",
      "481/970 번째 메일 처리 중...\n",
      "482/970 번째 메일 처리 중...\n",
      "483/970 번째 메일 처리 중...\n",
      "484/970 번째 메일 처리 중...\n",
      "485/970 번째 메일 처리 중...\n",
      "486/970 번째 메일 처리 중...\n",
      "487/970 번째 메일 처리 중...\n",
      "488/970 번째 메일 처리 중...\n",
      "489/970 번째 메일 처리 중...\n",
      "490/970 번째 메일 처리 중...\n",
      "491/970 번째 메일 처리 중...\n",
      "492/970 번째 메일 처리 중...\n",
      "493/970 번째 메일 처리 중...\n",
      "494/970 번째 메일 처리 중...\n",
      "495/970 번째 메일 처리 중...\n",
      "496/970 번째 메일 처리 중...\n",
      "497/970 번째 메일 처리 중...\n",
      "498/970 번째 메일 처리 중...\n",
      "499/970 번째 메일 처리 중...\n",
      "500/970 번째 메일 처리 중...\n",
      "501/970 번째 메일 처리 중...\n",
      "502/970 번째 메일 처리 중...\n",
      "503/970 번째 메일 처리 중...\n",
      "504/970 번째 메일 처리 중...\n",
      "505/970 번째 메일 처리 중...\n",
      "506/970 번째 메일 처리 중...\n",
      "507/970 번째 메일 처리 중...\n",
      "508/970 번째 메일 처리 중...\n",
      "509/970 번째 메일 처리 중...\n",
      "510/970 번째 메일 처리 중...\n",
      "511/970 번째 메일 처리 중...\n",
      "512/970 번째 메일 처리 중...\n",
      "513/970 번째 메일 처리 중...\n",
      "514/970 번째 메일 처리 중...\n",
      "515/970 번째 메일 처리 중...\n",
      "516/970 번째 메일 처리 중...\n",
      "517/970 번째 메일 처리 중...\n",
      "518/970 번째 메일 처리 중...\n",
      "519/970 번째 메일 처리 중...\n",
      "520/970 번째 메일 처리 중...\n",
      "521/970 번째 메일 처리 중...\n",
      "522/970 번째 메일 처리 중...\n",
      "523/970 번째 메일 처리 중...\n",
      "524/970 번째 메일 처리 중...\n",
      "525/970 번째 메일 처리 중...\n",
      "526/970 번째 메일 처리 중...\n",
      "527/970 번째 메일 처리 중...\n",
      "528/970 번째 메일 처리 중...\n",
      "529/970 번째 메일 처리 중...\n",
      "530/970 번째 메일 처리 중...\n",
      "531/970 번째 메일 처리 중...\n",
      "532/970 번째 메일 처리 중...\n",
      "533/970 번째 메일 처리 중...\n",
      "534/970 번째 메일 처리 중...\n",
      "535/970 번째 메일 처리 중...\n",
      "536/970 번째 메일 처리 중...\n",
      "537/970 번째 메일 처리 중...\n",
      "538/970 번째 메일 처리 중...\n",
      "539/970 번째 메일 처리 중...\n",
      "540/970 번째 메일 처리 중...\n",
      "541/970 번째 메일 처리 중...\n",
      "542/970 번째 메일 처리 중...\n",
      "543/970 번째 메일 처리 중...\n",
      "544/970 번째 메일 처리 중...\n",
      "545/970 번째 메일 처리 중...\n",
      "546/970 번째 메일 처리 중...\n",
      "547/970 번째 메일 처리 중...\n",
      "548/970 번째 메일 처리 중...\n",
      "549/970 번째 메일 처리 중...\n",
      "550/970 번째 메일 처리 중...\n",
      "551/970 번째 메일 처리 중...\n",
      "552/970 번째 메일 처리 중...\n",
      "553/970 번째 메일 처리 중...\n",
      "554/970 번째 메일 처리 중...\n",
      "555/970 번째 메일 처리 중...\n",
      "556/970 번째 메일 처리 중...\n",
      "557/970 번째 메일 처리 중...\n",
      "558/970 번째 메일 처리 중...\n",
      "559/970 번째 메일 처리 중...\n",
      "560/970 번째 메일 처리 중...\n",
      "561/970 번째 메일 처리 중...\n",
      "562/970 번째 메일 처리 중...\n",
      "563/970 번째 메일 처리 중...\n",
      "564/970 번째 메일 처리 중...\n",
      "565/970 번째 메일 처리 중...\n",
      "566/970 번째 메일 처리 중...\n",
      "567/970 번째 메일 처리 중...\n",
      "568/970 번째 메일 처리 중...\n",
      "569/970 번째 메일 처리 중...\n",
      "570/970 번째 메일 처리 중...\n",
      "571/970 번째 메일 처리 중...\n",
      "572/970 번째 메일 처리 중...\n",
      "573/970 번째 메일 처리 중...\n",
      "574/970 번째 메일 처리 중...\n",
      "575/970 번째 메일 처리 중...\n",
      "576/970 번째 메일 처리 중...\n",
      "577/970 번째 메일 처리 중...\n",
      "578/970 번째 메일 처리 중...\n",
      "579/970 번째 메일 처리 중...\n",
      "580/970 번째 메일 처리 중...\n",
      "581/970 번째 메일 처리 중...\n",
      "582/970 번째 메일 처리 중...\n",
      "583/970 번째 메일 처리 중...\n",
      "584/970 번째 메일 처리 중...\n",
      "585/970 번째 메일 처리 중...\n",
      "586/970 번째 메일 처리 중...\n",
      "587/970 번째 메일 처리 중...\n",
      "588/970 번째 메일 처리 중...\n",
      "589/970 번째 메일 처리 중...\n",
      "590/970 번째 메일 처리 중...\n",
      "591/970 번째 메일 처리 중...\n",
      "592/970 번째 메일 처리 중...\n",
      "593/970 번째 메일 처리 중...\n",
      "594/970 번째 메일 처리 중...\n",
      "595/970 번째 메일 처리 중...\n",
      "596/970 번째 메일 처리 중...\n",
      "597/970 번째 메일 처리 중...\n",
      "598/970 번째 메일 처리 중...\n",
      "599/970 번째 메일 처리 중...\n",
      "600/970 번째 메일 처리 중...\n",
      "601/970 번째 메일 처리 중...\n",
      "602/970 번째 메일 처리 중...\n",
      "603/970 번째 메일 처리 중...\n",
      "604/970 번째 메일 처리 중...\n",
      "605/970 번째 메일 처리 중...\n",
      "606/970 번째 메일 처리 중...\n",
      "607/970 번째 메일 처리 중...\n",
      "608/970 번째 메일 처리 중...\n",
      "609/970 번째 메일 처리 중...\n",
      "610/970 번째 메일 처리 중...\n",
      "611/970 번째 메일 처리 중...\n",
      "612/970 번째 메일 처리 중...\n",
      "613/970 번째 메일 처리 중...\n",
      "614/970 번째 메일 처리 중...\n",
      "615/970 번째 메일 처리 중...\n",
      "616/970 번째 메일 처리 중...\n",
      "617/970 번째 메일 처리 중...\n",
      "618/970 번째 메일 처리 중...\n",
      "619/970 번째 메일 처리 중...\n",
      "620/970 번째 메일 처리 중...\n",
      "621/970 번째 메일 처리 중...\n",
      "622/970 번째 메일 처리 중...\n",
      "623/970 번째 메일 처리 중...\n",
      "624/970 번째 메일 처리 중...\n",
      "625/970 번째 메일 처리 중...\n",
      "626/970 번째 메일 처리 중...\n",
      "627/970 번째 메일 처리 중...\n",
      "628/970 번째 메일 처리 중...\n",
      "629/970 번째 메일 처리 중...\n",
      "630/970 번째 메일 처리 중...\n",
      "631/970 번째 메일 처리 중...\n",
      "632/970 번째 메일 처리 중...\n",
      "633/970 번째 메일 처리 중...\n",
      "634/970 번째 메일 처리 중...\n",
      "635/970 번째 메일 처리 중...\n",
      "636/970 번째 메일 처리 중...\n",
      "637/970 번째 메일 처리 중...\n",
      "638/970 번째 메일 처리 중...\n",
      "639/970 번째 메일 처리 중...\n",
      "640/970 번째 메일 처리 중...\n",
      "641/970 번째 메일 처리 중...\n",
      "642/970 번째 메일 처리 중...\n",
      "643/970 번째 메일 처리 중...\n",
      "644/970 번째 메일 처리 중...\n",
      "645/970 번째 메일 처리 중...\n",
      "646/970 번째 메일 처리 중...\n",
      "647/970 번째 메일 처리 중...\n",
      "648/970 번째 메일 처리 중...\n",
      "649/970 번째 메일 처리 중...\n",
      "650/970 번째 메일 처리 중...\n",
      "651/970 번째 메일 처리 중...\n",
      "652/970 번째 메일 처리 중...\n",
      "653/970 번째 메일 처리 중...\n",
      "654/970 번째 메일 처리 중...\n",
      "655/970 번째 메일 처리 중...\n",
      "656/970 번째 메일 처리 중...\n",
      "657/970 번째 메일 처리 중...\n",
      "658/970 번째 메일 처리 중...\n",
      "659/970 번째 메일 처리 중...\n",
      "660/970 번째 메일 처리 중...\n",
      "661/970 번째 메일 처리 중...\n",
      "662/970 번째 메일 처리 중...\n",
      "663/970 번째 메일 처리 중...\n",
      "664/970 번째 메일 처리 중...\n",
      "665/970 번째 메일 처리 중...\n",
      "666/970 번째 메일 처리 중...\n",
      "667/970 번째 메일 처리 중...\n",
      "668/970 번째 메일 처리 중...\n",
      "669/970 번째 메일 처리 중...\n",
      "670/970 번째 메일 처리 중...\n",
      "671/970 번째 메일 처리 중...\n",
      "672/970 번째 메일 처리 중...\n",
      "673/970 번째 메일 처리 중...\n",
      "674/970 번째 메일 처리 중...\n",
      "675/970 번째 메일 처리 중...\n",
      "676/970 번째 메일 처리 중...\n",
      "677/970 번째 메일 처리 중...\n",
      "678/970 번째 메일 처리 중...\n",
      "679/970 번째 메일 처리 중...\n",
      "680/970 번째 메일 처리 중...\n",
      "681/970 번째 메일 처리 중...\n",
      "682/970 번째 메일 처리 중...\n",
      "683/970 번째 메일 처리 중...\n",
      "684/970 번째 메일 처리 중...\n",
      "685/970 번째 메일 처리 중...\n",
      "686/970 번째 메일 처리 중...\n",
      "687/970 번째 메일 처리 중...\n",
      "688/970 번째 메일 처리 중...\n",
      "689/970 번째 메일 처리 중...\n",
      "690/970 번째 메일 처리 중...\n",
      "691/970 번째 메일 처리 중...\n",
      "692/970 번째 메일 처리 중...\n",
      "693/970 번째 메일 처리 중...\n",
      "694/970 번째 메일 처리 중...\n",
      "695/970 번째 메일 처리 중...\n",
      "696/970 번째 메일 처리 중...\n",
      "697/970 번째 메일 처리 중...\n",
      "698/970 번째 메일 처리 중...\n",
      "699/970 번째 메일 처리 중...\n",
      "700/970 번째 메일 처리 중...\n",
      "701/970 번째 메일 처리 중...\n",
      "702/970 번째 메일 처리 중...\n",
      "703/970 번째 메일 처리 중...\n",
      "704/970 번째 메일 처리 중...\n",
      "705/970 번째 메일 처리 중...\n",
      "706/970 번째 메일 처리 중...\n",
      "707/970 번째 메일 처리 중...\n",
      "708/970 번째 메일 처리 중...\n",
      "709/970 번째 메일 처리 중...\n",
      "710/970 번째 메일 처리 중...\n",
      "711/970 번째 메일 처리 중...\n",
      "712/970 번째 메일 처리 중...\n",
      "713/970 번째 메일 처리 중...\n",
      "714/970 번째 메일 처리 중...\n",
      "715/970 번째 메일 처리 중...\n",
      "716/970 번째 메일 처리 중...\n",
      "717/970 번째 메일 처리 중...\n",
      "718/970 번째 메일 처리 중...\n",
      "719/970 번째 메일 처리 중...\n",
      "720/970 번째 메일 처리 중...\n",
      "721/970 번째 메일 처리 중...\n",
      "722/970 번째 메일 처리 중...\n",
      "723/970 번째 메일 처리 중...\n",
      "724/970 번째 메일 처리 중...\n",
      "725/970 번째 메일 처리 중...\n",
      "726/970 번째 메일 처리 중...\n",
      "727/970 번째 메일 처리 중...\n",
      "728/970 번째 메일 처리 중...\n",
      "729/970 번째 메일 처리 중...\n",
      "730/970 번째 메일 처리 중...\n",
      "731/970 번째 메일 처리 중...\n",
      "732/970 번째 메일 처리 중...\n",
      "733/970 번째 메일 처리 중...\n",
      "734/970 번째 메일 처리 중...\n",
      "735/970 번째 메일 처리 중...\n",
      "736/970 번째 메일 처리 중...\n",
      "737/970 번째 메일 처리 중...\n",
      "738/970 번째 메일 처리 중...\n",
      "739/970 번째 메일 처리 중...\n",
      "740/970 번째 메일 처리 중...\n",
      "741/970 번째 메일 처리 중...\n",
      "742/970 번째 메일 처리 중...\n",
      "743/970 번째 메일 처리 중...\n",
      "744/970 번째 메일 처리 중...\n",
      "745/970 번째 메일 처리 중...\n",
      "746/970 번째 메일 처리 중...\n",
      "747/970 번째 메일 처리 중...\n",
      "748/970 번째 메일 처리 중...\n",
      "749/970 번째 메일 처리 중...\n",
      "750/970 번째 메일 처리 중...\n",
      "751/970 번째 메일 처리 중...\n",
      "752/970 번째 메일 처리 중...\n",
      "753/970 번째 메일 처리 중...\n",
      "754/970 번째 메일 처리 중...\n",
      "755/970 번째 메일 처리 중...\n",
      "756/970 번째 메일 처리 중...\n",
      "757/970 번째 메일 처리 중...\n",
      "758/970 번째 메일 처리 중...\n",
      "759/970 번째 메일 처리 중...\n",
      "760/970 번째 메일 처리 중...\n",
      "761/970 번째 메일 처리 중...\n",
      "762/970 번째 메일 처리 중...\n",
      "763/970 번째 메일 처리 중...\n",
      "764/970 번째 메일 처리 중...\n",
      "765/970 번째 메일 처리 중...\n",
      "766/970 번째 메일 처리 중...\n",
      "767/970 번째 메일 처리 중...\n",
      "768/970 번째 메일 처리 중...\n",
      "769/970 번째 메일 처리 중...\n",
      "770/970 번째 메일 처리 중...\n",
      "771/970 번째 메일 처리 중...\n",
      "772/970 번째 메일 처리 중...\n",
      "773/970 번째 메일 처리 중...\n",
      "774/970 번째 메일 처리 중...\n",
      "775/970 번째 메일 처리 중...\n",
      "776/970 번째 메일 처리 중...\n",
      "777/970 번째 메일 처리 중...\n",
      "778/970 번째 메일 처리 중...\n",
      "779/970 번째 메일 처리 중...\n",
      "780/970 번째 메일 처리 중...\n",
      "781/970 번째 메일 처리 중...\n",
      "782/970 번째 메일 처리 중...\n",
      "783/970 번째 메일 처리 중...\n",
      "784/970 번째 메일 처리 중...\n",
      "785/970 번째 메일 처리 중...\n",
      "786/970 번째 메일 처리 중...\n",
      "787/970 번째 메일 처리 중...\n",
      "788/970 번째 메일 처리 중...\n",
      "789/970 번째 메일 처리 중...\n",
      "790/970 번째 메일 처리 중...\n",
      "791/970 번째 메일 처리 중...\n",
      "792/970 번째 메일 처리 중...\n",
      "793/970 번째 메일 처리 중...\n",
      "794/970 번째 메일 처리 중...\n",
      "795/970 번째 메일 처리 중...\n",
      "796/970 번째 메일 처리 중...\n",
      "797/970 번째 메일 처리 중...\n",
      "798/970 번째 메일 처리 중...\n",
      "799/970 번째 메일 처리 중...\n",
      "800/970 번째 메일 처리 중...\n",
      "801/970 번째 메일 처리 중...\n",
      "802/970 번째 메일 처리 중...\n",
      "803/970 번째 메일 처리 중...\n",
      "804/970 번째 메일 처리 중...\n",
      "805/970 번째 메일 처리 중...\n",
      "806/970 번째 메일 처리 중...\n",
      "807/970 번째 메일 처리 중...\n",
      "808/970 번째 메일 처리 중...\n",
      "809/970 번째 메일 처리 중...\n",
      "810/970 번째 메일 처리 중...\n",
      "811/970 번째 메일 처리 중...\n",
      "812/970 번째 메일 처리 중...\n",
      "813/970 번째 메일 처리 중...\n",
      "814/970 번째 메일 처리 중...\n",
      "815/970 번째 메일 처리 중...\n",
      "816/970 번째 메일 처리 중...\n",
      "817/970 번째 메일 처리 중...\n",
      "818/970 번째 메일 처리 중...\n",
      "819/970 번째 메일 처리 중...\n",
      "820/970 번째 메일 처리 중...\n",
      "821/970 번째 메일 처리 중...\n",
      "822/970 번째 메일 처리 중...\n",
      "823/970 번째 메일 처리 중...\n",
      "824/970 번째 메일 처리 중...\n",
      "825/970 번째 메일 처리 중...\n",
      "826/970 번째 메일 처리 중...\n",
      "827/970 번째 메일 처리 중...\n",
      "828/970 번째 메일 처리 중...\n",
      "829/970 번째 메일 처리 중...\n",
      "830/970 번째 메일 처리 중...\n",
      "831/970 번째 메일 처리 중...\n",
      "832/970 번째 메일 처리 중...\n",
      "833/970 번째 메일 처리 중...\n",
      "834/970 번째 메일 처리 중...\n",
      "835/970 번째 메일 처리 중...\n",
      "836/970 번째 메일 처리 중...\n",
      "837/970 번째 메일 처리 중...\n",
      "838/970 번째 메일 처리 중...\n",
      "839/970 번째 메일 처리 중...\n",
      "840/970 번째 메일 처리 중...\n",
      "841/970 번째 메일 처리 중...\n",
      "842/970 번째 메일 처리 중...\n",
      "843/970 번째 메일 처리 중...\n",
      "844/970 번째 메일 처리 중...\n",
      "845/970 번째 메일 처리 중...\n",
      "846/970 번째 메일 처리 중...\n",
      "847/970 번째 메일 처리 중...\n",
      "848/970 번째 메일 처리 중...\n",
      "849/970 번째 메일 처리 중...\n",
      "850/970 번째 메일 처리 중...\n",
      "851/970 번째 메일 처리 중...\n",
      "852/970 번째 메일 처리 중...\n",
      "853/970 번째 메일 처리 중...\n",
      "854/970 번째 메일 처리 중...\n",
      "855/970 번째 메일 처리 중...\n",
      "856/970 번째 메일 처리 중...\n",
      "857/970 번째 메일 처리 중...\n",
      "858/970 번째 메일 처리 중...\n",
      "859/970 번째 메일 처리 중...\n",
      "860/970 번째 메일 처리 중...\n",
      "861/970 번째 메일 처리 중...\n",
      "862/970 번째 메일 처리 중...\n",
      "863/970 번째 메일 처리 중...\n",
      "864/970 번째 메일 처리 중...\n",
      "865/970 번째 메일 처리 중...\n",
      "866/970 번째 메일 처리 중...\n",
      "867/970 번째 메일 처리 중...\n",
      "868/970 번째 메일 처리 중...\n",
      "869/970 번째 메일 처리 중...\n",
      "870/970 번째 메일 처리 중...\n",
      "871/970 번째 메일 처리 중...\n",
      "872/970 번째 메일 처리 중...\n",
      "873/970 번째 메일 처리 중...\n",
      "874/970 번째 메일 처리 중...\n",
      "875/970 번째 메일 처리 중...\n",
      "876/970 번째 메일 처리 중...\n",
      "877/970 번째 메일 처리 중...\n",
      "878/970 번째 메일 처리 중...\n",
      "879/970 번째 메일 처리 중...\n",
      "880/970 번째 메일 처리 중...\n",
      "881/970 번째 메일 처리 중...\n",
      "882/970 번째 메일 처리 중...\n",
      "883/970 번째 메일 처리 중...\n",
      "884/970 번째 메일 처리 중...\n",
      "885/970 번째 메일 처리 중...\n",
      "886/970 번째 메일 처리 중...\n",
      "887/970 번째 메일 처리 중...\n",
      "888/970 번째 메일 처리 중...\n",
      "889/970 번째 메일 처리 중...\n",
      "890/970 번째 메일 처리 중...\n",
      "891/970 번째 메일 처리 중...\n",
      "892/970 번째 메일 처리 중...\n",
      "893/970 번째 메일 처리 중...\n",
      "894/970 번째 메일 처리 중...\n",
      "895/970 번째 메일 처리 중...\n",
      "896/970 번째 메일 처리 중...\n",
      "897/970 번째 메일 처리 중...\n",
      "898/970 번째 메일 처리 중...\n",
      "899/970 번째 메일 처리 중...\n",
      "900/970 번째 메일 처리 중...\n",
      "901/970 번째 메일 처리 중...\n",
      "902/970 번째 메일 처리 중...\n",
      "903/970 번째 메일 처리 중...\n",
      "904/970 번째 메일 처리 중...\n",
      "905/970 번째 메일 처리 중...\n",
      "906/970 번째 메일 처리 중...\n",
      "907/970 번째 메일 처리 중...\n",
      "908/970 번째 메일 처리 중...\n",
      "909/970 번째 메일 처리 중...\n",
      "910/970 번째 메일 처리 중...\n",
      "911/970 번째 메일 처리 중...\n",
      "912/970 번째 메일 처리 중...\n",
      "913/970 번째 메일 처리 중...\n",
      "914/970 번째 메일 처리 중...\n",
      "915/970 번째 메일 처리 중...\n",
      "916/970 번째 메일 처리 중...\n",
      "917/970 번째 메일 처리 중...\n",
      "918/970 번째 메일 처리 중...\n",
      "919/970 번째 메일 처리 중...\n",
      "920/970 번째 메일 처리 중...\n",
      "921/970 번째 메일 처리 중...\n",
      "922/970 번째 메일 처리 중...\n",
      "923/970 번째 메일 처리 중...\n",
      "924/970 번째 메일 처리 중...\n",
      "925/970 번째 메일 처리 중...\n",
      "926/970 번째 메일 처리 중...\n",
      "927/970 번째 메일 처리 중...\n",
      "928/970 번째 메일 처리 중...\n",
      "929/970 번째 메일 처리 중...\n",
      "930/970 번째 메일 처리 중...\n",
      "931/970 번째 메일 처리 중...\n",
      "932/970 번째 메일 처리 중...\n",
      "933/970 번째 메일 처리 중...\n",
      "934/970 번째 메일 처리 중...\n",
      "935/970 번째 메일 처리 중...\n",
      "936/970 번째 메일 처리 중...\n",
      "937/970 번째 메일 처리 중...\n",
      "938/970 번째 메일 처리 중...\n",
      "939/970 번째 메일 처리 중...\n",
      "940/970 번째 메일 처리 중...\n",
      "941/970 번째 메일 처리 중...\n",
      "942/970 번째 메일 처리 중...\n",
      "943/970 번째 메일 처리 중...\n",
      "944/970 번째 메일 처리 중...\n",
      "945/970 번째 메일 처리 중...\n",
      "946/970 번째 메일 처리 중...\n",
      "947/970 번째 메일 처리 중...\n",
      "948/970 번째 메일 처리 중...\n",
      "949/970 번째 메일 처리 중...\n",
      "950/970 번째 메일 처리 중...\n",
      "951/970 번째 메일 처리 중...\n",
      "952/970 번째 메일 처리 중...\n",
      "953/970 번째 메일 처리 중...\n",
      "954/970 번째 메일 처리 중...\n",
      "955/970 번째 메일 처리 중...\n",
      "956/970 번째 메일 처리 중...\n",
      "957/970 번째 메일 처리 중...\n",
      "958/970 번째 메일 처리 중...\n",
      "959/970 번째 메일 처리 중...\n",
      "960/970 번째 메일 처리 중...\n",
      "961/970 번째 메일 처리 중...\n",
      "962/970 번째 메일 처리 중...\n",
      "963/970 번째 메일 처리 중...\n",
      "964/970 번째 메일 처리 중...\n",
      "965/970 번째 메일 처리 중...\n",
      "966/970 번째 메일 처리 중...\n",
      "967/970 번째 메일 처리 중...\n",
      "968/970 번째 메일 처리 중...\n",
      "969/970 번째 메일 처리 중...\n",
      "970/970 번째 메일 처리 중...\n",
      "로그인 성공!\n",
      "1/860 번째 메일 처리 중...\n",
      "2/860 번째 메일 처리 중...\n",
      "3/860 번째 메일 처리 중...\n",
      "4/860 번째 메일 처리 중...\n",
      "5/860 번째 메일 처리 중...\n",
      "6/860 번째 메일 처리 중...\n",
      "7/860 번째 메일 처리 중...\n",
      "8/860 번째 메일 처리 중...\n",
      "9/860 번째 메일 처리 중...\n",
      "10/860 번째 메일 처리 중...\n",
      "11/860 번째 메일 처리 중...\n",
      "12/860 번째 메일 처리 중...\n",
      "13/860 번째 메일 처리 중...\n",
      "14/860 번째 메일 처리 중...\n",
      "15/860 번째 메일 처리 중...\n",
      "16/860 번째 메일 처리 중...\n",
      "17/860 번째 메일 처리 중...\n",
      "18/860 번째 메일 처리 중...\n",
      "19/860 번째 메일 처리 중...\n",
      "20/860 번째 메일 처리 중...\n",
      "21/860 번째 메일 처리 중...\n",
      "22/860 번째 메일 처리 중...\n",
      "23/860 번째 메일 처리 중...\n",
      "24/860 번째 메일 처리 중...\n",
      "25/860 번째 메일 처리 중...\n",
      "26/860 번째 메일 처리 중...\n",
      "27/860 번째 메일 처리 중...\n",
      "28/860 번째 메일 처리 중...\n",
      "29/860 번째 메일 처리 중...\n",
      "30/860 번째 메일 처리 중...\n",
      "31/860 번째 메일 처리 중...\n",
      "32/860 번째 메일 처리 중...\n",
      "33/860 번째 메일 처리 중...\n",
      "34/860 번째 메일 처리 중...\n",
      "35/860 번째 메일 처리 중...\n",
      "36/860 번째 메일 처리 중...\n",
      "37/860 번째 메일 처리 중...\n",
      "38/860 번째 메일 처리 중...\n",
      "39/860 번째 메일 처리 중...\n",
      "40/860 번째 메일 처리 중...\n",
      "41/860 번째 메일 처리 중...\n",
      "42/860 번째 메일 처리 중...\n",
      "43/860 번째 메일 처리 중...\n",
      "44/860 번째 메일 처리 중...\n",
      "45/860 번째 메일 처리 중...\n",
      "46/860 번째 메일 처리 중...\n",
      "47/860 번째 메일 처리 중...\n",
      "48/860 번째 메일 처리 중...\n",
      "49/860 번째 메일 처리 중...\n",
      "50/860 번째 메일 처리 중...\n",
      "51/860 번째 메일 처리 중...\n",
      "52/860 번째 메일 처리 중...\n",
      "53/860 번째 메일 처리 중...\n",
      "54/860 번째 메일 처리 중...\n",
      "55/860 번째 메일 처리 중...\n",
      "56/860 번째 메일 처리 중...\n",
      "57/860 번째 메일 처리 중...\n",
      "58/860 번째 메일 처리 중...\n",
      "59/860 번째 메일 처리 중...\n",
      "60/860 번째 메일 처리 중...\n",
      "61/860 번째 메일 처리 중...\n",
      "62/860 번째 메일 처리 중...\n",
      "63/860 번째 메일 처리 중...\n",
      "64/860 번째 메일 처리 중...\n",
      "65/860 번째 메일 처리 중...\n",
      "66/860 번째 메일 처리 중...\n",
      "67/860 번째 메일 처리 중...\n",
      "68/860 번째 메일 처리 중...\n",
      "69/860 번째 메일 처리 중...\n",
      "70/860 번째 메일 처리 중...\n",
      "71/860 번째 메일 처리 중...\n",
      "72/860 번째 메일 처리 중...\n",
      "73/860 번째 메일 처리 중...\n",
      "74/860 번째 메일 처리 중...\n",
      "75/860 번째 메일 처리 중...\n",
      "76/860 번째 메일 처리 중...\n",
      "77/860 번째 메일 처리 중...\n",
      "78/860 번째 메일 처리 중...\n",
      "79/860 번째 메일 처리 중...\n",
      "80/860 번째 메일 처리 중...\n",
      "81/860 번째 메일 처리 중...\n",
      "82/860 번째 메일 처리 중...\n",
      "83/860 번째 메일 처리 중...\n",
      "84/860 번째 메일 처리 중...\n",
      "85/860 번째 메일 처리 중...\n",
      "86/860 번째 메일 처리 중...\n",
      "87/860 번째 메일 처리 중...\n",
      "88/860 번째 메일 처리 중...\n",
      "89/860 번째 메일 처리 중...\n",
      "90/860 번째 메일 처리 중...\n",
      "91/860 번째 메일 처리 중...\n",
      "92/860 번째 메일 처리 중...\n",
      "93/860 번째 메일 처리 중...\n",
      "94/860 번째 메일 처리 중...\n",
      "95/860 번째 메일 처리 중...\n",
      "96/860 번째 메일 처리 중...\n",
      "97/860 번째 메일 처리 중...\n",
      "98/860 번째 메일 처리 중...\n",
      "99/860 번째 메일 처리 중...\n",
      "100/860 번째 메일 처리 중...\n",
      "101/860 번째 메일 처리 중...\n",
      "102/860 번째 메일 처리 중...\n",
      "103/860 번째 메일 처리 중...\n",
      "104/860 번째 메일 처리 중...\n",
      "105/860 번째 메일 처리 중...\n",
      "106/860 번째 메일 처리 중...\n",
      "107/860 번째 메일 처리 중...\n",
      "108/860 번째 메일 처리 중...\n",
      "109/860 번째 메일 처리 중...\n",
      "110/860 번째 메일 처리 중...\n",
      "111/860 번째 메일 처리 중...\n",
      "112/860 번째 메일 처리 중...\n",
      "113/860 번째 메일 처리 중...\n",
      "114/860 번째 메일 처리 중...\n",
      "115/860 번째 메일 처리 중...\n",
      "116/860 번째 메일 처리 중...\n",
      "117/860 번째 메일 처리 중...\n",
      "118/860 번째 메일 처리 중...\n",
      "119/860 번째 메일 처리 중...\n",
      "120/860 번째 메일 처리 중...\n",
      "121/860 번째 메일 처리 중...\n",
      "122/860 번째 메일 처리 중...\n",
      "123/860 번째 메일 처리 중...\n",
      "124/860 번째 메일 처리 중...\n",
      "125/860 번째 메일 처리 중...\n",
      "126/860 번째 메일 처리 중...\n",
      "127/860 번째 메일 처리 중...\n",
      "128/860 번째 메일 처리 중...\n",
      "129/860 번째 메일 처리 중...\n",
      "130/860 번째 메일 처리 중...\n",
      "131/860 번째 메일 처리 중...\n",
      "132/860 번째 메일 처리 중...\n",
      "133/860 번째 메일 처리 중...\n",
      "134/860 번째 메일 처리 중...\n",
      "135/860 번째 메일 처리 중...\n",
      "136/860 번째 메일 처리 중...\n",
      "137/860 번째 메일 처리 중...\n",
      "138/860 번째 메일 처리 중...\n",
      "139/860 번째 메일 처리 중...\n",
      "140/860 번째 메일 처리 중...\n",
      "141/860 번째 메일 처리 중...\n",
      "142/860 번째 메일 처리 중...\n",
      "143/860 번째 메일 처리 중...\n",
      "144/860 번째 메일 처리 중...\n",
      "145/860 번째 메일 처리 중...\n",
      "146/860 번째 메일 처리 중...\n",
      "147/860 번째 메일 처리 중...\n",
      "148/860 번째 메일 처리 중...\n",
      "149/860 번째 메일 처리 중...\n",
      "150/860 번째 메일 처리 중...\n",
      "151/860 번째 메일 처리 중...\n",
      "152/860 번째 메일 처리 중...\n",
      "153/860 번째 메일 처리 중...\n",
      "154/860 번째 메일 처리 중...\n",
      "155/860 번째 메일 처리 중...\n",
      "156/860 번째 메일 처리 중...\n",
      "157/860 번째 메일 처리 중...\n",
      "158/860 번째 메일 처리 중...\n",
      "159/860 번째 메일 처리 중...\n",
      "160/860 번째 메일 처리 중...\n",
      "161/860 번째 메일 처리 중...\n",
      "162/860 번째 메일 처리 중...\n",
      "163/860 번째 메일 처리 중...\n",
      "164/860 번째 메일 처리 중...\n",
      "165/860 번째 메일 처리 중...\n",
      "166/860 번째 메일 처리 중...\n",
      "167/860 번째 메일 처리 중...\n",
      "168/860 번째 메일 처리 중...\n",
      "169/860 번째 메일 처리 중...\n",
      "170/860 번째 메일 처리 중...\n",
      "171/860 번째 메일 처리 중...\n",
      "172/860 번째 메일 처리 중...\n",
      "173/860 번째 메일 처리 중...\n",
      "174/860 번째 메일 처리 중...\n",
      "175/860 번째 메일 처리 중...\n",
      "176/860 번째 메일 처리 중...\n",
      "177/860 번째 메일 처리 중...\n",
      "178/860 번째 메일 처리 중...\n",
      "179/860 번째 메일 처리 중...\n",
      "180/860 번째 메일 처리 중...\n",
      "181/860 번째 메일 처리 중...\n",
      "182/860 번째 메일 처리 중...\n",
      "183/860 번째 메일 처리 중...\n",
      "184/860 번째 메일 처리 중...\n",
      "185/860 번째 메일 처리 중...\n",
      "186/860 번째 메일 처리 중...\n",
      "187/860 번째 메일 처리 중...\n",
      "188/860 번째 메일 처리 중...\n",
      "189/860 번째 메일 처리 중...\n",
      "190/860 번째 메일 처리 중...\n",
      "191/860 번째 메일 처리 중...\n",
      "192/860 번째 메일 처리 중...\n",
      "193/860 번째 메일 처리 중...\n",
      "194/860 번째 메일 처리 중...\n",
      "195/860 번째 메일 처리 중...\n",
      "196/860 번째 메일 처리 중...\n",
      "197/860 번째 메일 처리 중...\n",
      "198/860 번째 메일 처리 중...\n",
      "199/860 번째 메일 처리 중...\n",
      "200/860 번째 메일 처리 중...\n",
      "201/860 번째 메일 처리 중...\n",
      "202/860 번째 메일 처리 중...\n",
      "203/860 번째 메일 처리 중...\n",
      "204/860 번째 메일 처리 중...\n",
      "205/860 번째 메일 처리 중...\n",
      "206/860 번째 메일 처리 중...\n",
      "207/860 번째 메일 처리 중...\n",
      "208/860 번째 메일 처리 중...\n",
      "209/860 번째 메일 처리 중...\n",
      "210/860 번째 메일 처리 중...\n",
      "211/860 번째 메일 처리 중...\n",
      "212/860 번째 메일 처리 중...\n",
      "213/860 번째 메일 처리 중...\n",
      "214/860 번째 메일 처리 중...\n",
      "215/860 번째 메일 처리 중...\n",
      "216/860 번째 메일 처리 중...\n",
      "217/860 번째 메일 처리 중...\n",
      "218/860 번째 메일 처리 중...\n",
      "219/860 번째 메일 처리 중...\n",
      "220/860 번째 메일 처리 중...\n",
      "221/860 번째 메일 처리 중...\n",
      "222/860 번째 메일 처리 중...\n",
      "223/860 번째 메일 처리 중...\n",
      "224/860 번째 메일 처리 중...\n",
      "225/860 번째 메일 처리 중...\n",
      "226/860 번째 메일 처리 중...\n",
      "227/860 번째 메일 처리 중...\n",
      "228/860 번째 메일 처리 중...\n",
      "229/860 번째 메일 처리 중...\n",
      "230/860 번째 메일 처리 중...\n",
      "231/860 번째 메일 처리 중...\n",
      "232/860 번째 메일 처리 중...\n",
      "233/860 번째 메일 처리 중...\n",
      "234/860 번째 메일 처리 중...\n",
      "235/860 번째 메일 처리 중...\n",
      "236/860 번째 메일 처리 중...\n",
      "237/860 번째 메일 처리 중...\n",
      "238/860 번째 메일 처리 중...\n",
      "239/860 번째 메일 처리 중...\n",
      "240/860 번째 메일 처리 중...\n",
      "241/860 번째 메일 처리 중...\n",
      "242/860 번째 메일 처리 중...\n",
      "243/860 번째 메일 처리 중...\n",
      "244/860 번째 메일 처리 중...\n",
      "245/860 번째 메일 처리 중...\n",
      "246/860 번째 메일 처리 중...\n",
      "247/860 번째 메일 처리 중...\n",
      "248/860 번째 메일 처리 중...\n",
      "249/860 번째 메일 처리 중...\n",
      "250/860 번째 메일 처리 중...\n",
      "251/860 번째 메일 처리 중...\n",
      "252/860 번째 메일 처리 중...\n",
      "253/860 번째 메일 처리 중...\n",
      "254/860 번째 메일 처리 중...\n",
      "255/860 번째 메일 처리 중...\n",
      "256/860 번째 메일 처리 중...\n",
      "257/860 번째 메일 처리 중...\n",
      "258/860 번째 메일 처리 중...\n",
      "259/860 번째 메일 처리 중...\n",
      "260/860 번째 메일 처리 중...\n",
      "261/860 번째 메일 처리 중...\n",
      "262/860 번째 메일 처리 중...\n",
      "263/860 번째 메일 처리 중...\n",
      "264/860 번째 메일 처리 중...\n",
      "265/860 번째 메일 처리 중...\n",
      "266/860 번째 메일 처리 중...\n",
      "267/860 번째 메일 처리 중...\n",
      "268/860 번째 메일 처리 중...\n",
      "269/860 번째 메일 처리 중...\n",
      "270/860 번째 메일 처리 중...\n",
      "271/860 번째 메일 처리 중...\n",
      "272/860 번째 메일 처리 중...\n",
      "273/860 번째 메일 처리 중...\n",
      "274/860 번째 메일 처리 중...\n",
      "275/860 번째 메일 처리 중...\n",
      "276/860 번째 메일 처리 중...\n",
      "277/860 번째 메일 처리 중...\n",
      "278/860 번째 메일 처리 중...\n",
      "279/860 번째 메일 처리 중...\n",
      "280/860 번째 메일 처리 중...\n",
      "281/860 번째 메일 처리 중...\n",
      "282/860 번째 메일 처리 중...\n",
      "283/860 번째 메일 처리 중...\n",
      "284/860 번째 메일 처리 중...\n",
      "285/860 번째 메일 처리 중...\n",
      "286/860 번째 메일 처리 중...\n",
      "287/860 번째 메일 처리 중...\n",
      "288/860 번째 메일 처리 중...\n",
      "289/860 번째 메일 처리 중...\n",
      "290/860 번째 메일 처리 중...\n",
      "291/860 번째 메일 처리 중...\n",
      "292/860 번째 메일 처리 중...\n",
      "293/860 번째 메일 처리 중...\n",
      "294/860 번째 메일 처리 중...\n",
      "295/860 번째 메일 처리 중...\n",
      "296/860 번째 메일 처리 중...\n",
      "297/860 번째 메일 처리 중...\n",
      "298/860 번째 메일 처리 중...\n",
      "299/860 번째 메일 처리 중...\n",
      "300/860 번째 메일 처리 중...\n",
      "301/860 번째 메일 처리 중...\n",
      "302/860 번째 메일 처리 중...\n",
      "303/860 번째 메일 처리 중...\n",
      "304/860 번째 메일 처리 중...\n",
      "305/860 번째 메일 처리 중...\n",
      "306/860 번째 메일 처리 중...\n",
      "307/860 번째 메일 처리 중...\n",
      "308/860 번째 메일 처리 중...\n",
      "309/860 번째 메일 처리 중...\n",
      "310/860 번째 메일 처리 중...\n",
      "311/860 번째 메일 처리 중...\n",
      "312/860 번째 메일 처리 중...\n",
      "313/860 번째 메일 처리 중...\n",
      "314/860 번째 메일 처리 중...\n",
      "315/860 번째 메일 처리 중...\n",
      "316/860 번째 메일 처리 중...\n",
      "317/860 번째 메일 처리 중...\n",
      "318/860 번째 메일 처리 중...\n",
      "319/860 번째 메일 처리 중...\n",
      "320/860 번째 메일 처리 중...\n",
      "321/860 번째 메일 처리 중...\n",
      "322/860 번째 메일 처리 중...\n",
      "323/860 번째 메일 처리 중...\n",
      "324/860 번째 메일 처리 중...\n",
      "325/860 번째 메일 처리 중...\n",
      "326/860 번째 메일 처리 중...\n",
      "327/860 번째 메일 처리 중...\n",
      "328/860 번째 메일 처리 중...\n",
      "329/860 번째 메일 처리 중...\n",
      "330/860 번째 메일 처리 중...\n",
      "331/860 번째 메일 처리 중...\n",
      "332/860 번째 메일 처리 중...\n",
      "333/860 번째 메일 처리 중...\n",
      "334/860 번째 메일 처리 중...\n",
      "335/860 번째 메일 처리 중...\n",
      "336/860 번째 메일 처리 중...\n",
      "337/860 번째 메일 처리 중...\n",
      "338/860 번째 메일 처리 중...\n",
      "339/860 번째 메일 처리 중...\n",
      "340/860 번째 메일 처리 중...\n",
      "341/860 번째 메일 처리 중...\n",
      "342/860 번째 메일 처리 중...\n",
      "343/860 번째 메일 처리 중...\n",
      "344/860 번째 메일 처리 중...\n",
      "345/860 번째 메일 처리 중...\n",
      "346/860 번째 메일 처리 중...\n",
      "347/860 번째 메일 처리 중...\n",
      "348/860 번째 메일 처리 중...\n",
      "349/860 번째 메일 처리 중...\n",
      "350/860 번째 메일 처리 중...\n",
      "351/860 번째 메일 처리 중...\n",
      "352/860 번째 메일 처리 중...\n",
      "353/860 번째 메일 처리 중...\n",
      "354/860 번째 메일 처리 중...\n",
      "355/860 번째 메일 처리 중...\n",
      "356/860 번째 메일 처리 중...\n",
      "357/860 번째 메일 처리 중...\n",
      "358/860 번째 메일 처리 중...\n",
      "359/860 번째 메일 처리 중...\n",
      "360/860 번째 메일 처리 중...\n",
      "361/860 번째 메일 처리 중...\n",
      "362/860 번째 메일 처리 중...\n",
      "363/860 번째 메일 처리 중...\n",
      "364/860 번째 메일 처리 중...\n",
      "365/860 번째 메일 처리 중...\n",
      "366/860 번째 메일 처리 중...\n",
      "367/860 번째 메일 처리 중...\n",
      "368/860 번째 메일 처리 중...\n",
      "369/860 번째 메일 처리 중...\n",
      "370/860 번째 메일 처리 중...\n",
      "371/860 번째 메일 처리 중...\n",
      "372/860 번째 메일 처리 중...\n",
      "373/860 번째 메일 처리 중...\n",
      "374/860 번째 메일 처리 중...\n",
      "375/860 번째 메일 처리 중...\n",
      "376/860 번째 메일 처리 중...\n",
      "377/860 번째 메일 처리 중...\n",
      "378/860 번째 메일 처리 중...\n",
      "379/860 번째 메일 처리 중...\n",
      "380/860 번째 메일 처리 중...\n",
      "381/860 번째 메일 처리 중...\n",
      "382/860 번째 메일 처리 중...\n",
      "383/860 번째 메일 처리 중...\n",
      "384/860 번째 메일 처리 중...\n",
      "385/860 번째 메일 처리 중...\n",
      "386/860 번째 메일 처리 중...\n",
      "387/860 번째 메일 처리 중...\n",
      "388/860 번째 메일 처리 중...\n",
      "389/860 번째 메일 처리 중...\n",
      "390/860 번째 메일 처리 중...\n",
      "391/860 번째 메일 처리 중...\n",
      "392/860 번째 메일 처리 중...\n",
      "393/860 번째 메일 처리 중...\n",
      "394/860 번째 메일 처리 중...\n",
      "395/860 번째 메일 처리 중...\n",
      "396/860 번째 메일 처리 중...\n",
      "397/860 번째 메일 처리 중...\n",
      "398/860 번째 메일 처리 중...\n",
      "399/860 번째 메일 처리 중...\n",
      "400/860 번째 메일 처리 중...\n",
      "401/860 번째 메일 처리 중...\n",
      "402/860 번째 메일 처리 중...\n",
      "403/860 번째 메일 처리 중...\n",
      "404/860 번째 메일 처리 중...\n",
      "405/860 번째 메일 처리 중...\n",
      "406/860 번째 메일 처리 중...\n",
      "407/860 번째 메일 처리 중...\n",
      "408/860 번째 메일 처리 중...\n",
      "409/860 번째 메일 처리 중...\n",
      "410/860 번째 메일 처리 중...\n",
      "411/860 번째 메일 처리 중...\n",
      "412/860 번째 메일 처리 중...\n",
      "413/860 번째 메일 처리 중...\n",
      "414/860 번째 메일 처리 중...\n",
      "415/860 번째 메일 처리 중...\n",
      "416/860 번째 메일 처리 중...\n",
      "417/860 번째 메일 처리 중...\n",
      "418/860 번째 메일 처리 중...\n",
      "419/860 번째 메일 처리 중...\n",
      "420/860 번째 메일 처리 중...\n",
      "421/860 번째 메일 처리 중...\n",
      "422/860 번째 메일 처리 중...\n",
      "423/860 번째 메일 처리 중...\n",
      "424/860 번째 메일 처리 중...\n",
      "425/860 번째 메일 처리 중...\n",
      "426/860 번째 메일 처리 중...\n",
      "427/860 번째 메일 처리 중...\n",
      "428/860 번째 메일 처리 중...\n",
      "429/860 번째 메일 처리 중...\n",
      "430/860 번째 메일 처리 중...\n",
      "431/860 번째 메일 처리 중...\n",
      "432/860 번째 메일 처리 중...\n",
      "433/860 번째 메일 처리 중...\n",
      "434/860 번째 메일 처리 중...\n",
      "435/860 번째 메일 처리 중...\n",
      "436/860 번째 메일 처리 중...\n",
      "437/860 번째 메일 처리 중...\n",
      "438/860 번째 메일 처리 중...\n",
      "439/860 번째 메일 처리 중...\n",
      "440/860 번째 메일 처리 중...\n",
      "441/860 번째 메일 처리 중...\n",
      "442/860 번째 메일 처리 중...\n",
      "443/860 번째 메일 처리 중...\n",
      "444/860 번째 메일 처리 중...\n",
      "445/860 번째 메일 처리 중...\n",
      "446/860 번째 메일 처리 중...\n",
      "447/860 번째 메일 처리 중...\n",
      "448/860 번째 메일 처리 중...\n",
      "449/860 번째 메일 처리 중...\n",
      "450/860 번째 메일 처리 중...\n",
      "451/860 번째 메일 처리 중...\n",
      "452/860 번째 메일 처리 중...\n",
      "453/860 번째 메일 처리 중...\n",
      "454/860 번째 메일 처리 중...\n",
      "455/860 번째 메일 처리 중...\n",
      "456/860 번째 메일 처리 중...\n",
      "457/860 번째 메일 처리 중...\n",
      "458/860 번째 메일 처리 중...\n",
      "459/860 번째 메일 처리 중...\n",
      "460/860 번째 메일 처리 중...\n",
      "461/860 번째 메일 처리 중...\n",
      "462/860 번째 메일 처리 중...\n",
      "463/860 번째 메일 처리 중...\n",
      "464/860 번째 메일 처리 중...\n",
      "465/860 번째 메일 처리 중...\n",
      "466/860 번째 메일 처리 중...\n",
      "467/860 번째 메일 처리 중...\n",
      "468/860 번째 메일 처리 중...\n",
      "469/860 번째 메일 처리 중...\n",
      "470/860 번째 메일 처리 중...\n",
      "471/860 번째 메일 처리 중...\n",
      "472/860 번째 메일 처리 중...\n",
      "473/860 번째 메일 처리 중...\n",
      "474/860 번째 메일 처리 중...\n",
      "475/860 번째 메일 처리 중...\n",
      "476/860 번째 메일 처리 중...\n",
      "477/860 번째 메일 처리 중...\n",
      "478/860 번째 메일 처리 중...\n",
      "479/860 번째 메일 처리 중...\n",
      "480/860 번째 메일 처리 중...\n",
      "481/860 번째 메일 처리 중...\n",
      "482/860 번째 메일 처리 중...\n",
      "483/860 번째 메일 처리 중...\n",
      "484/860 번째 메일 처리 중...\n",
      "485/860 번째 메일 처리 중...\n",
      "486/860 번째 메일 처리 중...\n",
      "487/860 번째 메일 처리 중...\n",
      "488/860 번째 메일 처리 중...\n",
      "489/860 번째 메일 처리 중...\n",
      "490/860 번째 메일 처리 중...\n",
      "491/860 번째 메일 처리 중...\n",
      "492/860 번째 메일 처리 중...\n",
      "493/860 번째 메일 처리 중...\n",
      "494/860 번째 메일 처리 중...\n",
      "495/860 번째 메일 처리 중...\n",
      "496/860 번째 메일 처리 중...\n",
      "497/860 번째 메일 처리 중...\n",
      "498/860 번째 메일 처리 중...\n",
      "499/860 번째 메일 처리 중...\n",
      "500/860 번째 메일 처리 중...\n",
      "501/860 번째 메일 처리 중...\n",
      "502/860 번째 메일 처리 중...\n",
      "503/860 번째 메일 처리 중...\n",
      "504/860 번째 메일 처리 중...\n",
      "505/860 번째 메일 처리 중...\n",
      "506/860 번째 메일 처리 중...\n",
      "507/860 번째 메일 처리 중...\n",
      "508/860 번째 메일 처리 중...\n",
      "509/860 번째 메일 처리 중...\n",
      "510/860 번째 메일 처리 중...\n",
      "511/860 번째 메일 처리 중...\n",
      "512/860 번째 메일 처리 중...\n",
      "513/860 번째 메일 처리 중...\n",
      "514/860 번째 메일 처리 중...\n",
      "515/860 번째 메일 처리 중...\n",
      "516/860 번째 메일 처리 중...\n",
      "517/860 번째 메일 처리 중...\n",
      "518/860 번째 메일 처리 중...\n",
      "519/860 번째 메일 처리 중...\n",
      "520/860 번째 메일 처리 중...\n",
      "521/860 번째 메일 처리 중...\n",
      "522/860 번째 메일 처리 중...\n",
      "523/860 번째 메일 처리 중...\n",
      "524/860 번째 메일 처리 중...\n",
      "525/860 번째 메일 처리 중...\n",
      "526/860 번째 메일 처리 중...\n",
      "527/860 번째 메일 처리 중...\n",
      "528/860 번째 메일 처리 중...\n",
      "529/860 번째 메일 처리 중...\n",
      "530/860 번째 메일 처리 중...\n",
      "531/860 번째 메일 처리 중...\n",
      "532/860 번째 메일 처리 중...\n",
      "533/860 번째 메일 처리 중...\n",
      "534/860 번째 메일 처리 중...\n",
      "535/860 번째 메일 처리 중...\n",
      "536/860 번째 메일 처리 중...\n",
      "537/860 번째 메일 처리 중...\n",
      "538/860 번째 메일 처리 중...\n",
      "539/860 번째 메일 처리 중...\n",
      "540/860 번째 메일 처리 중...\n",
      "541/860 번째 메일 처리 중...\n",
      "542/860 번째 메일 처리 중...\n",
      "543/860 번째 메일 처리 중...\n",
      "544/860 번째 메일 처리 중...\n",
      "545/860 번째 메일 처리 중...\n",
      "546/860 번째 메일 처리 중...\n",
      "547/860 번째 메일 처리 중...\n",
      "548/860 번째 메일 처리 중...\n",
      "549/860 번째 메일 처리 중...\n",
      "550/860 번째 메일 처리 중...\n",
      "551/860 번째 메일 처리 중...\n",
      "552/860 번째 메일 처리 중...\n",
      "553/860 번째 메일 처리 중...\n",
      "554/860 번째 메일 처리 중...\n",
      "555/860 번째 메일 처리 중...\n",
      "556/860 번째 메일 처리 중...\n",
      "557/860 번째 메일 처리 중...\n",
      "558/860 번째 메일 처리 중...\n",
      "559/860 번째 메일 처리 중...\n",
      "560/860 번째 메일 처리 중...\n",
      "561/860 번째 메일 처리 중...\n",
      "562/860 번째 메일 처리 중...\n",
      "563/860 번째 메일 처리 중...\n",
      "564/860 번째 메일 처리 중...\n",
      "565/860 번째 메일 처리 중...\n",
      "566/860 번째 메일 처리 중...\n",
      "567/860 번째 메일 처리 중...\n",
      "568/860 번째 메일 처리 중...\n",
      "569/860 번째 메일 처리 중...\n",
      "570/860 번째 메일 처리 중...\n",
      "571/860 번째 메일 처리 중...\n",
      "572/860 번째 메일 처리 중...\n",
      "573/860 번째 메일 처리 중...\n",
      "574/860 번째 메일 처리 중...\n",
      "575/860 번째 메일 처리 중...\n",
      "576/860 번째 메일 처리 중...\n",
      "577/860 번째 메일 처리 중...\n",
      "578/860 번째 메일 처리 중...\n",
      "579/860 번째 메일 처리 중...\n",
      "580/860 번째 메일 처리 중...\n",
      "581/860 번째 메일 처리 중...\n",
      "582/860 번째 메일 처리 중...\n",
      "583/860 번째 메일 처리 중...\n",
      "584/860 번째 메일 처리 중...\n",
      "585/860 번째 메일 처리 중...\n",
      "586/860 번째 메일 처리 중...\n",
      "587/860 번째 메일 처리 중...\n",
      "588/860 번째 메일 처리 중...\n",
      "589/860 번째 메일 처리 중...\n",
      "590/860 번째 메일 처리 중...\n",
      "591/860 번째 메일 처리 중...\n",
      "592/860 번째 메일 처리 중...\n",
      "593/860 번째 메일 처리 중...\n",
      "594/860 번째 메일 처리 중...\n",
      "595/860 번째 메일 처리 중...\n",
      "596/860 번째 메일 처리 중...\n",
      "597/860 번째 메일 처리 중...\n",
      "598/860 번째 메일 처리 중...\n",
      "599/860 번째 메일 처리 중...\n",
      "600/860 번째 메일 처리 중...\n",
      "601/860 번째 메일 처리 중...\n",
      "602/860 번째 메일 처리 중...\n",
      "603/860 번째 메일 처리 중...\n",
      "604/860 번째 메일 처리 중...\n",
      "605/860 번째 메일 처리 중...\n",
      "606/860 번째 메일 처리 중...\n",
      "607/860 번째 메일 처리 중...\n",
      "608/860 번째 메일 처리 중...\n",
      "609/860 번째 메일 처리 중...\n",
      "610/860 번째 메일 처리 중...\n",
      "611/860 번째 메일 처리 중...\n",
      "612/860 번째 메일 처리 중...\n",
      "613/860 번째 메일 처리 중...\n",
      "614/860 번째 메일 처리 중...\n",
      "615/860 번째 메일 처리 중...\n",
      "616/860 번째 메일 처리 중...\n",
      "617/860 번째 메일 처리 중...\n",
      "618/860 번째 메일 처리 중...\n",
      "619/860 번째 메일 처리 중...\n",
      "620/860 번째 메일 처리 중...\n",
      "621/860 번째 메일 처리 중...\n",
      "622/860 번째 메일 처리 중...\n",
      "623/860 번째 메일 처리 중...\n",
      "624/860 번째 메일 처리 중...\n",
      "625/860 번째 메일 처리 중...\n",
      "626/860 번째 메일 처리 중...\n",
      "627/860 번째 메일 처리 중...\n",
      "628/860 번째 메일 처리 중...\n",
      "629/860 번째 메일 처리 중...\n",
      "630/860 번째 메일 처리 중...\n",
      "631/860 번째 메일 처리 중...\n",
      "632/860 번째 메일 처리 중...\n",
      "633/860 번째 메일 처리 중...\n",
      "634/860 번째 메일 처리 중...\n",
      "635/860 번째 메일 처리 중...\n",
      "636/860 번째 메일 처리 중...\n",
      "637/860 번째 메일 처리 중...\n",
      "638/860 번째 메일 처리 중...\n",
      "639/860 번째 메일 처리 중...\n",
      "640/860 번째 메일 처리 중...\n",
      "641/860 번째 메일 처리 중...\n",
      "642/860 번째 메일 처리 중...\n",
      "643/860 번째 메일 처리 중...\n",
      "644/860 번째 메일 처리 중...\n",
      "645/860 번째 메일 처리 중...\n",
      "646/860 번째 메일 처리 중...\n",
      "647/860 번째 메일 처리 중...\n",
      "648/860 번째 메일 처리 중...\n",
      "649/860 번째 메일 처리 중...\n",
      "650/860 번째 메일 처리 중...\n",
      "651/860 번째 메일 처리 중...\n",
      "652/860 번째 메일 처리 중...\n",
      "653/860 번째 메일 처리 중...\n",
      "654/860 번째 메일 처리 중...\n",
      "655/860 번째 메일 처리 중...\n",
      "656/860 번째 메일 처리 중...\n",
      "657/860 번째 메일 처리 중...\n",
      "658/860 번째 메일 처리 중...\n",
      "659/860 번째 메일 처리 중...\n",
      "660/860 번째 메일 처리 중...\n",
      "661/860 번째 메일 처리 중...\n",
      "662/860 번째 메일 처리 중...\n",
      "663/860 번째 메일 처리 중...\n",
      "664/860 번째 메일 처리 중...\n",
      "665/860 번째 메일 처리 중...\n",
      "666/860 번째 메일 처리 중...\n",
      "667/860 번째 메일 처리 중...\n",
      "668/860 번째 메일 처리 중...\n",
      "669/860 번째 메일 처리 중...\n",
      "670/860 번째 메일 처리 중...\n",
      "671/860 번째 메일 처리 중...\n",
      "672/860 번째 메일 처리 중...\n",
      "673/860 번째 메일 처리 중...\n",
      "674/860 번째 메일 처리 중...\n",
      "675/860 번째 메일 처리 중...\n",
      "676/860 번째 메일 처리 중...\n",
      "677/860 번째 메일 처리 중...\n",
      "678/860 번째 메일 처리 중...\n",
      "679/860 번째 메일 처리 중...\n",
      "680/860 번째 메일 처리 중...\n",
      "681/860 번째 메일 처리 중...\n",
      "682/860 번째 메일 처리 중...\n",
      "683/860 번째 메일 처리 중...\n",
      "684/860 번째 메일 처리 중...\n",
      "685/860 번째 메일 처리 중...\n",
      "686/860 번째 메일 처리 중...\n",
      "687/860 번째 메일 처리 중...\n",
      "688/860 번째 메일 처리 중...\n",
      "689/860 번째 메일 처리 중...\n",
      "690/860 번째 메일 처리 중...\n",
      "691/860 번째 메일 처리 중...\n",
      "692/860 번째 메일 처리 중...\n",
      "693/860 번째 메일 처리 중...\n",
      "694/860 번째 메일 처리 중...\n",
      "695/860 번째 메일 처리 중...\n",
      "696/860 번째 메일 처리 중...\n",
      "697/860 번째 메일 처리 중...\n",
      "698/860 번째 메일 처리 중...\n",
      "699/860 번째 메일 처리 중...\n",
      "700/860 번째 메일 처리 중...\n",
      "701/860 번째 메일 처리 중...\n",
      "702/860 번째 메일 처리 중...\n",
      "703/860 번째 메일 처리 중...\n",
      "704/860 번째 메일 처리 중...\n",
      "705/860 번째 메일 처리 중...\n",
      "706/860 번째 메일 처리 중...\n",
      "707/860 번째 메일 처리 중...\n",
      "708/860 번째 메일 처리 중...\n",
      "709/860 번째 메일 처리 중...\n",
      "710/860 번째 메일 처리 중...\n",
      "711/860 번째 메일 처리 중...\n",
      "712/860 번째 메일 처리 중...\n",
      "713/860 번째 메일 처리 중...\n",
      "714/860 번째 메일 처리 중...\n",
      "715/860 번째 메일 처리 중...\n",
      "716/860 번째 메일 처리 중...\n",
      "717/860 번째 메일 처리 중...\n",
      "718/860 번째 메일 처리 중...\n",
      "719/860 번째 메일 처리 중...\n",
      "720/860 번째 메일 처리 중...\n",
      "721/860 번째 메일 처리 중...\n",
      "722/860 번째 메일 처리 중...\n",
      "723/860 번째 메일 처리 중...\n",
      "724/860 번째 메일 처리 중...\n",
      "725/860 번째 메일 처리 중...\n",
      "726/860 번째 메일 처리 중...\n",
      "727/860 번째 메일 처리 중...\n",
      "728/860 번째 메일 처리 중...\n",
      "729/860 번째 메일 처리 중...\n",
      "730/860 번째 메일 처리 중...\n",
      "731/860 번째 메일 처리 중...\n",
      "732/860 번째 메일 처리 중...\n",
      "733/860 번째 메일 처리 중...\n",
      "734/860 번째 메일 처리 중...\n",
      "735/860 번째 메일 처리 중...\n",
      "736/860 번째 메일 처리 중...\n",
      "737/860 번째 메일 처리 중...\n",
      "738/860 번째 메일 처리 중...\n",
      "739/860 번째 메일 처리 중...\n",
      "740/860 번째 메일 처리 중...\n",
      "741/860 번째 메일 처리 중...\n",
      "742/860 번째 메일 처리 중...\n",
      "743/860 번째 메일 처리 중...\n",
      "744/860 번째 메일 처리 중...\n",
      "745/860 번째 메일 처리 중...\n",
      "746/860 번째 메일 처리 중...\n",
      "747/860 번째 메일 처리 중...\n",
      "748/860 번째 메일 처리 중...\n",
      "749/860 번째 메일 처리 중...\n",
      "750/860 번째 메일 처리 중...\n",
      "751/860 번째 메일 처리 중...\n",
      "752/860 번째 메일 처리 중...\n",
      "753/860 번째 메일 처리 중...\n",
      "754/860 번째 메일 처리 중...\n",
      "755/860 번째 메일 처리 중...\n",
      "756/860 번째 메일 처리 중...\n",
      "757/860 번째 메일 처리 중...\n",
      "758/860 번째 메일 처리 중...\n",
      "759/860 번째 메일 처리 중...\n",
      "760/860 번째 메일 처리 중...\n",
      "761/860 번째 메일 처리 중...\n",
      "762/860 번째 메일 처리 중...\n",
      "763/860 번째 메일 처리 중...\n",
      "764/860 번째 메일 처리 중...\n",
      "765/860 번째 메일 처리 중...\n",
      "766/860 번째 메일 처리 중...\n",
      "767/860 번째 메일 처리 중...\n",
      "768/860 번째 메일 처리 중...\n",
      "769/860 번째 메일 처리 중...\n",
      "770/860 번째 메일 처리 중...\n",
      "771/860 번째 메일 처리 중...\n",
      "772/860 번째 메일 처리 중...\n",
      "773/860 번째 메일 처리 중...\n",
      "774/860 번째 메일 처리 중...\n",
      "775/860 번째 메일 처리 중...\n",
      "776/860 번째 메일 처리 중...\n",
      "777/860 번째 메일 처리 중...\n",
      "778/860 번째 메일 처리 중...\n",
      "779/860 번째 메일 처리 중...\n",
      "780/860 번째 메일 처리 중...\n",
      "781/860 번째 메일 처리 중...\n",
      "782/860 번째 메일 처리 중...\n",
      "783/860 번째 메일 처리 중...\n",
      "784/860 번째 메일 처리 중...\n",
      "785/860 번째 메일 처리 중...\n",
      "786/860 번째 메일 처리 중...\n",
      "787/860 번째 메일 처리 중...\n",
      "788/860 번째 메일 처리 중...\n",
      "789/860 번째 메일 처리 중...\n",
      "790/860 번째 메일 처리 중...\n",
      "791/860 번째 메일 처리 중...\n",
      "792/860 번째 메일 처리 중...\n",
      "793/860 번째 메일 처리 중...\n",
      "794/860 번째 메일 처리 중...\n",
      "795/860 번째 메일 처리 중...\n",
      "796/860 번째 메일 처리 중...\n",
      "797/860 번째 메일 처리 중...\n",
      "798/860 번째 메일 처리 중...\n",
      "799/860 번째 메일 처리 중...\n",
      "800/860 번째 메일 처리 중...\n",
      "801/860 번째 메일 처리 중...\n",
      "802/860 번째 메일 처리 중...\n",
      "803/860 번째 메일 처리 중...\n",
      "804/860 번째 메일 처리 중...\n",
      "805/860 번째 메일 처리 중...\n",
      "806/860 번째 메일 처리 중...\n",
      "807/860 번째 메일 처리 중...\n",
      "808/860 번째 메일 처리 중...\n",
      "809/860 번째 메일 처리 중...\n",
      "810/860 번째 메일 처리 중...\n",
      "811/860 번째 메일 처리 중...\n",
      "812/860 번째 메일 처리 중...\n",
      "813/860 번째 메일 처리 중...\n",
      "814/860 번째 메일 처리 중...\n",
      "815/860 번째 메일 처리 중...\n",
      "816/860 번째 메일 처리 중...\n",
      "817/860 번째 메일 처리 중...\n",
      "818/860 번째 메일 처리 중...\n",
      "819/860 번째 메일 처리 중...\n",
      "820/860 번째 메일 처리 중...\n",
      "821/860 번째 메일 처리 중...\n",
      "822/860 번째 메일 처리 중...\n",
      "823/860 번째 메일 처리 중...\n",
      "824/860 번째 메일 처리 중...\n",
      "825/860 번째 메일 처리 중...\n",
      "826/860 번째 메일 처리 중...\n",
      "827/860 번째 메일 처리 중...\n",
      "828/860 번째 메일 처리 중...\n",
      "829/860 번째 메일 처리 중...\n",
      "830/860 번째 메일 처리 중...\n",
      "831/860 번째 메일 처리 중...\n",
      "832/860 번째 메일 처리 중...\n",
      "833/860 번째 메일 처리 중...\n",
      "834/860 번째 메일 처리 중...\n",
      "835/860 번째 메일 처리 중...\n",
      "836/860 번째 메일 처리 중...\n",
      "837/860 번째 메일 처리 중...\n",
      "838/860 번째 메일 처리 중...\n",
      "839/860 번째 메일 처리 중...\n",
      "840/860 번째 메일 처리 중...\n",
      "841/860 번째 메일 처리 중...\n",
      "842/860 번째 메일 처리 중...\n",
      "843/860 번째 메일 처리 중...\n",
      "844/860 번째 메일 처리 중...\n",
      "845/860 번째 메일 처리 중...\n",
      "846/860 번째 메일 처리 중...\n",
      "847/860 번째 메일 처리 중...\n",
      "848/860 번째 메일 처리 중...\n",
      "849/860 번째 메일 처리 중...\n",
      "850/860 번째 메일 처리 중...\n",
      "851/860 번째 메일 처리 중...\n",
      "852/860 번째 메일 처리 중...\n",
      "853/860 번째 메일 처리 중...\n",
      "854/860 번째 메일 처리 중...\n",
      "855/860 번째 메일 처리 중...\n",
      "856/860 번째 메일 처리 중...\n",
      "857/860 번째 메일 처리 중...\n",
      "858/860 번째 메일 처리 중...\n",
      "859/860 번째 메일 처리 중...\n",
      "860/860 번째 메일 처리 중...\n",
      "메일 제목 리스트를 'spam(K).csv'에 저장했습니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('BYE', [b'Logging out'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from email.header import decode_header # IMAP 이용\n",
    "import imaplib\n",
    "import email\n",
    "import csv\n",
    "\n",
    "# 메일 제목을 저장할 리스트\n",
    "subjects = []\n",
    "\n",
    "while input(\"ㄱㄱ?: \") != '0':\n",
    "\n",
    "    # IMAP 서버 정보\n",
    "    imap_server_input = input(\"사용할 메일서비스명: \")\n",
    "    imap_server = f\"imap.{imap_server_input}\"\n",
    "    email_user = input(\"계정 ID: \")\n",
    "    email_pass = input(\"password: \")\n",
    "\n",
    "    # IMAP 서버에 연결\n",
    "    mail = imaplib.IMAP4_SSL(imap_server, 993)\n",
    "    mail.login(email_user, email_pass)\n",
    "    print(\"로그인 성공!\")\n",
    "\n",
    "    # 받은 편지함 선택\n",
    "    mail.select(\"inbox\")  # 받은 편지함을 선택\n",
    "    status, messages = mail.search(None, \"ALL\")  # 모든 메일\n",
    "    # status, messages = mail.search(None, \"UNSEEN\")  # 읽지 않은 메일만 가져오기\n",
    "    # status, messages = mail.search(None, \"RECENT\")  # 최근에 받은 메일만 가져오기\n",
    "\n",
    "    # 메일 ID 추출\n",
    "    message_ids = messages[0].split()\n",
    "\n",
    "    # 메일 제목 가져오기\n",
    "    for index, msg_id in enumerate(message_ids, start=1):\n",
    "        print(f\"{index}/{len(message_ids)} 번째 메일 처리 중...\")\n",
    "\n",
    "        # 메일 가져오기\n",
    "        status, msg_data = mail.fetch(msg_id, \"(RFC822)\")\n",
    "\n",
    "        for response_part in msg_data:\n",
    "            if isinstance(response_part, tuple):\n",
    "                # 메일 내용 파싱\n",
    "                msg = email.message_from_bytes(response_part[1])\n",
    "                \n",
    "                # 메일 제목 디코딩\n",
    "                subject, encoding = decode_header(msg[\"Subject\"])[0]\n",
    "                if isinstance(subject, bytes):\n",
    "                    try:\n",
    "                        if encoding == \"cseuckr\":\n",
    "                            subject = subject.decode(\"euc-kr\", errors=\"ignore\")\n",
    "                        elif encoding == \"unknown-8bit\":\n",
    "                            subject = subject.decode(\"utf-8\", errors=\"ignore\")\n",
    "                        else:\n",
    "                            subject = subject.decode(encoding if encoding else \"utf-8\")\n",
    "                    except (UnicodeDecodeError, TypeError):\n",
    "                        subject = subject.decode(\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "                # 제목을 리스트에 추가\n",
    "                subjects.append(subject)\n",
    "\n",
    "# CSV 파일로 저장\n",
    "with open('spam(K).csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    for subject in subjects:\n",
    "        writer.writerow([0, subject])\n",
    "\n",
    "# 결과 확인\n",
    "print(\"메일 제목 리스트를 'spam(K).csv'에 저장했습니다.\")\n",
    "\n",
    "# IMAP 서버에서 로그아웃\n",
    "mail.close()\n",
    "mail.logout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def Info(DataFrame):\n",
    "    DataFrame.info()\n",
    "    print(\"---------------------------------- \")\n",
    "    print('Null 여부 :', DataFrame.isnull().values.any())\n",
    "    print('중복값 :', len(DataFrame) - DataFrame['body'].nunique())\n",
    "    DataFrame.drop_duplicates(subset=['body'], inplace=True)\n",
    "    print('삭제 후 샘플 수 :',len(DataFrame))\n",
    "    print(\"---------------------------------- \")\n",
    "    print(DataFrame.groupby('head').size().reset_index(name='count'))\n",
    "\n",
    "def Incoding():\n",
    "    print(\"인코딩 결과 : \", word_to_index)\n",
    "    print(\"등장횟수 : \", tokenizer.word_counts.items())\n",
    "\n",
    "    one = 2\n",
    "    total_cnt = len(word_to_index) # 단어의 수\n",
    "    rare_cnt = 0 # 등장 빈도수가 one보다 작은 단어의 개수를 카운트\n",
    "    total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "    rare_freq = 0 # 등장 빈도수가 one보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "    # 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "    for key, value in tokenizer.word_counts.items():\n",
    "        total_freq = total_freq + value\n",
    "\n",
    "        # 단어의 등장 빈도수가 one보다 작으면\n",
    "        if(value < one):\n",
    "            rare_cnt = rare_cnt + 1\n",
    "            rare_freq = rare_freq + value\n",
    "\n",
    "    print('메일의 최대 길이 : %d' % max(len(sample) for sample in X_train_encoded))\n",
    "    print('메일의 평균 길이 : %f' % (sum(map(len, X_train_encoded))/len(X_train_encoded)))\n",
    "    print('등장 빈도가 %s번 이하인 단어의 수: %s'%(one - 1, rare_cnt))\n",
    "    print(\"단어 집합(vocabulary)에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "    print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred: 'euc_kr' codec can't decode byte 0x84 in position 22: illegal multibyte sequence\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open('spam(K).csv', 'r', encoding='euc-kr') as infile:\n",
    "        content = infile.read()\n",
    "\n",
    "    with open('spam(k).csv', 'w', encoding='utf-8') as outfile:\n",
    "        outfile.write(content)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {e}\")\n",
    "    # 에러가 발생하면 해당 파일을 스킵하고, 프로그램을 계속 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플의 수 : 1830\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[EvryPlay] 계정을 인증해주세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>주말은 Google Play와 함께</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>주말은 Google Play, Chromecast와 함께!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>주말은 구글플레이와 함께! 도서 세트 할인!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2014 브라질 월드컵, 뜨겁게 즐기자!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   head                              body\n",
       "0     1            [EvryPlay] 계정을 인증해주세요.\n",
       "1     0               주말은 Google Play와 함께\n",
       "2     0  주말은 Google Play, Chromecast와 함께!\n",
       "3     0          주말은 구글플레이와 함께! 도서 세트 할인!\n",
       "4     0            2014 브라질 월드컵, 뜨겁게 즐기자!"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('spam(k).csv', encoding='utf-8')\n",
    "print('총 샘플의 수 :',len(data))\n",
    "data.columns = ['head', 'body']\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1830 entries, 0 to 1829\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   head    1830 non-null   int64 \n",
      " 1   body    1828 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 28.7+ KB\n",
      "---------------------------------- \n",
      "Null 여부 : True\n",
      "중복값 : 593\n",
      "삭제 후 샘플 수 : 1238\n",
      "---------------------------------- \n",
      "   head  count\n",
      "0     0    907\n",
      "1     1    331\n"
     ]
    }
   ],
   "source": [
    "Info(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 0 Axes>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['head'].value_counts().plot(kind='bar')\n",
    "plt.figure(figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = data['body']\n",
    "y_data = data['head']\n",
    "X_data = [sample if sample == sample else '0' for sample in X_data]\n",
    "# 데이터 나누기\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=0, stratify=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 결과 :  {'광고': 1, '안내': 2, '컬쳐랜드': 3, '개인정보': 4, '갤럭시': 5, 'google': 6, '문화상품권': 7, 'play': 8, '주문': 9, '혜택': 10, '영수증': 11, '이용약관': 12, '개정': 13, '이용내역': 14, '2021': 15, '계정': 16, 'to': 17, 'your': 18, '이벤트': 19, '및': 20, '지금': 21, '변경': 22, '보세요': 23, '새로운': 24, 'and': 25, '알바': 26, '받으세요': 27, '드립니다': 28, '최대': 29, 'circleci': 30, 'for': 31, '약관': 32, '서비스': 33, 'github': 34, '업데이트': 35, '할인': 36, '안내드립니다': 37, '내역': 38, '지급': 39, '받아가세요': 40, '2': 41, 'newsletter': 42, \"'\": 43, 'ci': 44, 'galaxy': 45, '만나보세요': 46, '알바천국': 47, '데스런': 48, '로그인': 49, '있는': 50, '이용': 51, 'cd': 52, '캠퍼스': 53, 'ip': 54, '11': 55, 'mega': 56, '3': 57, '수': 58, '함께': 59, 'webinar': 60, '2022': 61, '네이버': 62, '증정': 63, '방법': 64, '이용내역을': 65, '환영합니다': 66, '사전': 67, '문화상품권으로': 68, 'the': 69, 'repl': 70, 'it': 71, '6': 72, '월간': 73, '정보': 74, 'on': 75, 'new': 76, '100': 77, '스토어': 78, '·': 79, '원스토어': 80, '굽자님의': 81, '10': 82, '컬쳐캐쉬': 83, 'of': 84, '알림': 85, '한국발명진흥회': 86, 'in': 87, '양은석': 88, '수집': 89, '출처': 90, '앱': 91, '따른': 92, '5천원': 93, '12': 94, '삼성닷컴': 95, 'youtube': 96, '내': 97, '시': 98, '5': 99, 'academy': 100, '신규': 101, '휴면': 102, '구글': 103, '교육과정': 104, '완료되었습니다': 105, 'twitch': 106, '해피머니': 107, '고객님': 108, '무료로': 109, 'a': 110, '전자금융거래': 111, 'you': 112, '굽자님': 113, '설정을': 114, '전환': 115, 'ict': 116, 'cog': 117, '회원님의': 118, 'd': 119, '무료': 120, '1': 121, '에': 122, '이메일': 123, '설문조사': 124, '양은석님': 125, '시리즈': 126, '엠브레인': 127, '네이버웹툰': 128, '가장': 129, 'replit': 130, 'from': 131, '통지': 132, 'get': 133, '2020': 134, '보안': 135, '가입': 136, 'deslun': 137, '채널의': 138, '바로': 139, '5월': 140, '광고성': 141, '버즈': 142, '참여하고': 143, '포인트': 144, '받고': 145, '구매': 146, '웹하드': 147, '누군가가': 148, '여러분의': 149, '정책': 150, '연말': 151, '네이버페이': 152, '사전판매': 153, 'campus': 154, 'with': 155, '공지': 156, '북2': 157, '런칭': 158, '버즈2': 159, '문상': 160, '10월': 161, '쿠폰': 162, '제공': 163, '완료하세요': 164, 'android': 165, '대한': 166, '교육': 167, '더': 168, '인증': 169, '넥슨': 170, 'workout': 171, '시작': 172, '딱': 173, '2021년': 174, '동의': 175, '확인해': 176, '9': 177, '모집': 178, 'today': 179, '되는': 180, '4': 181, 'more': 182, '아카데미': 183, 'z': 184, '공모전': 185, '즉시': 186, '30': 187, '접근하려': 188, '합니다': 189, '선물': 190, '적립': 191, 'kakao': 192, '카카오': 193, '고지': 194, '받자': 195, '000원': 196, '뉴스레터': 197, '관련': 198, '추가': 199, '먼저': 200, 'cj': 201, 'one': 202, '완료': 203, '카카오페이': 204, 'kucoin': 205, 'is': 206, '수신동의': 207, '카카오페이지': 208, '포켓몬': 209, '혜택으로': 210, '2024년': 211, '삼성전자': 212, '계정이': 213, '게임': 214, '홍보': 215, '의견이': 216, '필요한': 217, '이용하세요': 218, '기프트': 219, '코드': 220, '트위치': 221, '판매': 222, '8': 223, '오프라인': 224, '도서관': 225, '주세요': 226, 'tips': 227, 'tricks': 228, '혜택을': 229, '공짜': 230, '고기먹고싶은디님': 231, '가입하면': 232, '500원': 233, '커리어넷': 234, '특별한': 235, '3천원': 236, '변경되었습니다': 237, '월간컬쳐랜드': 238, '메일': 239, '배달의민족': 240, 'stats': 241, '주소': 242, '확인': 243, '작성한': 244, '댓글에': 245, '답변': 246, '유료': 247, 'upcoming': 248, '사용한': 249, 'mobile': 250, 'development': 251, 'out': 252, 'gb': 253, '99': 254, 'universe': 255, '수수료': 256, '확인하세요': 257, '전원': 258, '26': 259, '2022년': 260, 'terms': 261, '단': 262, '특별': 263, '종료': 264, '인공지능': 265, '꿀알바': 266, 'kt': 267, 'writing': 268, 'premium': 269, '사칭한': 270, '롯데컬처웍스': 271, '수신': 272, '문화상품권이': 273, '할': 274, '새로': 275, '소중한': 276, '설문': 277, '구매하세요': 278, '2019': 279, '무제한': 280, '주의하세요': 281, '플레이': 282, 'yes6815': 283, '대성마이맥': 284, '장기': 285, '양은석님의': 286, '것을': 287, '라이벌스': 288, 'open': 289, 'party': 290, 'account': 291, '간단한': 292, '컬쳐캐쉬를': 293, '24': 294, '현금': 295, 'we': 296, '탑툰': 297, '4월': 298, '프로': 299, '13': 300, '설문조사로': 301, '좋은': 302, 'l': 303, 'point': 304, '회원가입을': 305, '되셨습니다': 306, '최신': 307, '컨텐츠': 308, '중요': 309, '♥': 310, 'h': 311, '삭제': 312, 'payments': 313, '예정': 314, '이번': 315, '12월': 316, '역대급': 317, '최저임금': 318, 'jenkins': 319, '상당': 320, '기회': 321, '7': 322, '3월': 323, '온라인': 324, 'live': 325, '가입을': 326, '삼성계정': 327, '마케팅': 328, '정기': 329, '싶다면': 330, '활용': 331, '23': 332, '선착순': 333, '전자제품': 334, '프로젝트': 335, 'just': 336, '거래': 337, '거래지원': 338, '만나는': 339, '를': 340, '워치4': 341, '고객님의': 342, '개인정보처리방침': 343, '9월': 344, '2500원': 345, '회원': 346, 'last': 347, '상품권': 348, 'twitch에서': 349, 'grammarly': 350, 'welcome': 351, 'our': 352, '위한': 353, 'webinars': 354, '휴면계정': 355, '패키지': 356, '출시': 357, '주말은': 358, '네이버파이낸셜': 359, 'note': 360, '설문조사하고': 361, '다쓴문상': 362, '이벤트를': 363, 'facebook': 364, 'mybox': 365, '체험': 366, '시즌': 367, 'sns': 368, '문자를': 369, '피싱': 370, '인증번호': 371, 'email': 372, '오신': 373, 'third': 374, 'application': 375, 'has': 376, 'been': 377, 'added': 378, '영남대학교': 379, '경품': 380, 'start': 381, 'pipelines': 382, '오픈': 383, '혜택은': 384, '뜨겁게': 385, '게임을': 386, '다': 387, 'privacy': 388, '교환해': 389, '기본': 390, '오세요': 391, '누구나': 392, '필요한데': 393, '얻을': 394, 'vms': 395, '도착': 396, '2021년도': 397, '청소년발명기자단': 398, '모집안내': 399, '컬쳐캐쉬로': 400, '즐겨보세요': 401, '준비': 402, '이제': 403, '소프라노몰': 404, '내역을': 405, '마감': 406, 'ip아카데미': 407, '9월호': 408, '8월': 409, 't아이디': 410, 'battle': 411, 'net': 412, '마지막': 413, '5g': 414, '패널모집': 415, '파일썬에서': 416, '상품권으로': 417, '기능': 418, 's20': 419, 'off': 420, 'storage': 421, 'month': 422, '기기에서': 423, '양': 424, '석님': 425, '통지문': 426, '플립4': 427, '확인해보세요': 428, '2천원': 429, 'com': 430, 'play와': 431, '회원님': 432, '알아보기': 433, '결제': 434, '모바일': 435, '쿠폰이': 436, '업비트': 437, 'service': 438, '이용해': 439, '프로그램': 440, 'please': 441, '스토리': 442, 'at': 443, '삼성카드': 444, '청구할인': 445, '조심하세요': 446, '회원가입이': 447, '맞이': 448, 'youmake': 449, 'offer': 450, '후': 451, '개정에': 452, '오늘': 453, '상당의': 454, '콜라보': 455, '한정': 456, '캐쉬백': 457, '확인하고': 458, '데이': 459, '에디션': 460, '요기요': 461, '증권플러스': 462, '이용하고': 463, '교육생': 464, 'vpn': 465, '15': 466, '축하드립니다': 467, '정보수신': 468, '오픈api': 469, '폐기': 470, '축하드려요': 471, '카페에': 472, '49': 473, '캐쉬업': 474, '피해': 475, 'week': 476, '하고': 477, '20': 478, '사전구매': 479, '제휴': 480, '고기먹고싶은디': 481, '인기': 482, '여부': 483, '구글기프트코드': 484, '다양한': 485, '이벤트까지': 486, 's7': 487, '블리자드': 488, '29': 489, '매일': 490, '특허청': 491, '결제하신': 492, '한': 493, '처리방침': 494, 'music': 495, '충전하고': 496, '당신의': 497, '가득': 498, '알바몬': 499, '삼성': 500, 'all': 501, '일정': 502, '이용·제공': 503, 'steam': 504, '한정수량': 505, '프로와': 506, '아디다스': 507, '오리지널스': 508, '만날': 509, '도서': 510, '티머니': 511, '대해': 512, 'best': 513, 'class': 514, 'an': 515, 'prem': 516, 'environment': 517, '공간': 518, '경험을': 519, 'samsung': 520, 're': 521, '수험생': 522, '만점': 523, '모아': 524, '북': 525, '보상': 526, '하는': 527, '회원가입하고': 528, '추가되었습니다': 529, '찐플에서': 530, '참여해': 531, '컬쳐랜드x파일썬': 532, '단돈': 533, '100원으로': 534, '처리': 535, '입금': 536, '400': 537, 'usdt': 538, '크리스마스': 539, '3가지': 540, '무료상담': 541, '개정안내': 542, '방식': 543, '일부': 544, '미사용': 545, '원스토리': 546, '라이엇게임즈': 547, '★구글': 548, 'epic': 549, 'games': 550, 'verification': 551, '한국갤럽에서': 552, '있습니다': 553, '미': 554, '개인정보가': 555, '11월': 556, '포함': 557, '전자금융거래약관': 558, 'your\\r': 559, '방법으로': 560, '안전하게': 561, '안내서': 562, '스마트하게': 563, '데이터를': 564, '유지하시겠습니까': 565, '결정해': 566, 'join': 567, 'practical': 568, '리니지w': 569, '아이템매니아': 570, '삼성페이': 571, '여름을': 572, '보너스': 573, '16': 574, 'oauth': 575, '드리는': 576, '마음을': 577, 'miss': 578, 'make': 579, 'logged': 580, '무료코인': 581, '6월': 582, '시리즈온': 583, '시리즈온에서': 584, '멤버십': 585, '콘텐츠': 586, '다쓴문상으로': 587, 'language': 588, 'jam': 589, '놀러': 590, '7월': 591, 's8': 592, '이유를': 593, '한눈에': 594, '없을까': 595, '8월호': 596, '만족도': 597, '참여하세요': 598, '발급되었습니다': 599, '비밀번호를': 600, '15만원': 601, '아직': 602, '페이백': 603, '15분': 604, '외식': 605, '데이터': 606, '사용자': 607, '정보가': 608, '1월호': 609, '아프리카tv': 610, '입니다': 611, '하세요': 612, '님': 613, '알려드립니다': 614, '임박': 615, '수강후기': 616, '앱으로': 617, '로드모바일': 618, 'apps': 619, '받는': 620, '2022년도': 621, 'moving': 622, '작성': 623, '01': 624, '개학': 625, '에픽게임즈': 626, '환불': 627, '이': 628, '컬쳐랜드와': 629, '공식': 630, '영화': 631, '대학생을': 632, '준비한': 633, 'fe': 634, '50': 635, '소비': 636, '갤': 637, '캠': 638, '스': 639, '필수': 640, 'upgrade': 641, '200': 642, 'code': 643, '18': 644, '사항': 645, '인증번호가': 646, '도착하였습니다': 647, 'schedule': 648, '0원': 649, '혜택이': 650, '쿠폰을': 651, '폴드4｜z': 652, '게임즈': 653, 'gmail': 654, '쿠코인': 655, 'satellite': 656, 'india': 657, '27': 658, '닌텐도': 659, '어카운트': 660, '특가': 661, '찬스': 662, '즐기세요': 663, '복구': 664, '우주라이크소설': 665, '메일입니다': 666, 'coming': 667, 'soon': 668, '다른': 669, '사전알림': 670, '신청하고': 671, 'final': 672, 'reminder': 673, '트레이너': 674, '유료서비스': 675, '집에서': 676, '영상보며': 677, '같이하는': 678, '맨몸운동': 679, '맨몸운동루틴': 680, 'this': 681, '어떠세요': 682, '회원가입': 683, 'announcing': 684, 'always': 685, '★': 686, '도전': 687, '명절': 688, '설': 689, '지식재산': 690, '영상을': 691, '알려라': 692, '삼성닷컴단독': 693, '경품과': 694, '분할합병에': 695, '이전': 696, '경고': 697, '웹': 698, '1월': 699, 'google을': 700, '사용해': 701, '2016': 702, 'discord': 703, 'bots': 704, 'verify': 705, 'cyber': 706, 'nh투자증권': 707, '조사하면': 708, '선물까지': 709, '쉿': 710, '쉽게': 711, '카페': 712, '운영': 713, '176만': 714, '만남': 715, '이용권': 716, '확인하여': 717, '다음': 718, '단계를': 719, '진행하세요': 720, 'i': 721, 'galaxy를': 722, '4월호': 723, '구스': 724, '추석': 725, '캐릭터': 726, '찐플': 727, 'year': 728, 'data': 729, 'languages': 730, '금리': 731, '커버': 732, '등': 733, '공공데이터포털': 734, '기상청': 735, '7eunsuk': 736, '자세히': 737, '가입하고': 738, '상품권도': 739, '드려요': 740, '외국어': 741, '능력자에겐': 742, '번역': 743, '통역': 744, '회원정보': 745, '3월호': 746, '동북권': 747, '아울렛': 748, '주의': 749, '합격자': 750, '지식재산권': 751, '이해': 752, '선행기술조사': 753, '실무': 754, '블로그': 755, '설정': 756, '받아': 757, '가세요': 758, '삼성월렛': 759, '확인하면': 760, '우수사례': 761, '참가자': 762, '19': 763, '시크릿': 764, '스타벅스': 765, '05': 766, 'x': 767, '케이뱅크': 768, '7천원': 769, '현금3천원': 770, '3분내': 771, '노래와': 772, 'basic': 773, 'api': 774, 'link': 775, 'special': 776, 'app': 777, 'have': 778, 'ventures': 779, '패밀리': 780, '끝': 781, '지원': 782, '갤캠스': 783, '진로교육정보망': 784, '어서': 785, '재안내': 786, 'policy': 787, '내게': 788, '맞는': 789, '공고': 790, '쇼핑몰': 791, '이용ㆍ제공': 792, '만료됨': 793, '문상으로': 794, '휴대폰': 795, '발명기자단': 796, '가입하세요': 797, 'up': 798, '비밀번호': 799, '위치기반서비스': 800, '마감임박': 801, 'getting': 802, '비밀번호가': 803, '흔치': 804, '않은': 805, '개인정보의': 806, '톰브라운': 807, '디자인을': 808, '입은': 809, '선물을': 810, 'kg이니시스': 811, '결제확인': 812, '주': 813, '확인바랍니다': 814, 'january': 815, '지급되었습니다': 816, '파일썬': 817, 'see': 818, 'what': 819, '화제의': 820, '콘텐츠를': 821, '스트리머를': 822, 'devops': 823, '새': 824, '기기에': 825, '내용': 826, '나의': 827, '핸들을': 828, '토루나에서': 829, '달': 830, '원하는': 831, 'id': 832, '12월호': 833, '31': 834, '사고': 835, \"we're\": 836, 'any': 837, 'activity': 838, '대학생': 839, '번개특가': 840, 'session': 841, 'pro': 842, '찼습니다': 843, 'most': 844, '받은': 845, '따뜻한': 846, '제18기': 847, '세뱃돈': 848, 'update': 849, '시리즈로': 850, '28': 851, '할인쿠폰': 852, '선플': 853, '÷': 854, '인터넷': 855, '컨텐츠를': 856, '2023': 857, 'recap': 858, 'first': 859, '카카오톡': 860, '대상': 861, '오버워치': 862, 'va': 863, '대규모': 864, '패치': 865, '한국정보통신자격협회': 866, 'move': 867, 'scale': 868, 'without\\r': 869, 'compromising': 870, 'security': 871, 'secure': 872, 'ebs': 873, '해': 874, '14': 875, '€1': 876, '지금이': 877, '스미싱을': 878, '플레이가': 879, '내가': 880, '접속': 881, '등록되었습니다': 882, '최고의': 883, '북3': 884, '넥슨캐시': 885, '배달': 886, '버즈2와': 887, '안부문자를': 888, 'pin': 889, '시청하세요': 890, '오픈뱅킹': 891, '금융거래정보': 892, '제공사실': 893, '즐겨': 894, 'cgv': 895, '공공데이터활용지원센터': 896, '변경에': 897, '코리아': 898, '사람들과': 899, '채팅해': 900, '알바의': 901, '기간': 902, '사전안내': 903, 'yes0363': 904, 'meet': 905, '대여': 906, '방식이': 907, 'point로': 908, '참여바랍니다': 909, 'tab': 910, 'cu': 911, '▶': 912, '스페셜한': 913, '넥서스': 914, 'g': 915, 'star에서': 916, '구글플레이와': 917, '세트': 918, '고객확인제도': 919, 'cdd': 920, 'edd': 921, '상세': 922, '설정에': 923, '동국대학교': 924, \"'25학년도\": 925, '전기': 926, '지식재산학': 927, '석사과정': 928, '신입생': 929, '게토': 930, '활동적인': 931, '여행·캠프·레포츠': 932, 'neo에서': 933, '생활': 934, '속': 935, '작은': 936, '습관으로': 937, '개인정보를': 938, '보호하세요': 939, '자': 940, '잘가라': 941, '종료까지': 942, '패널나우': 943, '신학기에': 944, '꼭': 945, '혜택만': 946, '대세는': 947, '폴더블': 948, 'flip': 949, 'lte': 950, '법': 951, '대학생이라면': 952, '스토어에서': 953, '할인받고': 954, '얼마든지': 955, '가져가세요': 956, '페이코인에서': 957, '창의발명교육': 958, '체험수기': 959, '계좌개설': 960, '다쓴상품권으로': 961, 'school': 962, '수강수료': 963, 'cloudberry': 964, '용량이': 965, '30일': 966, '영화감상하세요': 967, '펀드': 968, '피싱에': 969, '대비하는': 970, '국비지원': 971, '교육자료': 972, '14종': 973, 'nh투자': 974, '계좌통합관리서비스': 975, '통한': 976, '메신저': 977, '보유잔액': 978, '637868': 979, '리니지': 980, '위크': 981, '기념★': 982, '지원받고': 983, '미투디스크야': 984, '줄게': 985, '다오': 986, '모빌리티': 987, '자율주행': 988, '기기가': 989, '위치': 990, '기록에': 991, '반영되고': 992, 'dothome': 993, 'co': 994, 'kr': 995, '입학원서': 996, '접수가': 997, '이용으로': 998, '인해': 999, '별도': 1000, '보관됨을': 1001, 'twitch에': 1002, '하스스톤': 1003, '쇼다운이': 1004, '시작됩니다': 1005, '언제나': 1006, '꿈꿔온': 1007, 'note20': 1008, '여기': 1009, '시작되었어♪': 1010, '16일': 1011, '학생이라면': 1012, '교육할인과': 1013, '추가혜택도': 1014, '방송에': 1015, '관심이': 1016, '많았던': 1017, '분이라면': 1018, '방송스텝': 1019, '촬영보조': 1020, '해피캐시': 1021, '보유한도': 1022, '특강': 1023, '드라마': 1024, '통신과금서비스': 1025, 'experiment': 1026, 'projects': 1027, 'youtube에': 1028, '핸들이': 1029, '도입됩니다': 1030, '보호': 1031, '사용하세요': 1032, '04': 1033, '집콕하면서': 1034, '쇼핑하는': 1035, '타임라인': 1036, '서둘러': 1037, 'securing': 1038, 'cd\\r': 1039, '투믹스': 1040, '세상은': 1041, '넓고': 1042, '많다': 1043, '올': 1044, '달군': 1045, '알바자리': 1046, '싹': 1047, '찾는': 1048, '설치': 1049, '해머': 1050, '유효기간': 1051, '경과에': 1052, '해머소멸': 1053, '굽자': 1054, 'complete': 1055, 'checkup': 1056, '에베베베': 1057, '문화생활도': 1058, '알바도': 1059, '한번에': 1060, '영화관': 1061, '공연': 1062, '회원들만': 1063, '100원': 1064, '아카데미에서': 1065, '풀템으로': 1066, '전하세요': 1067, 'sure': 1068, \"you're\": 1069, '여름맞이': 1070, '의견': 1071, '내고': 1072, '지': 1073, '금': 1074, '이순간': 1075, '필요하다면': 1076, '종료를': 1077, '2023년': 1078, '영화보세요': 1079, 'submissions': 1080, '이젠': 1081, '중고': 1082, '혜택까지': 1083, 'filesun에서': 1084, '다쓴': 1085, '10만': 1086, '포인트로': 1087, '게임만해도': 1088, '편하게': 1089, '돈벌자': 1090, '탭': 1091, '제안': 1092, '구매하기': 1093, '축하합니다': 1094, '이벤트에': 1095, '당첨': 1096, 'gs건설': 1097, '자이': 1098, '조사에': 1099, '31일까지': 1100, '임시비밀번호가': 1101, '홈페이지': 1102, '수정에서': 1103, '수정하세요': 1104, '못받으셨나요': 1105, '서둘러서': 1106, '세상을바꾸는': 1107, '시간': 1108, '강연자': 1109, '공지사항': 1110, '바리스타': 1111, '경력을': 1112, '쌓아보세요': 1113, '커피전문점': 1114, '갤럭시끼리': 1115, '만나면': 1116, '환상의': 1117, '호흡': 1118, 'buds2': 1119, 'point전환': 1120, '국민관광상품권으로': 1121, '쇼핑': 1122, '관광을': 1123, '4에서': 1124, '네이버에서': 1125, '쇼핑하세요': 1126, '유웨이어플라이': 1127, '알바몬소식메일457호': 1128, '220607': 1129, '회원이라면': 1130, '페이백을': 1131, '분리보관': 1132, '절찬': 1133, '4백원': 1134, '구글플레이에서': 1135, '주말': 1136, '더위를': 1137, '날려버리세요': 1138, '6월호': 1139, 'website': 1140, 'project': 1141, 'sharing': 1142, '전자': 1143, '월동': 1144, '모바일로': 1145, '편리하게': 1146, 'ip스쿨': 1147, 'note9': 1148, '삼성계정에': 1149, '채팅창이': 1150, '기다려요': 1151, \"'의천도룡기\": 1152, \"kakao'에\": 1153, 'smart5': 1154, '특허정보분석시스템': 1155, '갤럭시를': 1156, '준비되셨나요': 1157, '10일': 1158, '마침내': 1159, '아이템': 1160, '5일부터': 1161, '7일까지': 1162, '어떤': 1163, '내용의': 1164, '방송이': 1165, '진행되나요': 1166, 'chat': 1167, 'user': 1168, '알바몬소식메일448호': 1169, '220118': 1170, '실전': 1171, '기술이전': 1172, '라이센싱': 1173, '계약서': 1174, '2025': 1175, '시행': 1176, '2020년': 1177, '갤럭시s21': 1178, '21만원': 1179, '전': 1180, '72만원': 1181, '혜택의': 1182, '최초': 1183, '자동납부': 1184, '3만': 1185, '6천원': 1186, '계정에': 1187, 'nintendo': 1188, '연결': 1189, 'riot': 1190, '기프트카드': 1191, '구매취소': 1192, '캐쉬': 1193, '상상력을디자인하는동화쓰기': 1194, '김기호님': 1195, '보냈습니다': 1196, '제휴한': 1197, '알바몬소식메일464호': 1198, '220906': 1199, '새학기': 1200, '위해': 1201, '스토어가': 1202, '컬러부터': 1203, '그리고': 1204, '가격까지': 1205, '뛰어난': 1206, 'ends': 1207, 'don’t': 1208, 'press': 1209, 'luck': 1210, '스마트한': 1211, '가입은': 1212, '건강': 1213, '습관': 1214, '챌린지': 1215, '이벤트도': 1216, \"don't\": 1217, 'only': 1218, '€2': 1219, '영남대': 1220, 'm365': 1221, 'office': 1222, '365': 1223, '용량': 1224, '제한': 1225, '졸업생': 1226, '단기알바도': 1227, '재밌게': 1228, '행사스텝': 1229, '해리': 1230, '포터': 1231, '마법사': 1232, '연합': 1233, '정식': 1234, '1장': 1235, '모델포스를': 1236, '가진': 1237, '분들은': 1238, '주목': 1239, '피팅모델': 1240, '삼성뮤직': 1241, '【10월': 1242, '26일': 1243, '세미나】circleci': 1244, '101': 1245, '첫걸음': 1246, '동북권ct이노베이션스퀘어': 1247, '정보와': 1248, '안전을': 1249, '지켜드립니다': 1250, '경비': 1251, 'uh': 1252, 'oh': 1253, 'might': 1254, 'be': 1255, 'chromecast와': 1256, 'now': 1257, '은': 1258, 'btc': 1259, 'etc': 1260, 'apt': 1261, '즐거운': 1262, '가득한': 1263, '축하': 1264, '상품권이': 1265, '2월호': 1266, '알바몬소식메일447호': 1267, '220104': 1268, 'gs': 1269, 'space': 1270, '설문조사에': 1271, '응하면': 1272, '커피쿠폰이': 1273, '구매해야': 1274, '안내문': 1275, '2분내': 1276, '신청하러': 1277, 'go': 1278, '참여자': 1279, '블리츠': 1280, '챔피언': 1281, '2025년도': 1282, 'yanges0603': 1283, '한국': 1284, '‘해피투더문’': 1285, '개인정보이용내역': 1286, '보험료': 1287, '너무': 1288, '비싸지': 1289, '않나요': 1290, 'march': 1291, 'check': 1292, '2024년도': 1293, '상품관리부터': 1294, '프로모션': 1295, '기획까지': 1296, '경험하고': 1297, 'md·쇼핑몰운영': 1298, '지식을': 1299, '나눠요': 1300, '강사': 1301, '겨울방학': 1302, 'sale': 1303, '노트북': 1304, '구매할': 1305, '절호의': 1306, '야구': 1307, '주소를': 1308, '이메일로': 1309, '추가했습니다': 1310, '탑툰을': 1311, '보는': 1312, '공개': 1313, '알바몬소식메일465호': 1314, '221011': 1315, '이미': 1316, '도착한': 1317, '미래': 1318, 'sf': 1319, '신작': 1320, '특선': 1321, '종료에': 1322, '정책을': 1323, 'caching': 1324, '최신컨텐츠': 1325, '157만': 1326, '17일': 1327, '차원이': 1328, '받기': 1329, '한국유저': 1330, '첫거래': 1331, '12월에도': 1332, '계속': 1333, '기업멤버십sw캠프': 1334, '멤버십기업': 1335, '도메인': 1336, '특화': 1337, '빅데이터': 1338, '개발자': 1339, '부트캠프': 1340, 'deep': 1341, 'dive': 1342, 'techniques': 1343, 'pipelines\\r': 1344, 'run': 1345, 'faster': 1346, '알바몬소식메일449호': 1347, '220125': 1348, \"'삼국블레이드'에\": 1349, 'are': 1350, 'changing': 1351, '메타몽': 1352, '동영상': 1353, '7eunsuk전용': 1354, 'sms': 1355, '피싱을': 1356, '예방하세요': 1357, 'workout데스런': 1358, '턱걸이50개': 1359, '갤럭시는': 1360, '역시': 1361, 'review': 1362, 'sign': 1363, '추석에는': 1364, '백화점상품권': 1365, '알바몬소식메일468호': 1366, '221129': 1367, '리디북스': 1368, 'hosting': 1369, 'platform': 1370, '오늘도': 1371, '벅차올랐다': 1372, '여섯': 1373, '덕후의': 1374, '행복한': 1375, '덕밍아웃': 1376, '어스라이크': 1377, '에서': 1378, 'enable': 1379, 'futures': 1380, 'contracts': 1381, 'trade': 1382, 'discover': 1383, 'what’s': 1384, '유': 1385, '전용상품권': 1386, '가격': 1387, '노트8': 1388, '8일간': 1389, '삼성닷컴에서': 1390, '물구나무를': 1391, '꾸준히': 1392, '서다보면': 1393, '해피': 1394, '할로윈': 1395, '사탕을': 1396, '경품으로': 1397, '바꿔보세요': 1398, '연령제한': 1399, '없이': 1400, '가능한': 1401, '패스트푸드점': 1402, '추첨': 1403, '2만원': 1404, '연휴에': 1405, '활발한': 1406, '십오야': 1407, '십오夜': 1408, '혜택받자': 1409, '보아라': 1410, '의견으로': 1411, '방법이': 1412, '없다면': 1413, 'defender': 1414, '승모근과': 1415, '목의': 1416, '통증': 1417, '해결법': 1418, '이달까지': 1419, '최대45': 1420, '최대127만': 1421, '상당혜택': 1422, '2022년에도': 1423, '저희와': 1424, '문상받으세요': 1425, '무료폰트까지': 1426, \"'gali\": 1427, \"run'\": 1428, '하드': 1429, '상품이': 1430, '발송되었습니다': 1431, 'j7': 1432, 'autograding': 1433, 'java': 1434, 'curriculum': 1435, 'address': 1436, \"week's\": 1437, 'monday': 1438, '추석맞이': 1439, 'starchaser': 1440, '알려드려요': 1441, '상반기분': 1442, '근로장려금': 1443, '9월1일부터': 1444, '19일까지': 1445, '신청하세요': 1446, '휴면정책': 1447, '운영정책': 1448, '플레이에서': 1449, '한글날': 1450, '모음전을': 1451, '엽니다': 1452, '오미세고': 1453, 'omg': 1454, '세럼': 1455, 'srm': 1456, 'access': 1457, 'game': 1458, '이력': 1459, 'daum': 1460, '원칙': 1461, '90개로': 1462, '전면': 1463, '측면': 1464, '후면': 1465, '삼각근': 1466, '뿌게기': 1467, \"'dynasty\": 1468, 'warriors': 1469, \"unleashed'에\": 1470, '제대로': 1471, '만난': 1472, 'onyx와': 1473, '펩시의': 1474, '등운동': 1475, 'evryplay': 1476, '계정을': 1477, '인증해주세요': 1478, '파기됨을': 1479, '구하셨나요': 1480, '알바천국이': 1481, '도와드릴게요': 1482, '구독이': 1483, '취소됩니다': 1484, '요모조모': 1485, '유용한': 1486, '앱을': 1487, '유가네': 1488, '닭갈비': 1489, '먹고': 1490, '1만원': 1491, 'fix': 1492, 'citations': 1493, 'word': 1494, 'docs': 1495, '일시': 1496, '중단': 1497, '8월22일': 1498, 'windows에서': 1499, '임무': 1500, 'kuro': 1501, 'mori': 1502, 'mine': 1503, 'tiger': 1504, '스토브': 1505, 'you’re': 1506, 'officially': 1507, 'part': 1508, 'community': 1509, '7월호': 1510, '슬로리딩': 1511, 'ppt': 1512, '늦어서': 1513, '미안해': 1514, 'ㅠㅠ': 1515, '알바몬소식메일462호': 1516, '220809': 1517, '이용내역의': 1518, 'notification': 1519, 'usage': 1520, 'personal': 1521, 'information': 1522, '명세서': 1523, '상품': 1524, '구입': 1525, 'teams': 1526, 'edu': 1527, 'leaves': 1528, 'beta': 1529, 'unit': 1530, 'testing': 1531, '내일': 1532, '‘트위치': 1533, '덕': 1534, '파티’가': 1535, '개최됩니다': 1536, '필수템': 1537, '앵그리버드': 1538, '에픽': 1539, '이제는': 1540, '입고': 1541, '다니는': 1542, '시대': 1543, 'wear': 1544, 'type': 1545, '62': 1546, '이유': 1547, '품절': 1548, '대란': 1549, '9월27일까지': 1550, '클라우드베리에': 1551, '저장되어': 1552, '백업해주세요': 1553, '6월은': 1554, '러버들': 1555, '모여랏': 1556, '귀여운': 1557, '득템의': 1558, '해제': 1559, '한국리서치에서': 1560, '공짜로': 1561, '안쓴': 1562, \"'클럽\": 1563, \"오디션'에\": 1564, '미션을': 1565, '완료하고': 1566, '스페셜': 1567, '리워드를': 1568, 'dropbox': 1569, '사회복지자원봉사': 1570, '03월호': 1571, 'vol': 1572, '079': 1573, 'unlimited': 1574, 'video': 1575, 'calling': 1576, '€23': 1577, '88': 1578, '문화상품권을': 1579, '삼쩜삼': 1580, '예스24': 1581, '예스24의': 1582, '회원이': 1583, '되신것을': 1584, 'sweeniz님이': 1585, '동영상을': 1586, '올렸습니다': 1587, '1천대': 1588, '지구를': 1589, '생각하는': 1590, '착한': 1591, '매달': 1592, '이야기가': 1593, '샘솟는': 1594, '이곳은': 1595, '신작을': 1596, '커뮤니티가': 1597, '기다리고': 1598, '있어요': 1599, 'abstract': 1600, 'making': 1601, '잠깐': 1602, '스토리지에': 1603, '중요한': 1604, '변경사항\\r': 1605, '8월을': 1606, '달궜던': 1607, '게임과': 1608, '보실래요': 1609, '적금': 1610, '금액': 1611, '상관없이': 1612, '개설': 1613, '프링글스': 1614, '36': 1615, '등장': 1616, '5개': 1617, '대체': 1618, '80마리': 1619, '이상의': 1620, '알아보세요': 1621, '★1월': 1622, '한정★': 1623, '순금': 1624, '골드바': 1625, '설치하면': 1626, '아이디어': 1627, '도출': 1628, '청구항': 1629, '작성법': 1630, 'p2p': 1631, '마켓': 1632, '원화': 1633, '해제됨': 1634, '스쿨': 1635, '연말연시에': 1636, '전용': 1637, '누려보세요': 1638, '혈액관리본부': 1639, '재동의': 1640, 'programming': 1641, 'results': 1642, 'achievement': 1643, 'hunting': 1644, '기출비': 1645, 'acadmey': 1646, 'ict이노베이션스퀘어': 1647, '취업클리닉': 1648, '현황을': 1649, '9월의': 1650, '기프트를': 1651, '준비해보세요': 1652, '유료서비스이용약관': 1653, '개정내역': 1654, '알바몬소식메일470호': 1655, '221227': 1656, \"'한국어를\": 1657, \"잘해요'라고\": 1658, '말할': 1659, '그날까지': 1660, '0개': 1661, '국어': 1662, '탈출': 1663, '함께해요': 1664, '이달의': 1665, '최저가도전': 1666, 'shop에서': 1667, '결제하고': 1668, 'weekly': 1669, '40': 1670, 'tv광고': 1671, '속의': 1672, '정부기관': 1673, '사칭': 1674, '스미싱': 1675, '363380': 1676, 'yogiyo에': 1677, '손님응대부터': 1678, '안전관리까지': 1679, '책임지는': 1680, '놀이공원': 1681, '테마파크': 1682, 'did': 1683, 'take': 1684, 'break': 1685, '라이엇': 1686, '자녀': 1687, '지인을': 1688, \"'sns피싱'을\": 1689, '기반': 1690, '발표': 1691, '후불결제': 1692, '제휴된': 1693, '연결은': 1694, '삼성이': 1695, '할게': 1696, '사용은': 1697, '누가': 1698, '할래': 1699, '생태계': 1700, 'build': 1701, 'own': 1702, 'adventure': 1703, '있으시죠': 1704, '가을맞이': 1705, '무료충전': 1706, '회원님이': 1707, '방금': 1708, '재설정하셨나요': 1709, '건강상태': 1710, '3만원': 1711, '설문참여하면': 1712, '통장에': 1713, '꽂히는': 1714, '미접속에': 1715, 'quantum2': 1716, '겨울에만': 1717, '스키장': 1718, '리디': 1719, '필요': 1720, '색다른': 1721, '사용처에서': 1722, '사용해보세요': 1723, '3일간의': 1724, '기프티콘': 1725, '루나': 1726, 'luna': 1727, '기다리던': 1728, 'hurloon': 1729, 'minotaur': 1730, 'advent': 1731, 'education': 1732, 'summary': 1733, '게임의': 1734, '윤종신': 1735, '과': 1736, '회색도시2': 1737, '삭제됩니다': 1738, '최고': 1739, '6개를': 1740, '베이직': 1741, 'manifest': 1742, 'miraculous': 1743, '끝이': 1744, '잡코리아': 1745, '강화하기': 1746, '한정판매': 1747, 'girls': 1748, 'und': 1749, 'panzer': 1750, 'pz': 1751, 'iv': 1752, 'anko': 1753, '전차를': 1754, '획득해': 1755, '보십시오': 1756, '엔플레이샵에서': 1757, 'save': 1758, 'date': 1759, 'zone': 1760, '연말선물로': 1761, 'stars': 1762, 'aligned': 1763, 'savings': 1764, '던파': 1765, '가이드': 1766, '갤럭시로': 1767, '통하는': 1768, '우리': 1769, '가족': 1770, '페스타에서': 1771, '득템데이': 1772, '0': 1773, '배송이': 1774, '초대장': 1775, '감사의': 1776, '특별하게': 1777, '전하는': 1778, '페스타와': 1779, '봄맞이': 1780, '혜택과': 1781, '이벤트가': 1782, '만개한': 1783, '갤캠스로': 1784, 'want': 1785, 'send': 1786, 'stellar': 1787, 'awesome': 1788, 'achievements': 1789, '회원탈퇴': 1790, '받을': 1791, '되신': 1792, '유출': 1793, '사실': 1794, 'ut': 1795, '갤캠스가': 1796, '쏜다': 1797, '찬스부터': 1798, '놓치면': 1799, '후회할걸': 1800, '파일캐스트에서': 1801, '사용한상품권': 1802, '활용하세요': 1803, 'red가': 1804, '한국에': 1805, '출시되었습니다': 1806, '폴드4': 1807, '오직': 1808, '일주일': 1809, '동안의': 1810, '한정판': 1811, 'juun': 1812, 'j': 1813, 'note10': 1814, 'discord용': 1815, 'improving': 1816, 'better': 1817, 'protect': 1818, '통합서비스약관': 1819, '남들보다': 1820, '빠르게': 1821, '알바를': 1822, '구하세요': 1823, '【notice】kucoin': 1824, '결제가': 1825, '몸짱이': 1826, '될수': 1827, '음식조절': 1828, '정리해': 1829, 'discord의': 1830, '클래스101': 1831, '과제': 1832, '커뮤니티에': 1833, '당신이': 1834, '필요해요': 1835, '교환하세요': 1836, 'store': 1837, '계약': 1838, 't다이렉트샵': 1839, '구매하고': 1840, '기기': 1841, '지식in': 1842, '더욱': 1843, '풍성해진': 1844, '갤캠데이부터': 1845, '놓칠': 1846, '없는': 1847, '신': 1848, '동네예보정보조회서비스': 1849, '청소년': 1850, '제19기': 1851, '기한연장': 1852, '응모하면': 1853, '아메리카노가': 1854, '채팅창에': 1855, '자리를': 1856, '마련해두었습니다': 1857, 'baekjoon': 1858, 'online': 1859, 'judge': 1860, '머슬업의': 1861, '모든것': 1862, '반동': 1863, '무반동': 1864, '슬로우': 1865, '까지': 1866, '배워보기': 1867, 'ways': 1868, 'speed': 1869, 'builds': 1870, '2023년도': 1871, '알바몬소식메일466호': 1872, '221101': 1873, 'k': 1874, 'mooc에': 1875, '재설정': 1876, '위치정보서비스': 1877, '회원에게만': 1878, 'amendments': 1879, '기본과정': 1880, '12일': 1881, 'sd': 1882, '탭s8': 1883, '4일': 1884, '어카운트의': 1885, '제공되었습니다': 1886, 'started': 1887, '08': 1888, '새소식을': 1889, '500명': 1890, '프린터': 1891, '소모품': 1892, '기프티콘을': 1893, '진행': 1894, '중': 1895, '아울렛에서': 1896, '알아': 1897, '클래식': 1898, '09': 1899, '9시': 1900, '기념': 1901, '쏟아지는': 1902, '추가모집': 1903, '비즈마켓에서': 1904, 'event': 1905, '마진': 1906, '무이자': 1907, '클릭': 1908, '번으로': 1909, 'facebook에': 1910, '로그인하세요': 1911, '삼성페이를': 1912, '등록해주셔서': 1913, '감사': 1914, '구매혜택과': 1915, '드디어': 1916, 's21': 1917, '전액': 1918, '면제': 1919, '갓': 1920, '나온': 1921, '현명한': 1922, '레알팜': 1923, 'expires': 1924, 'tonight': 1925, '【닌텐도': 1926, '어카운트】어카운트': 1927, '여름에만': 1928, '여름알바': 1929, '채용관': 1930, '3일에': 1931, '캐시충전하면': 1932, '2배': 1933, 'can': 1934, 'do': 1935, 'gpa': 1936, '가격이': 1937, '인상되는': 1938, '2일': 1939, '이전에': 1940, 'premium에': 1941, '9시간': 1942, '클래식의': 1943, '주인이': 1944, '되어보세요': 1945, 'secrets': 1946, 'blubbr': 1947, '【circleci】how': 1948, 'achieve': 1949, 'innovation': 1950, 'excellence': 1951, 'latest': 1952, 'report': 1953, '알바몬소식메일453호': 1954, '220405': 1955, '인증서를': 1956, '저장했습니다': 1957, '가능': 1958, '것': 1959, '아시나요': 1960, 'vip': 1961, '받았습니다': 1962, '알바몬소식메일458호': 1963, '220705': 1964, '채널': 1965, '선택하실': 1966, 'ぺにょ': 1967, '님이': 1968, '생방송': 1969, '중임': 1970, 'こんにちは': 1971, '이용이': 1972, '금액으로': 1973, '팬들이': 1974, '모든': 1975, '담은': 1976, 'series': 1977, 'unity': 1978, '힘이': 1979, '휴가비': 1980, '벌자': 1981, '대경권': 1982, '청년과학기술인': 1983, '일자리박람회': 1984, '3일간': 1985, '안써보셨어요': 1986, '고객님께만': 1987, '비밀': 1988, '출퇴근길': 1989, '발생하는': 1990, '갑작스러운': 1991, '지키세요': 1992, 'say': 1993, 'hello': 1994, 'world': 1995, 'into': 1996, 'flow': 1997, '띠링': 1998, '할인쿠폰이': 1999, '했습니다': 2000, '겟': 2001, 'not': 2002, 'seeing': 2003, '완벽한': 2004, '몸매': 2005, '준비하자': 2006, '2개월': 2007, '혜택에': 2008, '가입할': 2009, '기간이': 2010, '얼마': 2011, '남지': 2012, '않았습니다': 2013, '도전과제': 2014, 'us': 2015, 'securing\\r': 2016, '휴면회원': 2017, '맞춤': 2018, '구매혜택은': 2019, '몬스터볼': 2020, '패키지까지': 2021, '5월의': 2022, '소식': 2023, '마이통장으로': 2024, '알바몬소식메일454호': 2025, '220412': 2026, '현금이': 2027, '콜라보라해♥': 2028, '버즈프로': 2029, '라네즈': 2030, '네오쿠션': 2031, '시작합니다': 2032, '10일간': 2033, '변경사항': 2034, '지역에서의': 2035, 'call': 2036, 'submit': 2037, 'idea': 2038, '차원의': 2039, '승리를': 2040, '경험하세요': 2041, '만나고': 2042, 't다이렉트샵에서': 2043, '용돈벌자': 2044, '봄날에': 2045, '찾아온': 2046, 'set': 2047, 'integrations': 2048, 'continuous': 2049, 'deployment': 2050, 'with\\r': 2051, 'windows의': 2052, 'internet': 2053, 'explorer에서': 2054, '갤캠스에서': 2055, '모음': 2056, 'zip': 2057, 'permissions': 2058, '사람에게': 2059, '큰': 2060, '세상을': 2061, '선물해보세요': 2062, 'adobe': 2063, '공고를': 2064, '알바몬소식메일460호': 2065, '220726': 2066, '클래스메이트님': 2067, 'gemini에': 2068, '910916': 2069, '이용자': 2070, '만족도조사': 2071, 'updates': 2072, 'use': 2073, 'october': 2074, 'pdt': 2075, \"here's\": 2076, 'sneak': 2077, 'peek': 2078, 'at\\r': 2079, 'expect': 2080, '페이코인': 2081, 'pci': 2082, 'g마켓': 2083, '매월': 2084, '공간이': 2085, '필요합니다': 2086, '500포인트': 2087, 'hive': 2088, '분리저장': 2089, '웹툰': 2090, '보고': 2091, '4백원도': 2092, '샘플': 2093, '앱만의': 2094, '즐거움': 2095, '1500': 2096, '25': 2097, '아직도': 2098, '고통받고': 2099, '튀르키예': 2100, '지진피해': 2101, '주민들을': 2102, '선플달기에': 2103, '동참해': 2104, '2024': 2105, 'ħ': 2106, 'α': 2107, '당장': 2108, '버려야': 2109, '보험은': 2110, 'standing': 2111, 'strong': 2112, 'south': 2113, 'korea': 2114, 'gifts': 2115, '신청하면': 2116, '1천원': 2117, '연말연시': 2118, '각종': 2119, '디지털': 2120, '할인된': 2121, '가격에': 2122, '어디까지': 2123, '써봤니': 2124, '활용편': 2125, '아이디가': 2126, '06': 2127, '22': 2128, '휴면상태로': 2129, '됩니다': 2130, '매직서바이벌': 2131, '공식카페': 2132, '투썸플레이스': 2133, '보내세요': 2134, '설문하고': 2135, 'celebrating': 2136, '22년도': 2137, '3기': 2138, '중급': 2139, '노티드': 2140, '♡9천원': 2141, '추가로': 2142, '귀여움': 2143, '장착♡': 2144, '보이스룸': 2145, '구직자': 2146, '범죄': 2147, '방지를': 2148, '유의사항': 2149, 'to\\r': 2150, '성우': 2151, '김현지가': 2152, '알려주는': 2153, '【6484】닌텐도': 2154, '01회': 2155, '네트워크관리사': 2156, 'pc정비사': 2157, '지능형홈관리사': 2158, '영상정보관리사': 2159, '자격검정': 2160, '접수': 2161, '고민은': 2162, '배송만': 2163, '늦출': 2164, '뿐': 2165, '라이브': 2166, '43': 2167, '삐삐케이스': 2168, '공홈단독': 2169, '공동구매': 2170, 'experience': 2171, 'lightning': 2172, 'fast': 2173, 'ultra': 2174, 'browsing': 2175, 'devices': 2176, '방어': 2177, '매트릭스': 2178, '재사용': 2179, '대기시간': 2180, '감소': 2181, '올가을': 2182, 'premium을': 2183, '체험해': 2184, 'aws에서': 2185, '구축하는': 2186, '환경': 2187, 'hands': 2188, '메시지': 2189, 'social': 2190, '밤': 2191, '언팩': 2192, '행사로': 2193, '초대합니다': 2194, 'sk텔레콤': 2195, '안전한': 2196, \"'demong\": 2197, 'hunter': 2198, \"se'에\": 2199, 'ready': 2200, 'action': 2201, \"there's\": 2202, 'still': 2203, 'time': 2204, 'claim': 2205, 'plan': 2206, 'per': 2207, 'mega는': 2208, '당신을': 2209, '기다립니다': 2210, '교보문고에서': 2211, '2014': 2212, '브라질': 2213, '월드컵': 2214, '즐기자': 2215, 'upbit': 2216, '매주': 2217, '화요일에는': 2218, '위클리': 2219, '받아가세요♥': 2220, '찐': 2221, '유저라면': 2222, '만의': 2223, '특급혜택': 2224, '만나': 2225, '한국정보방송통신대연합': 2226, '인적자원개발위원회': 2227, 'isc': 2228, '주관으로': 2229, '새해': 2230, '인사를': 2231, '업데이트된': 2232, '약관에': 2233, '관해': 2234, '가성비': 2235, '끝판왕': 2236, '국민관광상품권을': 2237, '구매해보세요': 2238, '추석을': 2239, '맞아': 2240, '풍성한': 2241, '국가지식재산교육포털': 2242, 'h포인트': 2243, '전환하고': 2244, '시리즈on에서': 2245, '결제한': 2246, '안내해': 2247, '25일까지': 2248, '레벨': 2249, '달성': 2250, '블랙': 2251, '프라이데이': 2252, '알바몬소식메일455호': 2253, '220426': 2254, '카카오모빌리티': 2255, 't': 2256, '떴습니다': 2257, '514671은': 2258, '는': 2259, '코드입니다': 2260, 'win': 2261, '000': 2262, 'work': 2263, 'minecraft': 2264, '참여': 2265, '응원해': 2266, '꿈': 2267, '500만원': 2268, '여행상품권': 2269, '활기찬': 2270, '일상을': 2271, '갤럭시가': 2272, '응원합니다': 2273, '자유지상주의': 2274, '최준하': 2275, '작품': 2276, 'letter': 2277, 'care': 2278, 'about': 2279, 'trust': 2280, 'transparency': 2281, '컴퓨터로': 2282, '삼성월렛이': 2283, '2014년을': 2284, '빛낸': 2285, '본인확인이': 2286, '울트라': 2287, 'f2302030903050994': 2288, '또': 2289, '수집한': 2290, '수집출처등': 2291, '행거가': 2292, '무너졌다': 2293, '소비중독': 2294, '직장인의': 2295, '‘옷': 2296, '1년': 2297, '안': 2298, '사기': 2299, '프로젝트’': 2300, '성공할': 2301, '있을까요': 2302, '진로': 2303, '설계를': 2304, '부탁해': 2305, '구하자': 2306, '환경에서': 2307, '되었습니다': 2308, '5월호': 2309, '운전에': 2310, '자신이': 2311, '있다면': 2312, '통합회원가입이': 2313, '에브리타임': 2314, '플스게임': 2315, '이용하는': 2316, '알바몬소식메일463호': 2317, '220816': 2318, '리워드': 2319, '￦2750': 2320, '유저': 2321, '바우처': 2322, '획득을': 2323, '오늘만': 2324, 'hey': 2325, '힙한': 2326, '액세서리': 2327, '득템하자': 2328, '센스있게': 2329, '얻는': 2330, '방법은': 2331, '뭘까': 2332, '100만원': 2333, '이벤트★': 2334, '아이디에': 2335, '휴대기기가': 2336, '걱정': 2337, '없이도': 2338, '플레이할': 2339, '총집합': 2340, '품절대란템': 2341, '127만원': 2342, '혜택받고': 2343, 'get찬스': 2344, '대축제': 2345, '추석택배': 2346, '스미싱에': 2347, '양은석님에게만': 2348, '실시간': 2349, '도서부터': 2350, '어학까지': 2351, '자기개발도': 2352, '하자': 2353, '뒤가': 2354, '싸': 2355, '해지는': 2356, '여기는': 2357, '서늘한': 2358, '서점입니다': 2359, '리그': 2360, '오브': 2361, '레전드': 2362, '2분기': 2363, '농·축협': 2364, '널리': 2365, '들은': 2366, '아티스트를': 2367, '한달': 2368, '영화감상': 2369, '여행': 2370, '계획': 2371, '세워보세요': 2372, 'kb국민은행': 2373, '전설의': 2374, '레이드배틀': 2375, 'vod': 2376, '콘텐츠에': 2377, '관한': 2378, '변경의': 2379, '건': 2380, '알바몬소식메일456호': 2381, '220510': 2382, 'steam에': 2383, '타임라인을': 2384, '1일까지': 2385, 'band': 2386, '미접속자': 2387, '14일까지': 2388, 'introducing': 2389, 'kaboom': 2390, 'repls': 2391, '우티': 2392, '다쓴문상등록하면': 2393, '탑툰이': 2394, '스펙을': 2395, '높일': 2396, '꽃': 2397, '사무보조': 2398, 'ぺにょ님이': 2399, '생방송을': 2400, '시작했습니다': 2401, '풀템': 2402, '최단': 2403, '국내': 2404, '100만대': 2405, '돌파한': 2406, '노트10의': 2407, '매력은': 2408, '파티': 2409, '방송으로': 2410, '함께하세요': 2411, 'windows': 2412, 'keep': 2413, 'super': 2414, '무더운': 2415, '여름': 2416, '플레이와': 2417, '언어로': 2418, '업데이트하세요\\r': 2419, '구매하신': 2420, '상품의': 2421, '결제내역입니다': 2422, '릴레이특강·기본과정': 2423, '클라우드의': 2424, '약관이': 2425, '적용되었습니다': 2426, '휴면해제': 2427, '원서접수': 2428, '완료메일': 2429, 'made': 2430, '롯데멤버스': 2431, \"'23년\": 2432, 'pubc': 2433, 'looks': 2434, 'like': 2435, \"didn't\": 2436, '능력을': 2437, '향상시키고': 2438, '백화점': 2439, 'love': 2440, 'so': 2441, 'far': 2442, 'opinion': 2443, 'counts': 2444, '갤럭시엔': 2445, '버즈2를': 2446, 'ferpa': 2447, 'coppa': 2448, 'compliance': 2449, '알림메일입니다': 2450, '오': 2451, '늘': 2452, '마': 2453, '감': 2454, '한번': 2455, '오늘이': 2456, 'december': 2457, '카카오페이로': 2458, '17': 2459, '마이데이터': 2460, '개인신용정보': 2461, '전송내역': 2462, '죽도록': 2463, '운동하기': 2464, '싫은날': 2465, '턱걸이': 2466, '50개': 2467, '푸쉬업': 2468, '100개': 2469, '컬쳐랜드x호텔케니': 2470, '호텔케니': 2471, '예약하고': 2472, '여행가자': 2473, '시작은': 2474, '이력서': 2475, '작성부터입니다': 2476, '기자단': 2477, '뉴스레터를': 2478, '구독해': 2479, '2개월로': 2480, '길어진': 2481, '체험판을': 2482, '외국계': 2483, '기업에서': 2484, '일하고': 2485, '싶은': 2486, '사람': 2487, '21': 2488, '외투기업': 2489, '만남의': 2490, '날에서': 2491, '모이자': 2492, '도용': 2493, '발생': 2494, 'workflows': 2495, '갤러리': 2496, '장기미사용계정전환알림': 2497, '브라우저': 2498, '혹은': 2499, '기기로': 2500, '조사': 2501, '에어드랍': 2502, '사업자': 2503, '외': 2504, '첫': 2505, '기업탐방': 2506, '참석자': 2507, '결과보고서': 2508, '제출': 2509, 'yes30141': 2510, 'qa·테스터': 2511, '쌓고': 2512, 'qa·테스터·검증': 2513, '4조': 2514, '수탁업체': 2515, '전화번호': 2516, '가전제품의': 2517, '구매혜택': 2518, '대방출': 2519, '특별히': 2520, '마련한': 2521, '보따리': 2522, '9일에': 2523, '데이의': 2524, '거의': 2525, 'device': 2526, '전환하세요': 2527, '확인하기': 2528, '데드': 2529, '바이': 2530, '데이라이트': 2531, '쇼다운을': 2532, '대한민국의': 2533, '자랑스런': 2534, '인디게임을': 2535, '마이맥': 2536, '약관개정': 2537, '복구가': 2538, '1분내': 2539, '총상금': 2540, '1천3백만원': 2541, 'ucc공모전': 2542, '주제': 2543, '감정노동자': 2544, '배려': 2545, '도는': 2546, '언어문화': 2547, '개선': 2548, 'extended': 2549, '48': 2550, 'hours': 2551, '설날': 2552, '품절임박▶adidas기프트와': 2553, '신상컬러': 2554, '알바몬소식메일452호': 2555, '220322': 2556, '변경됩니다': 2557, '긴급재난지원금': 2558, '조회를': 2559, '클라우드': 2560, 'difficult': 2561, 'conversations': 2562, 'tone': 2563, 'suggestions': 2564, '도움이': 2565, '필요하시다면': 2566, '언제든지': 2567, '안내데스크·': 2568, '리셉션': 2569, '4월의': 2570, '갓생': 2571, '시작하기': 2572, '빠른': 2573, '때': 2574, '트릭스터m': 2575, '아이템매니아에서': 2576, '용돈': 2577, '벌어': 2578, '볼까': 2579, '구독하기': 2580, '시기': 2581, '대가족이': 2582, '되어주세요': 2583, '보도자료': 2584, '여야': 2585, '국회의원': 2586, '299명': 2587, '선플서명…올해': 2588, '선플상': 2589, '시상식': 2590, '빛냈다': 2591, '메이플스토리': 2592, '모험가': 2593, '리마스터': 2594, '게임이용내역': 2595, '지금이야말로': 2596, '얻기': 2597, '날': 2598, 'signs': 2599, '55': 2600, '【오늘': 2601, '개최】circleci': 2602, '세미나에서': 2603, 'cd를': 2604, '시작하는': 2605, '방법을': 2606, '배워봅시다': 2607, '진로상담은': 2608, '커리어넷에서': 2609, '11월호': 2610, '삭제되었습니다': 2611, '반값할인': 2612, '웹툰도': 2613, '보자': 2614, '♬': 2615, '수신거부': 2616, 'november': 2617, '10월에': 2618, '많은': 2619, '사랑을': 2620, '앱과': 2621, '할인돼요': 2622, '네': 2623, '여긴': 2624, '65': 2625, '기존': 2626, '휴면유저': 2627, '복귀': 2628, '개별': 2629, '카카오계정': 2630, '계좌개설하면': 2631, 'updating': 2632, '자신의': 2633, '타입에': 2634, '맞춰': 2635, '상태로': 2636, '무료건강검진': 2637, 'yes24': 2638, '★곧': 2639, '종료★': 2640, '올해': 2641, '삼성전자멤버십': 2642, '미이용': 2643, '고객': 2644, '분리': 2645, '보관': 2646, '가정의': 2647, '선물로': 2648, '7eunsuk님': 2649, '「부화장치」를': 2650, 'lg전자': 2651, '마음껏': 2652, '쇼핑을': 2653, '키움페이': 2654, '결제알림': 2655, '주식회사': 2656, '원포유': 2657, '내역입니다': 2658}\n",
      "등장횟수 :  odict_items([('cu', 1), ('3', 12), ('광고', 334), ('한정수량', 2), ('▶', 1), ('갤럭시', 66), ('버즈', 7), ('프로와', 2), ('아디다스', 2), ('오리지널스', 2), ('스페셜한', 1), ('패키지', 3), ('넥서스', 1), ('9', 6), ('출시', 3), ('g', 1), ('star에서', 1), ('만날', 2), ('수', 12), ('있는', 13), ('게임', 5), ('주말은', 3), ('구글플레이와', 1), ('함께', 12), ('도서', 2), ('세트', 1), ('할인', 17), ('롯데컬처웍스', 4), ('이용약관', 32), ('개정', 30), ('안내', 190), ('컬쳐랜드', 75), ('고객확인제도', 1), ('cdd', 1), ('edd', 1), ('상세', 1), ('티머니', 2), ('약관', 18), ('네이버파이낸셜', 3), ('혜택', 37), ('이벤트', 25), ('정보', 11), ('알림', 10), ('수신', 4), ('설정에', 1), ('대해', 2), ('안내드립니다', 17), ('한국발명진흥회', 10), ('동국대학교', 1), (\"'25학년도\", 1), ('전기', 1), ('지식재산학', 1), ('석사과정', 1), ('신입생', 1), ('모집', 6), ('홍보', 5), ('게토', 1), ('개인정보', 75), ('이용', 13), ('내역', 17), ('webinar', 12), ('today', 6), ('best', 2), ('in', 10), ('class', 2), ('ci', 15), ('cd', 13), ('an', 2), ('on', 11), ('prem', 2), ('environment', 2), ('내', 9), ('의견이', 5), ('문화상품권이', 4), ('되는', 6), ('공간', 2), ('활동적인', 1), ('경험을', 2), ('할', 4), ('여행·캠프·레포츠', 1), ('알바', 20), ('이용내역', 30), ('samsung', 2), ('galaxy', 15), ('note', 3), ('neo에서', 1), ('새로', 4), ('로그인', 14), ('생활', 1), ('속', 1), ('작은', 1), ('습관으로', 1), ('소중한', 4), ('개인정보를', 1), ('보호하세요', 1), ('re', 2), ('자', 1), ('잘가라', 1), ('수험생', 2), ('만점', 2), ('종료까지', 1), ('d', 8), ('4', 6), ('패널나우', 1), ('설문', 4), ('참여하고', 7), ('포인트', 7), ('받으세요', 20), ('신학기에', 1), ('꼭', 1), ('필요한', 5), ('혜택만', 1), ('모아', 2), ('more', 6), ('2022', 12), ('new', 11), ('북', 2), ('아카데미', 6), ('대세는', 1), ('폴더블', 1), ('z', 6), ('flip', 1), ('lte', 1), ('보상', 2), ('받고', 7), ('구매', 7), ('하는', 2), ('법', 1), ('대학생이라면', 1), ('캠퍼스', 13), ('스토어에서', 1), ('할인받고', 1), ('구매하세요', 4), ('문화상품권', 41), ('설문조사하고', 3), ('얼마든지', 1), ('가져가세요', 1), ('페이코인에서', 1), ('회원가입하고', 2), ('받아가세요', 16), ('2019', 4), ('창의발명교육', 1), ('체험수기', 1), ('공모전', 6), ('계좌개설', 1), ('시', 9), ('즉시', 6), ('지급', 17), ('다쓴상품권으로', 1), ('웹하드', 7), ('무료', 8), ('이용하세요', 5), ('google', 59), ('play', 40), ('주문', 39), ('영수증', 37), ('5', 9), ('1', 8), ('ip', 13), ('academy', 9), ('school', 1), ('수강수료', 1), ('11', 13), ('30', 6), ('cloudberry', 1), ('용량이', 1), ('추가되었습니다', 2), ('신규', 9), ('찐플에서', 2), ('다쓴문상', 3), ('이벤트를', 3), ('참여해', 2), ('보세요', 22), ('컬쳐랜드x파일썬', 2), ('단돈', 2), ('100원으로', 2), ('30일', 1), ('무제한', 4), ('영화감상하세요', 1), ('누군가가', 7), ('여러분의', 7), ('facebook', 3), ('에', 8), ('접근하려', 6), ('합니다', 6), ('네이버', 12), ('mybox', 3), ('서비스', 18), ('변경', 23), ('휴면', 9), ('처리', 2), ('정책', 7), ('입금', 2), ('400', 2), ('usdt', 2), ('선물', 6), ('체험', 3), ('펀드', 1), ('증정', 12), ('연말', 7), ('크리스마스', 2), ('시즌', 3), ('피싱에', 1), ('대비하는', 1), ('방법', 12), ('3가지', 2), ('100', 11), ('국비지원', 1), ('무료상담', 2), ('교육자료', 1), ('14종', 1), ('nh투자', 1), ('계좌통합관리서비스', 1), ('개정안내', 2), ('sns', 3), ('및', 25), ('문자를', 3), ('통한', 1), ('메신저', 1), ('피싱', 3), ('주의하세요', 4), ('네이버페이', 7), ('적립', 6), ('방식', 2), ('일부', 2), ('미사용', 2), ('보유잔액', 1), ('원스토리', 2), ('이용내역을', 12), ('드립니다', 20), ('라이엇게임즈', 2), ('이메일', 8), ('인증번호', 3), ('637868', 1), ('★구글', 2), ('플레이', 4), ('리니지', 1), ('위크', 1), ('기념★', 1), ('최대', 20), ('지원받고', 1), ('구글', 9), ('기프트', 5), ('코드', 5), ('epic', 2), ('games', 2), ('email', 3), ('verification', 2), ('미투디스크야', 1), ('줄게', 1), ('다오', 1), ('한국갤럽에서', 2), ('설문조사', 8), ('모빌리티', 1), ('자율주행', 1), ('교육과정', 9), ('새로운', 22), ('기기가', 1), ('위치', 1), ('기록에', 1), ('반영되고', 1), ('있습니다', 2), ('yes6815', 4), ('dothome', 1), ('co', 1), ('kr', 1), ('양은석님', 8), ('입학원서', 1), ('접수가', 1), ('완료되었습니다', 9), ('대성마이맥', 4), ('장기', 4), ('미', 2), ('이용으로', 1), ('인해', 1), ('양은석님의', 4), ('개인정보가', 2), ('별도', 1), ('보관됨을', 1), ('twitch에', 1), ('오신', 3), ('것을', 4), ('환영합니다', 12), ('twitch', 9), ('트위치', 5), ('라이벌스', 4), ('하스스톤', 1), ('쇼다운이', 1), ('시작됩니다', 1), ('언제나', 1), ('꿈꿔온', 1), ('note20', 1), ('사전', 12), ('판매', 5), ('여기', 1), ('지금', 25), ('시작되었어♪', 1), ('스토어', 11), ('사전판매', 7), ('8', 5), ('16일', 1), ('open', 4), ('학생이라면', 1), ('교육할인과', 1), ('추가혜택도', 1), ('방송에', 1), ('관심이', 1), ('많았던', 1), ('분이라면', 1), ('방송스텝', 1), ('·', 11), ('촬영보조', 1), ('해피머니', 9), ('해피캐시', 1), ('보유한도', 1), ('campus', 7), ('11월', 2), ('오프라인', 5), ('특강', 1), ('포함', 2), ('양은석', 10), ('고객님', 9), ('드라마', 1), ('무료로', 9), ('원스토어', 11), ('전자금융거래약관', 2), ('통신과금서비스', 1), ('circleci', 20), ('github', 18), ('a', 9), ('third', 3), ('party', 4), ('application', 3), ('has', 3), ('been', 3), ('added', 3), ('to', 27), ('your\\r', 2), ('account', 4), ('kakao', 6), ('카카오', 6), ('전자금융거래', 9), ('experiment', 1), ('with', 7), ('projects', 1), ('youtube에', 1), ('핸들이', 1), ('도입됩니다', 1), ('간단한', 4), ('보호', 1), ('방법으로', 2), ('컬쳐캐쉬를', 4), ('안전하게', 2), ('사용하세요', 1), ('영남대학교', 3), ('도서관', 5), ('안내서', 2), ('04', 1), ('24', 4), ('경품', 3), ('start', 3), ('집콕하면서', 1), ('문화상품권으로', 12), ('스마트하게', 2), ('쇼핑하는', 1), ('타임라인', 1), ('데이터를', 2), ('유지하시겠습니까', 2), ('서둘러', 1), ('결정해', 2), ('주세요', 5), ('join', 2), ('the', 12), ('practical', 2), ('tips', 5), ('tricks', 5), ('for', 19), ('securing', 1), ('your', 27), ('cd\\r', 1), ('pipelines', 3), ('투믹스', 1), ('리니지w', 2), ('오픈', 3), ('세상은', 1), ('넓고', 1), ('아이템매니아', 2), ('혜택은', 3), ('많다', 1), ('삼성페이', 2), ('수집', 10), ('출처', 10), ('고지', 6), ('올', 1), ('여름을', 2), ('뜨겁게', 3), ('달군', 1), ('앱', 10), ('게임을', 3), ('만나보세요', 15), ('알바천국', 15), ('알바자리', 1), ('싹', 1), ('다', 3), ('찾는', 1), ('mega', 13), ('설치', 1), ('보너스', 2), ('공지', 7), ('해머', 1), ('유효기간', 1), ('경과에', 1), ('따른', 10), ('해머소멸', 1), ('굽자', 1), ('complete', 1), ('privacy', 3), ('checkup', 1), ('현금', 4), ('받자', 6), ('2', 16), ('16', 2), ('에베베베', 1), ('문화생활도', 1), ('알바도', 1), ('한번에', 1), ('영화관', 1), ('공연', 1), ('oauth', 2), ('회원들만', 1), ('드리는', 2), ('100원', 1), ('아카데미에서', 1), ('풀템으로', 1), ('마음을', 2), ('전하세요', 1), ('we', 4), ('miss', 2), ('you', 9), ('make', 2), ('sure', 1), (\"you're\", 1), ('logged', 2), ('여름맞이', 1), ('탑툰', 4), ('무료코인', 2), ('의견', 1), ('내고', 1), ('교환해', 3), ('지', 1), ('금', 1), ('이순간', 1), ('필요하다면', 1), ('굽자님의', 11), ('6월', 2), ('업데이트', 18), ('북2', 7), ('시리즈', 8), ('런칭', 7), ('4월', 4), ('혜택을', 5), ('시리즈온', 2), ('시리즈온에서', 2), ('멤버십', 2), ('콘텐츠', 2), ('종료를', 1), ('2023년', 1), ('다쓴문상으로', 2), ('공짜', 5), ('영화보세요', 1), ('repl', 12), ('it', 12), ('newsletter', 16), ('language', 2), ('jam', 2), ('submissions', 1), ('버즈2', 7), ('프로', 4), ('기본', 3), ('이젠', 1), ('중고', 1), ('혜택까지', 1), ('filesun에서', 1), ('다쓴', 1), ('10만', 1), ('포인트로', 1), ('고기먹고싶은디님', 5), ('놀러', 2), ('오세요', 3), ('게임만해도', 1), ('000원', 6), ('문상', 7), ('2021', 28), ('10', 11), ('13', 4), ('설문조사로', 4), ('편하게', 1), ('돈벌자', 1), ('엠브레인', 8), ('7월', 2), ('가입하면', 5), ('누구나', 3), ('500원', 5), ('네이버웹툰', 8), ('탭', 1), ('s8', 2), ('제안', 1), ('구매하기', 1), ('좋은', 4), ('이유를', 2), ('한눈에', 2), ('필요한데', 3), ('얻을', 3), ('없을까', 2), ('vms', 3), ('뉴스레터', 6), ('8월호', 2), ('l', 4), ('point', 4), ('회원가입을', 4), ('축하합니다', 1), ('이벤트에', 1), ('당첨', 1), ('되셨습니다', 4), ('gs건설', 1), ('자이', 1), ('커리어넷', 5), ('만족도', 2), ('조사에', 1), ('참여하세요', 2), ('10월', 7), ('31일까지', 1), ('최신', 4), ('컨텐츠', 4), ('임시비밀번호가', 1), ('발급되었습니다', 2), ('홈페이지', 1), ('수정에서', 1), ('비밀번호를', 2), ('수정하세요', 1), ('15만원', 2), ('쿠폰', 7), ('도착', 3), ('아직', 2), ('못받으셨나요', 1), ('컬쳐캐쉬', 11), ('페이백', 2), ('서둘러서', 1), ('2021년도', 3), ('청소년발명기자단', 3), ('세상을바꾸는', 1), ('시간', 1), ('15분', 2), ('강연자', 1), ('모집안내', 3), ('중요', 4), ('공지사항', 1), ('계정', 28), ('관련', 6), ('바리스타', 1), ('경력을', 1), ('쌓아보세요', 1), ('커피전문점', 1), ('갤럭시끼리', 1), ('만나면', 1), ('환상의', 1), ('호흡', 1), ('♥', 4), ('buds2', 1), ('특별한', 5), ('컬쳐캐쉬로', 3), ('h', 4), ('point전환', 1), ('6', 12), ('추가', 6), ('국민관광상품권으로', 1), ('쇼핑', 1), ('외식', 2), ('관광을', 1), ('즐겨보세요', 3), ('4에서', 1), ('네이버에서', 1), ('쇼핑하세요', 1), ('유웨이어플라이', 1), ('데이터', 2), ('삭제', 4), ('알바몬소식메일457호', 1), ('220607', 1), ('회원이라면', 1), ('3천원', 5), ('페이백을', 1), ('payments', 4), ('사용자', 2), ('정보가', 2), ('변경되었습니다', 5), ('월간컬쳐랜드', 5), ('1월호', 2), ('아프리카tv', 2), ('분리보관', 1), ('예정', 4), ('메일', 5), ('입니다', 2), ('배달의민족', 5), ('제공', 7), ('절찬', 1), ('4백원', 1), ('구글플레이에서', 1), ('이번', 4), ('주말', 1), ('더위를', 1), ('날려버리세요', 1), ('월간', 12), ('6월호', 1), ('website', 1), ('stats', 5), ('and', 21), ('project', 1), ('sharing', 1), ('전자', 1), ('주소', 5), ('확인', 5), ('월동', 1), ('준비', 3), ('이제', 3), ('모바일로', 1), ('편리하게', 1), ('하세요', 2), ('소프라노몰', 3), ('님', 2), ('내역을', 3), ('알려드립니다', 2), ('마감', 3), ('임박', 2), ('ip아카데미', 3), ('ip스쿨', 1), ('수강후기', 2), ('굽자님', 9), ('앱으로', 2), ('note9', 1), ('설정을', 9), ('완료하세요', 7), ('삼성계정에', 1), ('채팅창이', 1), ('기다려요', 1), ('android', 7), (\"'의천도룡기\", 1), (\"kakao'에\", 1), ('작성한', 5), ('댓글에', 5), ('대한', 7), ('답변', 5), ('smart5', 1), ('특허정보분석시스템', 1), ('교육', 7), ('유료', 5), ('9월호', 3), ('갤럭시를', 1), ('가장', 8), ('먼저', 6), ('준비되셨나요', 1), ('8월', 3), ('10일', 1), ('마침내', 1), ('로드모바일', 2), ('아이템', 1), ('12월', 4), ('5일부터', 1), ('7일까지', 1), ('어떤', 1), ('내용의', 1), ('방송이', 1), ('진행되나요', 1), ('replit', 8), ('chat', 1), ('apps', 2), ('user', 1), ('더', 7), ('받는', 2), ('역대급', 4), ('2022년도', 2), ('최저임금', 4), ('알바몬소식메일448호', 1), ('220118', 1), ('upcoming', 5), ('moving', 2), ('from', 8), ('jenkins', 4), ('실전', 1), ('기술이전', 1), ('라이센싱', 1), ('계약서', 1), ('작성', 2), ('cj', 6), ('one', 6), ('2025', 1), ('01', 2), ('시행', 1), ('t아이디', 3), ('2020년', 1), ('통지', 8), ('battle', 3), ('net', 3), ('인증', 7), ('갤럭시s21', 1), ('get', 8), ('21만원', 1), ('상당', 4), ('개학', 2), ('전', 1), ('마지막', 3), ('기회', 4), ('72만원', 1), ('혜택의', 1), ('5g', 3), ('최초', 1), ('자동납부', 1), ('3만', 1), ('6천원', 1), ('2020', 8), ('7', 4), ('에픽게임즈', 2), ('계정에', 1), ('nintendo', 1), ('연결', 1), ('완료', 6), ('riot', 1), ('카카오페이', 6), ('기프트카드', 1), ('구매취소', 1), ('캐쉬', 1), ('환불', 2), ('패널모집', 3), ('상상력을디자인하는동화쓰기', 1), ('김기호님', 1), ('이', 2), ('보냈습니다', 1), ('컬쳐랜드와', 2), ('공식', 2), ('제휴한', 1), ('파일썬에서', 3), ('사용한', 5), ('상품권으로', 3), ('영화', 2), ('mobile', 5), ('development', 5), ('알바몬소식메일464호', 1), ('220906', 1), ('3월', 4), ('새학기', 1), ('대학생을', 2), ('위해', 1), ('스토어가', 1), ('준비한', 2), ('컬러부터', 1), ('기능', 3), ('그리고', 1), ('가격까지', 1), ('뛰어난', 1), ('s20', 3), ('fe', 2), ('50', 2), ('off', 3), ('ends', 1), ('don’t', 1), ('press', 1), ('luck', 1), ('스마트한', 1), ('소비', 2), ('갤', 2), ('캠', 2), ('스', 2), ('가입은', 1), ('필수', 2), ('건강', 1), ('습관', 1), ('챌린지', 1), ('이벤트도', 1), (\"don't\", 1), ('out', 5), ('upgrade', 2), ('200', 2), ('gb', 5), ('of', 11), ('storage', 3), ('only', 1), ('€2', 1), ('99', 5), ('month', 3), ('영남대', 1), ('m365', 1), ('office', 1), ('365', 1), ('용량', 1), ('제한', 1), ('졸업생', 1), ('단기알바도', 1), ('재밌게', 1), ('행사스텝', 1), ('kucoin', 6), ('code', 2), ('기기에서', 3), ('18', 2), ('해리', 1), ('포터', 1), ('마법사', 1), ('연합', 1), ('정식', 1), ('1장', 1), ('모델포스를', 1), ('가진', 1), ('분들은', 1), ('주목', 1), ('피팅모델', 1), ('삼성뮤직', 1), ('사항', 2), ('【10월', 1), ('26일', 1), ('온라인', 4), ('세미나】circleci', 1), ('101', 1), ('첫걸음', 1), ('동북권ct이노베이션스퀘어', 1), ('인증번호가', 2), ('도착하였습니다', 2), ('정보와', 1), ('안전을', 1), ('지켜드립니다', 1), ('보안', 8), ('경비', 1), ('uh', 1), ('oh', 1), ('might', 1), ('be', 1), ('chromecast와', 1), ('universe', 5), ('schedule', 2), ('is', 6), ('now', 1), ('live', 4), ('은', 1), ('btc', 1), ('etc', 1), ('apt', 1), ('수수료', 5), ('0원', 2), ('양', 3), ('석님', 3), ('즐거운', 1), ('혜택이', 2), ('가득한', 1), ('가입을', 4), ('가입', 8), ('축하', 1), ('쿠폰을', 2), ('확인하세요', 5), ('상품권이', 1), ('2월호', 1), ('알바몬소식메일447호', 1), ('220104', 1), ('gs', 1), ('space', 1), ('통지문', 3), ('설문조사에', 1), ('응하면', 1), ('커피쿠폰이', 1), ('폴드4｜z', 2), ('플립4', 3), ('구매해야', 1), ('확인해보세요', 3), ('삼성계정', 4), ('마케팅', 4), ('수신동의', 6), ('정기', 4), ('안내문', 1), ('5천원', 10), ('2분내', 1), ('12', 10), ('신청하러', 1), ('go', 1), ('참여자', 1), ('전원', 5), ('2천원', 3), ('블리츠', 1), ('게임즈', 2), ('챔피언', 1), ('2025년도', 1), ('yanges0603', 1), ('gmail', 2), ('com', 3), ('쿠코인', 2), ('한국', 1), ('‘해피투더문’', 1), ('넥슨', 7), ('개인정보이용내역', 1), ('보험료', 1), ('너무', 1), ('비싸지', 1), ('않나요', 1), ('satellite', 2), ('india', 2), ('march', 1), ('26', 5), ('27', 2), ('check', 1), ('2024년도', 1), ('상품관리부터', 1), ('프로모션', 1), ('기획까지', 1), ('경험하고', 1), ('싶다면', 4), ('md·쇼핑몰운영', 1), ('닌텐도', 2), ('어카운트', 2), ('지식을', 1), ('나눠요', 1), ('강사', 1), ('겨울방학', 1), ('특가', 2), ('sale', 1), ('노트북', 1), ('구매할', 1), ('절호의', 1), ('찬스', 2), ('play와', 3), ('야구', 1), ('즐기세요', 2), ('주소를', 1), ('복구', 2), ('이메일로', 1), ('추가했습니다', 1), ('탑툰을', 1), ('보는', 1), ('공개', 1), ('알바몬소식메일465호', 1), ('221011', 1), ('이미', 1), ('도착한', 1), ('미래', 1), ('우주라이크소설', 2), ('sf', 1), ('신작', 1), ('특선', 1), ('종료에', 1), ('정책을', 1), ('caching', 1), ('회원님', 3), ('최신컨텐츠', 1), ('카카오페이지', 6), ('전환', 9), ('157만', 1), ('알아보기', 3), ('결제', 3), ('메일입니다', 2), ('17일', 1), ('coming', 2), ('soon', 2), ('차원이', 1), ('다른', 2), ('사전알림', 2), ('신청하고', 2), ('받기', 1), ('한국유저', 1), ('첫거래', 1), ('12월에도', 1), ('계속', 1), ('2022년', 5), ('기업멤버십sw캠프', 1), ('멤버십기업', 1), ('도메인', 1), ('특화', 1), ('빅데이터', 1), ('활용', 4), ('개발자', 1), ('부트캠프', 1), ('final', 2), ('reminder', 2), ('deep', 1), ('dive', 1), ('techniques', 1), ('pipelines\\r', 1), ('run', 1), ('faster', 1), ('모바일', 3), ('쿠폰이', 3), ('업비트', 3), ('알바몬소식메일449호', 1), ('220125', 1), (\"'삼국블레이드'에\", 1), ('terms', 5), ('service', 3), ('are', 1), ('changing', 1), ('이용해', 3), ('메타몽', 1), ('포켓몬', 6), ('동영상', 1), ('트레이너', 2), ('7eunsuk전용', 1), ('sms', 1), ('피싱을', 1), ('예방하세요', 1), ('유료서비스', 2), ('deslun', 8), ('workout데스런', 1), ('채널의', 8), (\"'\", 16), ('데스런', 15), ('집에서', 2), ('영상보며', 2), ('같이하는', 2), ('맨몸운동', 2), ('프로그램', 3), ('맨몸운동루틴', 2), ('턱걸이50개', 1), ('갤럭시는', 1), ('역시', 1), ('please', 3), ('review', 1), ('this', 2), ('sign', 1), ('추석에는', 1), ('백화점상품권', 1), ('어떠세요', 2), ('ict', 9), ('cog', 9), ('알바몬소식메일468호', 1), ('221129', 1), ('리디북스', 1), ('회원가입', 2), ('announcing', 2), ('hosting', 1), ('platform', 1), ('always', 2), ('오늘도', 1), ('벅차올랐다', 1), ('★', 2), ('여섯', 1), ('덕후의', 1), ('행복한', 1), ('덕밍아웃', 1), ('스토리', 3), ('어스라이크', 1), ('에서', 1), ('enable', 1), ('futures', 1), ('contracts', 1), ('trade', 1), ('discover', 1), ('what’s', 1), ('at', 3), ('유', 1), ('전용상품권', 1), ('가격', 1), ('삼성닷컴', 10), ('노트8', 1), ('삼성카드', 3), ('청구할인', 3), ('혜택으로', 6), ('단', 5), ('8일간', 1), ('삼성닷컴에서', 1), ('workout', 7), ('물구나무를', 1), ('꾸준히', 1), ('서다보면', 1), ('해피', 1), ('할로윈', 1), ('사탕을', 1), ('경품으로', 1), ('바꿔보세요', 1), ('연령제한', 1), ('없이', 1), ('도전', 2), ('가능한', 1), ('패스트푸드점', 1), ('23', 4), ('추첨', 1), ('2만원', 1), ('명절', 2), ('연휴에', 1), ('활발한', 1), ('조심하세요', 3), ('회원가입이', 3), ('십오야', 1), ('십오夜', 1), ('혜택받자', 1), ('설', 2), ('맞이', 3), ('지식재산', 2), ('영상을', 2), ('보아라', 1), ('알려라', 2), ('의견으로', 1), ('선착순', 4), ('방법이', 1), ('없다면', 1), ('defender', 1), ('승모근과', 1), ('목의', 1), ('통증', 1), ('해결법', 1), ('삼성닷컴단독', 2), ('이달까지', 1), ('전자제품', 4), ('최대45', 1), ('최대127만', 1), ('상당혜택', 1), ('youmake', 3), ('프로젝트', 4), ('2022년에도', 1), ('저희와', 1), ('문상받으세요', 1), ('경품과', 2), ('무료폰트까지', 1), (\"'gali\", 1), (\"run'\", 1), ('분할합병에', 2), ('이전', 2), ('경고', 2), ('웹', 2), ('하드', 1), ('상품이', 1), ('발송되었습니다', 1), ('1월', 2), ('google을', 2), ('사용해', 2), ('j7', 1), ('2016', 2), ('discord', 2), ('bots', 2), ('autograding', 1), ('java', 1), ('curriculum', 1), ('verify', 2), ('address', 1), ('just', 4), (\"week's\", 1), ('cyber', 2), ('monday', 1), ('offer', 3), ('nh투자증권', 2), ('후', 3), ('조사하면', 2), ('추석맞이', 1), ('선물까지', 2), ('starchaser', 1), ('쉿', 2), ('쉽게', 2), ('알려드려요', 1), ('2024년', 6), ('상반기분', 1), ('근로장려금', 1), ('9월1일부터', 1), ('19일까지', 1), ('신청하세요', 1), ('개정에', 3), ('휴면정책', 1), ('운영정책', 1), ('플레이에서', 1), ('한글날', 1), ('특별', 5), ('모음전을', 1), ('엽니다', 1), ('거래', 4), ('오미세고', 1), ('omg', 1), ('세럼', 1), ('srm', 1), ('거래지원', 4), ('종료', 5), ('access', 1), ('game', 1), ('이력', 1), ('daum', 1), ('카페', 2), ('운영', 2), ('원칙', 1), ('바로', 8), ('오늘', 3), ('176만', 2), ('상당의', 3), ('시작', 7), ('딱', 7), ('90개로', 1), ('전면', 1), ('측면', 1), ('후면', 1), ('삼각근', 1), ('뿌게기', 1), (\"'dynasty\", 1), ('warriors', 1), (\"unleashed'에\", 1), ('제대로', 1), ('만난', 1), ('콜라보', 3), ('onyx와', 1), ('펩시의', 1), ('만남', 2), ('5월', 8), ('한정', 3), ('등운동', 1), ('evryplay', 1), ('계정을', 1), ('인증해주세요', 1), ('파기됨을', 1), ('구하셨나요', 1), ('알바천국이', 1), ('도와드릴게요', 1), ('구독이', 1), ('취소됩니다', 1), ('요모조모', 1), ('유용한', 1), ('앱을', 1), ('유가네', 1), ('닭갈비', 1), ('먹고', 1), ('1만원', 1), ('이용권', 2), ('fix', 1), ('citations', 1), ('word', 1), ('docs', 1), ('일시', 1), ('중단', 1), ('8월22일', 1), ('확인하여', 2), ('windows에서', 1), ('다음', 2), ('단계를', 2), ('진행하세요', 2), ('임무', 1), ('kuro', 1), ('mori', 1), ('mine', 1), ('tiger', 1), ('i', 2), ('스토브', 1), ('you’re', 1), ('officially', 1), ('part', 1), ('community', 1), ('7월호', 1), ('슬로리딩', 1), ('ppt', 1), ('늦어서', 1), ('미안해', 1), ('ㅠㅠ', 1), ('알바몬소식메일462호', 1), ('220809', 1), ('캐쉬백', 3), ('galaxy를', 2), ('만나는', 4), ('4월호', 2), ('이용내역의', 1), ('notification', 1), ('usage', 1), ('personal', 1), ('information', 1), ('명세서', 1), ('상품', 1), ('구입', 1), ('teams', 1), ('edu', 1), ('leaves', 1), ('beta', 1), ('unit', 1), ('testing', 1), ('내일', 1), ('‘트위치', 1), ('구스', 2), ('덕', 1), ('추석', 2), ('파티’가', 1), ('개최됩니다', 1), ('필수템', 1), ('를', 4), ('youtube', 10), ('앵그리버드', 1), ('에픽', 1), ('이제는', 1), ('입고', 1), ('다니는', 1), ('시대', 1), ('wear', 1), ('type', 1), ('62', 1), ('이유', 1), ('품절', 1), ('대란', 1), ('워치4', 4), ('확인하고', 3), ('2021년', 7), ('9월27일까지', 1), ('클라우드베리에', 1), ('저장되어', 1), ('고객님의', 4), ('백업해주세요', 1), ('6월은', 1), ('캐릭터', 2), ('데이', 3), ('러버들', 1), ('모여랏', 1), ('귀여운', 1), ('에디션', 3), ('득템의', 1), ('요기요', 3), ('해제', 1), ('증권플러스', 3), ('한국리서치에서', 1), ('찐플', 2), ('공짜로', 1), ('이용하고', 3), ('안쓴', 1), ('인공지능', 5), ('교육생', 3), (\"'클럽\", 1), (\"오디션'에\", 1), ('미션을', 1), ('완료하고', 1), ('스페셜', 1), ('리워드를', 1), ('dropbox', 1), ('개인정보처리방침', 4), ('사회복지자원봉사', 1), ('03월호', 1), ('vol', 1), ('079', 1), ('vpn', 3), ('unlimited', 1), ('video', 1), ('calling', 1), ('€23', 1), ('88', 1), ('year', 2), ('문화상품권을', 1), ('15', 3), ('삼쩜삼', 1), ('예스24', 1), ('예스24의', 1), ('회원이', 1), ('되신것을', 1), ('축하드립니다', 3), ('sweeniz님이', 1), ('동영상을', 1), ('올렸습니다', 1), ('광고성', 8), ('정보수신', 3), ('동의', 7), ('1천대', 1), ('지구를', 1), ('생각하는', 1), ('착한', 1), ('매달', 1), ('이야기가', 1), ('샘솟는', 1), ('이곳은', 1), ('9월', 4), ('신작을', 1), ('커뮤니티가', 1), ('기다리고', 1), ('있어요', 1), ('abstract', 1), ('data', 2), ('making', 1), ('languages', 2), ('잠깐', 1), ('스토리지에', 1), ('중요한', 1), ('변경사항\\r', 1), ('8월을', 1), ('달궜던', 1), ('게임과', 1), ('보실래요', 1), ('금리', 2), ('적금', 1), ('금액', 1), ('상관없이', 1), ('개설', 1), ('프링글스', 1), ('커버', 2), ('36', 1), ('등장', 1), ('등', 2), ('5개', 1), ('공공데이터포털', 2), ('기상청', 2), ('오픈api', 3), ('폐기', 3), ('대체', 1), ('7eunsuk', 2), ('80마리', 1), ('이상의', 1), ('자세히', 2), ('알아보세요', 1), ('★1월', 1), ('한정★', 1), ('가입하고', 2), ('2500원', 4), ('순금', 1), ('골드바', 1), ('설치하면', 1), ('상품권도', 2), ('드려요', 2), ('아이디어', 1), ('도출', 1), ('청구항', 1), ('작성법', 1), ('p2p', 1), ('마켓', 1), ('원화', 1), ('해제됨', 1), ('외국어', 2), ('능력자에겐', 2), ('꿀알바', 5), ('번역', 2), ('통역', 2), ('스쿨', 1), ('연말연시에', 1), ('회원', 4), ('전용', 1), ('누려보세요', 1), ('혈액관리본부', 1), ('회원정보', 2), ('재동의', 1), ('programming', 1), ('results', 1), ('achievement', 1), ('hunting', 1), ('3월호', 2), ('축하드려요', 3), ('기출비', 1), ('카페에', 3), ('acadmey', 1), ('동북권', 2), ('ict이노베이션스퀘어', 1), ('취업클리닉', 1), ('현황을', 1), ('9월의', 1), ('기프트를', 1), ('준비해보세요', 1), ('유료서비스이용약관', 1), ('개정내역', 1), ('알바몬소식메일470호', 1), ('221227', 1), (\"'한국어를\", 1), (\"잘해요'라고\", 1), ('말할', 1), ('그날까지', 1), ('0개', 1), ('국어', 1), ('탈출', 1), ('함께해요', 1), ('이달의', 1), ('아울렛', 2), ('49', 3), ('최저가도전', 1), ('kt', 5), ('shop에서', 1), ('결제하고', 1), ('캐쉬업', 3), ('weekly', 1), ('writing', 5), ('40', 1), ('premium', 5), ('tv광고', 1), ('속의', 1), ('정부기관', 1), ('사칭', 1), ('스미싱', 1), ('피해', 3), ('주의', 2), ('363380', 1), ('yogiyo에', 1), ('손님응대부터', 1), ('안전관리까지', 1), ('책임지는', 1), ('놀이공원', 1), ('테마파크', 1), ('did', 1), ('take', 1), ('break', 1), ('last', 4), ('week', 3), ('라이엇', 1), ('자녀', 1), ('지인을', 1), ('사칭한', 5), (\"'sns피싱'을\", 1), ('기반', 1), ('합격자', 2), ('발표', 1), ('지식재산권', 2), ('이해', 2), ('선행기술조사', 2), ('실무', 2), ('후불결제', 1), ('블로그', 2), ('설정', 2), ('제휴된', 1), ('받아', 2), ('가세요', 2), ('삼성월렛', 2), ('연결은', 1), ('삼성이', 1), ('할게', 1), ('사용은', 1), ('누가', 1), ('할래', 1), ('삼성전자', 6), ('생태계', 1), ('build', 1), ('own', 1), ('adventure', 1), ('상품권', 4), ('있으시죠', 1), ('가을맞이', 1), ('무료충전', 1), ('회원님이', 1), ('방금', 1), ('회원님의', 9), ('재설정하셨나요', 1), ('건강상태', 1), ('확인하면', 2), ('3만원', 1), ('설문참여하면', 1), ('통장에', 1), ('꽂히는', 1), ('미접속에', 1), ('quantum2', 1), ('우수사례', 2), ('참가자', 2), ('19', 2), ('하고', 3), ('겨울에만', 1), ('스키장', 1), ('리디', 1), ('필요', 1), ('색다른', 1), ('사용처에서', 1), ('사용해보세요', 1), ('3일간의', 1), ('시크릿', 2), ('스타벅스', 2), ('기프티콘', 1), ('루나', 1), ('luna', 1), ('05', 2), ('20', 3), ('기다리던', 1), ('사전구매', 3), ('x', 2), ('케이뱅크', 2), ('제휴', 3), ('7천원', 2), ('현금3천원', 2), ('3분내', 2), ('hurloon', 1), ('minotaur', 1), ('advent', 1), ('education', 1), ('summary', 1), ('노래와', 2), ('게임의', 1), ('윤종신', 1), ('과', 1), ('회색도시2', 1), ('계정이', 6), ('삭제됩니다', 1), ('고기먹고싶은디', 3), ('twitch에서', 4), ('최고', 1), ('인기', 3), ('6개를', 1), ('확인해', 7), ('베이직', 1), ('basic', 2), ('api', 2), ('link', 2), ('manifest', 1), ('miraculous', 1), ('grammarly', 4), ('끝이', 1), ('잡코리아', 1), ('강화하기', 1), ('한정판매', 1), ('girls', 1), ('und', 1), ('panzer', 1), ('pz', 1), ('iv', 1), ('anko', 1), ('special', 2), ('전차를', 1), ('획득해', 1), ('보십시오', 1), ('엔플레이샵에서', 1), ('save', 1), ('date', 1), ('welcome', 4), ('app', 2), ('zone', 1), ('연말선물로', 1), ('stars', 1), ('have', 2), ('aligned', 1), ('savings', 1), ('여부', 3), ('던파', 1), ('가이드', 1), ('ventures', 2), ('갤럭시로', 1), ('통하는', 1), ('우리', 1), ('가족', 1), ('패밀리', 2), ('페스타에서', 1), ('끝', 2), ('득템데이', 1), ('구글기프트코드', 3), ('0', 1), ('배송이', 1), ('초대장', 1), ('지원', 2), ('감사의', 1), ('특별하게', 1), ('전하는', 1), ('페스타와', 1), ('갤캠스', 2), ('봄맞이', 1), ('혜택과', 1), ('이벤트가', 1), ('만개한', 1), ('갤캠스로', 1), ('want', 1), ('send', 1), ('stellar', 1), ('awesome', 1), ('achievements', 1), ('진로교육정보망', 2), ('회원탈퇴', 1), ('받을', 1), ('되신', 1), ('어서', 2), ('유출', 1), ('사실', 1), ('재안내', 2), ('ut', 1), ('갤캠스가', 1), ('쏜다', 1), ('찬스부터', 1), ('다양한', 3), ('이벤트까지', 3), ('놓치면', 1), ('후회할걸', 1), ('s7', 3), ('파일캐스트에서', 1), ('사용한상품권', 1), ('활용하세요', 1), ('red가', 1), ('한국에', 1), ('출시되었습니다', 1), ('폴드4', 1), ('오직', 1), ('일주일', 1), ('동안의', 1), ('한정판', 1), ('juun', 1), ('j', 1), ('note10', 1), ('discord용', 1), ('improving', 1), ('our', 4), ('policy', 2), ('better', 1), ('protect', 1), ('통합서비스약관', 1), ('내게', 2), ('맞는', 2), ('공고', 2), ('남들보다', 1), ('빠르게', 1), ('알바를', 1), ('구하세요', 1), ('【notice】kucoin', 1), ('결제가', 1), ('위한', 4), ('쇼핑몰', 2), ('몸짱이', 1), ('될수', 1), ('음식조절', 1), ('정리해', 1), ('discord의', 1), ('클래스101', 1), ('이용ㆍ제공', 2), ('과제', 1), ('만료됨', 2), ('커뮤니티에', 1), ('당신이', 1), ('필요해요', 1), ('문상으로', 2), ('교환하세요', 1), ('store', 1), ('계약', 1), ('t다이렉트샵', 1), ('구매하고', 1), ('휴대폰', 2), ('기기', 1), ('webinars', 4), ('지식in', 1), ('더욱', 1), ('풍성해진', 1), ('갤캠데이부터', 1), ('놓칠', 1), ('없는', 1), ('신', 1), ('동네예보정보조회서비스', 1), ('청소년', 1), ('발명기자단', 2), ('제19기', 1), ('기한연장', 1), ('응모하면', 1), ('아메리카노가', 1), ('가입하세요', 2), ('채팅창에', 1), ('자리를', 1), ('마련해두었습니다', 1), ('baekjoon', 1), ('online', 1), ('judge', 1), ('머슬업의', 1), ('모든것', 1), ('반동', 1), ('무반동', 1), ('슬로우', 1), ('까지', 1), ('배워보기', 1), ('ways', 1), ('speed', 1), ('up', 2), ('builds', 1), ('2023년도', 1), ('알바몬소식메일466호', 1), ('221101', 1), ('k', 1), ('mooc에', 1), ('비밀번호', 2), ('재설정', 1), ('위치정보서비스', 1), ('위치기반서비스', 2), ('회원에게만', 1), ('amendments', 1), ('마감임박', 2), ('기본과정', 1), ('12일', 1), ('sd', 1), ('탭s8', 1), ('4일', 1), ('어카운트의', 1), ('제공되었습니다', 1), ('getting', 2), ('started', 1), ('08', 1), ('블리자드', 3), ('비밀번호가', 2), ('새소식을', 1), ('500명', 1), ('프린터', 1), ('소모품', 1), ('기프티콘을', 1), ('흔치', 2), ('않은', 2), ('진행', 1), ('중', 1), ('아울렛에서', 1), ('알아', 1), ('개인정보의', 2), ('톰브라운', 2), ('디자인을', 2), ('입은', 2), ('클래식', 1), ('09', 1), ('29', 3), ('9시', 1), ('기념', 1), ('매일', 3), ('쏟아지는', 1), ('선물을', 2), ('특허청', 3), ('추가모집', 1), ('kg이니시스', 2), ('결제확인', 2), ('주', 2), ('비즈마켓에서', 1), ('결제하신', 3), ('확인바랍니다', 2), ('event', 1), ('january', 2), ('마진', 1), ('무이자', 1), ('지급되었습니다', 2), ('클릭', 1), ('한', 3), ('번으로', 1), ('facebook에', 1), ('로그인하세요', 1), ('삼성페이를', 1), ('등록해주셔서', 1), ('감사', 1), ('구매혜택과', 1), ('드디어', 1), ('s21', 1), ('전액', 1), ('면제', 1), ('갓', 1), ('나온', 1), ('현명한', 1), ('레알팜', 1), ('expires', 1), ('tonight', 1), ('【닌텐도', 1), ('어카운트】어카운트', 1), ('여름에만', 1), ('여름알바', 1), ('채용관', 1), ('3일에', 1), ('캐시충전하면', 1), ('2배', 1), ('파일썬', 2), ('see', 2), ('what', 2), ('can', 1), ('do', 1), ('gpa', 1), ('가격이', 1), ('인상되는', 1), ('2일', 1), ('이전에', 1), ('premium에', 1), ('9시간', 1), ('클래식의', 1), ('주인이', 1), ('되어보세요', 1), ('화제의', 2), ('콘텐츠를', 2), ('스트리머를', 2), ('secrets', 1), ('blubbr', 1), ('【circleci】how', 1), ('achieve', 1), ('innovation', 1), ('excellence', 1), ('devops', 2), ('latest', 1), ('report', 1), ('알바몬소식메일453호', 1), ('220405', 1), ('새', 2), ('인증서를', 1), ('기기에', 2), ('저장했습니다', 1), ('가능', 1), ('것', 1), ('아시나요', 1), ('vip', 1), ('받았습니다', 1), ('처리방침', 3), ('내용', 2), ('알바몬소식메일458호', 1), ('220705', 1), ('나의', 2), ('채널', 1), ('핸들을', 2), ('선택하실', 1), ('ぺにょ', 1), ('님이', 1), ('생방송', 1), ('중임', 1), ('こんにちは', 1), ('토루나에서', 2), ('달', 2), ('이용이', 1), ('금액으로', 1), ('팬들이', 1), ('원하는', 2), ('모든', 1), ('담은', 1), ('series', 1), ('unity', 1), ('id', 2), ('힘이', 1), ('휴가비', 1), ('벌자', 1), ('12월호', 2), ('대경권', 1), ('청년과학기술인', 1), ('일자리박람회', 1), ('31', 2), ('3일간', 1), ('안써보셨어요', 1), ('고객님께만', 1), ('비밀', 1), ('출퇴근길', 1), ('발생하는', 1), ('갑작스러운', 1), ('사고', 2), ('지키세요', 1), ('say', 1), ('hello', 1), ('world', 1), ('into', 1), ('flow', 1), ('띠링', 1), ('할인쿠폰이', 1), ('했습니다', 1), ('겟', 1), (\"we're\", 2), ('not', 1), ('seeing', 1), ('any', 2), ('activity', 2), ('완벽한', 1), ('몸매', 1), ('준비하자', 1), ('휴면계정', 4), ('music', 3), ('2개월', 1), ('혜택에', 1), ('가입할', 1), ('기간이', 1), ('얼마', 1), ('남지', 1), ('않았습니다', 1), ('도전과제', 1), ('us', 1), ('securing\\r', 1), ('휴면회원', 1), ('대학생', 2), ('맞춤', 1), ('구매혜택은', 1), ('몬스터볼', 1), ('패키지까지', 1), ('5월의', 1), ('소식', 1), ('마이통장으로', 1), ('충전하고', 3), ('알바몬소식메일454호', 1), ('220412', 1), ('현금이', 1), ('콜라보라해♥', 1), ('버즈프로', 1), ('라네즈', 1), ('네오쿠션', 1), ('번개특가', 2), ('시작합니다', 1), ('10일간', 1), ('변경사항', 1), ('지역에서의', 1), ('call', 1), ('submit', 1), ('session', 2), ('idea', 1), ('당신의', 3), ('pro', 2), ('가득', 3), ('찼습니다', 2), ('most', 2), ('차원의', 1), ('승리를', 1), ('경험하세요', 1), ('만나고', 1), ('받은', 2), ('t다이렉트샵에서', 1), ('용돈벌자', 1), ('따뜻한', 2), ('봄날에', 1), ('찾아온', 1), ('set', 1), ('integrations', 1), ('continuous', 1), ('deployment', 1), ('with\\r', 1), ('windows의', 1), ('internet', 1), ('explorer에서', 1), ('제18기', 2), ('갤캠스에서', 1), ('세뱃돈', 2), ('모음', 1), ('zip', 1), ('permissions', 1), ('update', 2), ('시리즈로', 2), ('사람에게', 1), ('큰', 1), ('세상을', 1), ('선물해보세요', 1), ('adobe', 1), ('공고를', 1), ('알바몬소식메일460호', 1), ('220726', 1), ('클래스메이트님', 1), ('알바몬', 3), ('gemini에', 1), ('910916', 1), ('이용자', 1), ('만족도조사', 1), ('updates', 1), ('use', 1), ('october', 1), ('28', 2), ('pdt', 1), (\"here's\", 1), ('sneak', 1), ('peek', 1), ('at\\r', 1), ('expect', 1), ('페이코인', 1), ('pci', 1), ('g마켓', 1), ('할인쿠폰', 2), ('매월', 1), ('공간이', 1), ('필요합니다', 1), ('500포인트', 1), ('hive', 1), ('분리저장', 1), ('웹툰', 1), ('보고', 1), ('4백원도', 1), ('샘플', 1), ('앱만의', 1), ('즐거움', 1), ('1500', 1), ('25', 1), ('선플', 2), ('아직도', 1), ('고통받고', 1), ('튀르키예', 1), ('지진피해', 1), ('주민들을', 1), ('선플달기에', 1), ('동참해', 1), ('2024', 1), ('÷', 2), ('ħ', 1), ('α', 1), ('당장', 1), ('버려야', 1), ('보험은', 1), ('standing', 1), ('strong', 1), ('south', 1), ('korea', 1), ('gifts', 1), ('신청하면', 1), ('1천원', 1), ('삼성', 3), ('인터넷', 2), ('연말연시', 1), ('각종', 1), ('디지털', 1), ('컨텐츠를', 2), ('할인된', 1), ('가격에', 1), ('어디까지', 1), ('써봤니', 1), ('활용편', 1), ('아이디가', 1), ('2023', 2), ('06', 1), ('22', 1), ('휴면상태로', 1), ('됩니다', 1), ('매직서바이벌', 1), ('공식카페', 1), ('recap', 2), ('투썸플레이스', 1), ('보내세요', 1), ('설문하고', 1), ('celebrating', 1), ('first', 2), ('22년도', 1), ('3기', 1), ('중급', 1), ('노티드', 1), ('♡9천원', 1), ('추가로', 1), ('귀여움', 1), ('장착♡', 1), ('카카오톡', 2), ('보이스룸', 1), ('구직자', 1), ('대상', 2), ('범죄', 1), ('방지를', 1), ('유의사항', 1), ('to\\r', 1), ('오버워치', 2), ('va', 2), ('성우', 1), ('김현지가', 1), ('알려주는', 1), ('대규모', 2), ('패치', 2), ('【6484】닌텐도', 1), ('한국정보통신자격협회', 2), ('01회', 1), ('네트워크관리사', 1), ('pc정비사', 1), ('지능형홈관리사', 1), ('영상정보관리사', 1), ('자격검정', 1), ('접수', 1), ('move', 2), ('scale', 2), ('without\\r', 2), ('compromising', 2), ('security', 2), ('고민은', 1), ('배송만', 1), ('늦출', 1), ('뿐', 1), ('라이브', 1), ('43', 1), ('삐삐케이스', 1), ('공홈단독', 1), ('공동구매', 1), ('experience', 1), ('lightning', 1), ('fast', 1), ('ultra', 1), ('secure', 2), ('browsing', 1), ('all', 3), ('devices', 1), ('방어', 1), ('매트릭스', 1), ('재사용', 1), ('대기시간', 1), ('감소', 1), ('올가을', 1), ('premium을', 1), ('체험해', 1), ('aws에서', 1), ('구축하는', 1), ('환경', 1), ('hands', 1), ('메시지', 1), ('ebs', 2), ('해', 2), ('social', 1), ('밤', 1), ('언팩', 1), ('행사로', 1), ('초대합니다', 1), ('14', 2), ('sk텔레콤', 1), ('안전한', 1), (\"'demong\", 1), ('hunter', 1), (\"se'에\", 1), ('ready', 1), ('action', 1), (\"there's\", 1), ('still', 1), ('time', 1), ('claim', 1), ('plan', 1), ('€1', 2), ('per', 1), ('mega는', 1), ('당신을', 1), ('기다립니다', 1), ('교보문고에서', 1), ('2014', 1), ('브라질', 1), ('월드컵', 1), ('즐기자', 1), ('upbit', 1), ('매주', 1), ('화요일에는', 1), ('위클리', 1), ('받아가세요♥', 1), ('찐', 1), ('유저라면', 1), ('지금이', 2), ('만의', 1), ('특급혜택', 1), ('만나', 1), ('한국정보방송통신대연합', 1), ('인적자원개발위원회', 1), ('isc', 1), ('주관으로', 1), ('새해', 1), ('인사를', 1), ('스미싱을', 2), ('업데이트된', 1), ('약관에', 1), ('관해', 1), ('가성비', 1), ('끝판왕', 1), ('국민관광상품권을', 1), ('구매해보세요', 1), ('플레이가', 2), ('추석을', 1), ('맞아', 1), ('풍성한', 1), ('국가지식재산교육포털', 1), ('일정', 3), ('h포인트', 1), ('전환하고', 1), ('이용·제공', 3), ('시리즈on에서', 1), ('결제한', 1), ('안내해', 1), ('25일까지', 1), ('레벨', 1), ('달성', 1), ('블랙', 1), ('프라이데이', 1), ('알바몬소식메일455호', 1), ('220426', 1), ('카카오모빌리티', 1), ('t', 1), ('떴습니다', 1), ('514671은', 1), ('는', 1), ('코드입니다', 1), ('win', 1), ('000', 1), ('work', 1), ('minecraft', 1), ('참여', 1), ('내가', 2), ('응원해', 1), ('꿈', 1), ('500만원', 1), ('여행상품권', 1), ('활기찬', 1), ('일상을', 1), ('갤럭시가', 1), ('응원합니다', 1), ('자유지상주의', 1), ('최준하', 1), ('작품', 1), ('letter', 1), ('care', 1), ('about', 1), ('trust', 1), ('transparency', 1), ('steam', 3), ('컴퓨터로', 1), ('접속', 2), ('삼성월렛이', 1), ('등록되었습니다', 2), ('2014년을', 1), ('빛낸', 1), ('최고의', 2), ('본인확인이', 1), ('북3', 2), ('울트라', 1), ('f2302030903050994', 1), ('넥슨캐시', 2), ('또', 1), ('수집한', 1), ('수집출처등', 1), ('행거가', 1), ('무너졌다', 1), ('소비중독', 1), ('직장인의', 1), ('‘옷', 1), ('1년', 1), ('안', 1), ('사기', 1), ('프로젝트’', 1), ('성공할', 1), ('있을까요', 1), ('진로', 1), ('설계를', 1), ('부탁해', 1), ('구하자', 1), ('환경에서', 1), ('되었습니다', 1), ('5월호', 1), ('운전에', 1), ('자신이', 1), ('있다면', 1), ('배달', 2), ('통합회원가입이', 1), ('에브리타임', 1), ('플스게임', 1), ('이용하는', 1), ('알바몬소식메일463호', 1), ('220816', 1), ('리워드', 1), ('￦2750', 1), ('유저', 1), ('바우처', 1), ('획득을', 1), ('오늘만', 1), ('hey', 1), ('버즈2와', 2), ('힙한', 1), ('액세서리', 1), ('득템하자', 1), ('센스있게', 1), ('얻는', 1), ('방법은', 1), ('뭘까', 1), ('100만원', 1), ('이벤트★', 1), ('아이디에', 1), ('휴대기기가', 1), ('걱정', 1), ('없이도', 1), ('플레이할', 1), ('총집합', 1), ('품절대란템', 1), ('127만원', 1), ('혜택받고', 1), ('get찬스', 1), ('대축제', 1), ('추석택배', 1), ('안부문자를', 2), ('스미싱에', 1), ('양은석님에게만', 1), ('pin', 2), ('실시간', 1), ('도서부터', 1), ('어학까지', 1), ('자기개발도', 1), ('하자', 1), ('뒤가', 1), ('싸', 1), ('해지는', 1), ('여기는', 1), ('서늘한', 1), ('서점입니다', 1), ('리그', 1), ('오브', 1), ('레전드', 1), ('시청하세요', 2), ('2분기', 1), ('오픈뱅킹', 2), ('금융거래정보', 2), ('제공사실', 2), ('농·축협', 1), ('널리', 1), ('즐겨', 2), ('들은', 1), ('아티스트를', 1), ('한달', 1), ('영화감상', 1), ('cgv', 2), ('여행', 1), ('계획', 1), ('세워보세요', 1), ('kb국민은행', 1), ('공공데이터활용지원센터', 2), ('변경에', 2), ('전설의', 1), ('레이드배틀', 1), ('vod', 1), ('콘텐츠에', 1), ('관한', 1), ('코리아', 2), ('변경의', 1), ('건', 1), ('알바몬소식메일456호', 1), ('220510', 1), ('steam에', 1), ('타임라인을', 1), ('1일까지', 1), ('band', 1), ('미접속자', 1), ('14일까지', 1), ('사람들과', 2), ('채팅해', 2), ('introducing', 1), ('kaboom', 1), ('repls', 1), ('우티', 1), ('다쓴문상등록하면', 1), ('탑툰이', 1), ('스펙을', 1), ('높일', 1), ('알바의', 2), ('꽃', 1), ('사무보조', 1), ('ぺにょ님이', 1), ('생방송을', 1), ('시작했습니다', 1), ('풀템', 1), ('최단', 1), ('기간', 2), ('국내', 1), ('100만대', 1), ('돌파한', 1), ('노트10의', 1), ('매력은', 1), ('파티', 1), ('방송으로', 1), ('함께하세요', 1), ('windows', 1), ('사전안내', 2), ('keep', 1), ('super', 1), ('무더운', 1), ('여름', 1), ('플레이와', 1), ('언어로', 1), ('업데이트하세요\\r', 1), ('yes0363', 2), ('구매하신', 1), ('상품의', 1), ('결제내역입니다', 1), ('릴레이특강·기본과정', 1), ('클라우드의', 1), ('약관이', 1), ('적용되었습니다', 1), ('휴면해제', 1), ('원서접수', 1), ('완료메일', 1), ('meet', 2), ('made', 1), ('롯데멤버스', 1), (\"'23년\", 1), ('pubc', 1), ('looks', 1), ('like', 1), (\"didn't\", 1), ('대여', 2), ('능력을', 1), ('향상시키고', 1), ('백화점', 1), ('love', 1), ('so', 1), ('far', 1), ('opinion', 1), ('counts', 1), ('갤럭시엔', 1), ('버즈2를', 1), ('ferpa', 1), ('coppa', 1), ('compliance', 1), ('알림메일입니다', 1), ('오', 1), ('늘', 1), ('마', 1), ('감', 1), ('한번', 1), ('오늘이', 1), ('december', 1), ('카카오페이로', 1), ('17', 1), ('마이데이터', 1), ('개인신용정보', 1), ('전송내역', 1), ('죽도록', 1), ('운동하기', 1), ('싫은날', 1), ('턱걸이', 1), ('50개', 1), ('푸쉬업', 1), ('100개', 1), ('컬쳐랜드x호텔케니', 1), ('호텔케니', 1), ('예약하고', 1), ('여행가자', 1), ('방식이', 2), ('시작은', 1), ('이력서', 1), ('작성부터입니다', 1), ('기자단', 1), ('뉴스레터를', 1), ('구독해', 1), ('2개월로', 1), ('길어진', 1), ('체험판을', 1), ('외국계', 1), ('기업에서', 1), ('일하고', 1), ('싶은', 1), ('사람', 1), ('21', 1), ('외투기업', 1), ('만남의', 1), ('날에서', 1), ('모이자', 1), ('도용', 1), ('발생', 1), ('point로', 2), ('workflows', 1), ('갤러리', 1), ('장기미사용계정전환알림', 1), ('브라우저', 1), ('혹은', 1), ('기기로', 1), ('조사', 1), ('에어드랍', 1), ('사업자', 1), ('외', 1), ('첫', 1), ('기업탐방', 1), ('참석자', 1), ('결과보고서', 1), ('제출', 1), ('yes30141', 1), ('qa·테스터', 1), ('쌓고', 1), ('qa·테스터·검증', 1), ('4조', 1), ('수탁업체', 1), ('전화번호', 1), ('가전제품의', 1), ('구매혜택', 1), ('대방출', 1), ('특별히', 1), ('마련한', 1), ('보따리', 1), ('9일에', 1), ('데이의', 1), ('거의', 1), ('device', 1), ('전환하세요', 1), ('확인하기', 1), ('데드', 1), ('바이', 1), ('데이라이트', 1), ('쇼다운을', 1), ('대한민국의', 1), ('자랑스런', 1), ('인디게임을', 1), ('마이맥', 1), ('약관개정', 1), ('복구가', 1), ('1분내', 1), ('참여바랍니다', 2), ('총상금', 1), ('1천3백만원', 1), ('ucc공모전', 1), ('주제', 1), ('감정노동자', 1), ('배려', 1), ('도는', 1), ('언어문화', 1), ('개선', 1), ('extended', 1), ('48', 1), ('hours', 1), ('설날', 1), ('품절임박▶adidas기프트와', 1), ('tab', 2), ('신상컬러', 1), ('알바몬소식메일452호', 1), ('220322', 1), ('변경됩니다', 1), ('긴급재난지원금', 1), ('조회를', 1), ('클라우드', 1), ('difficult', 1), ('conversations', 1), ('tone', 1), ('suggestions', 1), ('도움이', 1), ('필요하시다면', 1), ('언제든지', 1), ('안내데스크·', 1), ('리셉션', 1), ('4월의', 1), ('갓생', 1), ('시작하기', 1), ('빠른', 1), ('때', 1), ('트릭스터m', 1), ('아이템매니아에서', 1), ('용돈', 1), ('벌어', 1), ('볼까', 1), ('구독하기', 1), ('시기', 1), ('대가족이', 1), ('되어주세요', 1), ('보도자료', 1), ('여야', 1), ('국회의원', 1), ('299명', 1), ('선플서명…올해', 1), ('선플상', 1), ('시상식', 1), ('빛냈다', 1), ('메이플스토리', 1), ('모험가', 1), ('리마스터', 1), ('게임이용내역', 1), ('지금이야말로', 1), ('얻기', 1), ('날', 1), ('signs', 1), ('55', 1), ('【오늘', 1), ('개최】circleci', 1), ('세미나에서', 1), ('cd를', 1), ('시작하는', 1), ('방법을', 1), ('배워봅시다', 1), ('진로상담은', 1), ('커리어넷에서', 1), ('11월호', 1), ('삭제되었습니다', 1), ('반값할인', 1), ('웹툰도', 1), ('보자', 1), ('♬', 1), ('수신거부', 1), ('november', 1), ('10월에', 1), ('많은', 1), ('사랑을', 1), ('앱과', 1), ('할인돼요', 1), ('네', 1), ('여긴', 1), ('65', 1), ('기존', 1), ('휴면유저', 1), ('복귀', 1), ('개별', 1), ('카카오계정', 1), ('계좌개설하면', 1), ('updating', 1), ('자신의', 1), ('타입에', 1), ('맞춰', 1), ('상태로', 1), ('무료건강검진', 1), ('yes24', 1), ('★곧', 1), ('종료★', 1), ('올해', 1), ('삼성전자멤버십', 1), ('미이용', 1), ('고객', 1), ('분리', 1), ('보관', 1), ('가정의', 1), ('선물로', 1), ('7eunsuk님', 1), ('「부화장치」를', 1), ('lg전자', 1), ('마음껏', 1), ('쇼핑을', 1), ('키움페이', 1), ('결제알림', 1), ('주식회사', 1), ('원포유', 1), ('내역입니다', 1)])\n",
      "메일의 최대 길이 : 19\n",
      "메일의 평균 길이 : 6.855556\n",
      "등장 빈도가 1번 이하인 단어의 수: 1748\n",
      "단어 집합(vocabulary)에서 희귀 단어의 비율: 65.76373212942062\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 25.75512008251068\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_encoded = tokenizer.texts_to_sequences(X_train)\n",
    "word_to_index = tokenizer.word_index\n",
    "Incoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1회 단어 제외\n",
    "#tokenizer = Tokenizer(num_words = total_cnt - rare_cnt + 1)\n",
    "vocab_size = len(word_to_index) + 1\n",
    "max_len = max(len(sample) for sample in X_train_encoded)\n",
    "lengths = [len(sample) for sample in X_data if isinstance(sample, str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기: 2659\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('단어 집합의 크기: {}'.format((vocab_size)))\n",
    "plt.hist(lengths, bins=50)\n",
    "plt.xlabel('Length of samples')\n",
    "plt.ylabel('Number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 크기(shape): (990, 19)\n"
     ]
    }
   ],
   "source": [
    "X_train_padded = pad_sequences(X_train_encoded, maxlen = max_len)\n",
    "print(\"훈련 데이터의 크기(shape):\", X_train_padded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer + CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_encoded = tokenizer.texts_to_sequences(X_train)\n",
    "word_to_index = tokenizer.word_index\n",
    "\n",
    "vocab_size = len(word_to_index) + 1\n",
    "max_len = max(len(sample) for sample in X_train_encoded)\n",
    "X_train_padded = pad_sequences(X_train_encoded, maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m15/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.3034 - loss: 4.9265\n",
      "Epoch 1: val_loss improved from inf to 3.39602, saving model to best_model_TKCNN.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - f1_score: 0.2791 - loss: 4.7821 - val_f1_score: 0.0932 - val_loss: 3.3960\n",
      "Epoch 2/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.0750 - loss: 3.0934\n",
      "Epoch 2: val_loss improved from 3.39602 to 2.26657, saving model to best_model_TKCNN.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - f1_score: 0.0741 - loss: 3.0686 - val_f1_score: 0.0489 - val_loss: 2.2666\n",
      "Epoch 3/100\n",
      "\u001b[1m14/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.0436 - loss: 2.1105\n",
      "Epoch 3: val_loss improved from 2.26657 to 1.48261, saving model to best_model_TKCNN.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - f1_score: 0.0426 - loss: 2.0443 - val_f1_score: 0.0332 - val_loss: 1.4826\n",
      "Epoch 4/100\n",
      "\u001b[1m13/19\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.0474 - loss: 1.3540\n",
      "Epoch 4: val_loss improved from 1.48261 to 0.99147, saving model to best_model_TKCNN.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - f1_score: 0.0656 - loss: 1.3162 - val_f1_score: 0.2400 - val_loss: 0.9915\n",
      "Epoch 5/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.2958 - loss: 0.8831\n",
      "Epoch 5: val_loss improved from 0.99147 to 0.69515, saving model to best_model_TKCNN.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - f1_score: 0.3014 - loss: 0.8735 - val_f1_score: 0.4094 - val_loss: 0.6952\n",
      "Epoch 6/100\n",
      "\u001b[1m14/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.4376 - loss: 0.6190\n",
      "Epoch 6: val_loss improved from 0.69515 to 0.52925, saving model to best_model_TKCNN.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - f1_score: 0.4448 - loss: 0.6072 - val_f1_score: 0.5169 - val_loss: 0.5293\n",
      "Epoch 7/100\n",
      "\u001b[1m15/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.5392 - loss: 0.4903\n",
      "Epoch 7: val_loss improved from 0.52925 to 0.44690, saving model to best_model_TKCNN.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - f1_score: 0.5433 - loss: 0.4814 - val_f1_score: 0.5909 - val_loss: 0.4469\n",
      "Epoch 8/100\n",
      "\u001b[1m15/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.6057 - loss: 0.3759\n",
      "Epoch 8: val_loss improved from 0.44690 to 0.40777, saving model to best_model_TKCNN.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - f1_score: 0.6086 - loss: 0.3758 - val_f1_score: 0.6424 - val_loss: 0.4078\n",
      "Epoch 9/100\n",
      "\u001b[1m15/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.6532 - loss: 0.3598\n",
      "Epoch 9: val_loss improved from 0.40777 to 0.39034, saving model to best_model_TKCNN.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - f1_score: 0.6553 - loss: 0.3555 - val_f1_score: 0.6811 - val_loss: 0.3903\n",
      "Epoch 10/100\n",
      "\u001b[1m14/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.6891 - loss: 0.3154\n",
      "Epoch 10: val_loss improved from 0.39034 to 0.37463, saving model to best_model_TKCNN.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - f1_score: 0.6912 - loss: 0.3173 - val_f1_score: 0.7114 - val_loss: 0.3746\n",
      "Epoch 11/100\n",
      "\u001b[1m14/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.7183 - loss: 0.3152\n",
      "Epoch 11: val_loss improved from 0.37463 to 0.36173, saving model to best_model_TKCNN.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - f1_score: 0.7199 - loss: 0.3108 - val_f1_score: 0.7358 - val_loss: 0.3617\n",
      "Epoch 12/100\n",
      "\u001b[1m15/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.7404 - loss: 0.2600\n",
      "Epoch 12: val_loss improved from 0.36173 to 0.35114, saving model to best_model_TKCNN.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - f1_score: 0.7416 - loss: 0.2677 - val_f1_score: 0.7558 - val_loss: 0.3511\n",
      "Epoch 13/100\n",
      "\u001b[1m15/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.7609 - loss: 0.2775\n",
      "Epoch 13: val_loss did not improve from 0.35114\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - f1_score: 0.7618 - loss: 0.2777 - val_f1_score: 0.7726 - val_loss: 0.3549\n",
      "Epoch 14/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.7769 - loss: 0.2634\n",
      "Epoch 14: val_loss did not improve from 0.35114\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.7774 - loss: 0.2633 - val_f1_score: 0.7868 - val_loss: 0.3531\n",
      "Epoch 15/100\n",
      "\u001b[1m14/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.7897 - loss: 0.2686\n",
      "Epoch 15: val_loss improved from 0.35114 to 0.34340, saving model to best_model_TKCNN.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - f1_score: 0.7905 - loss: 0.2649 - val_f1_score: 0.7987 - val_loss: 0.3434\n",
      "Epoch 16/100\n",
      "\u001b[1m15/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.8013 - loss: 0.2605\n",
      "Epoch 16: val_loss improved from 0.34340 to 0.31745, saving model to best_model_TKCNN.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - f1_score: 0.8019 - loss: 0.2551 - val_f1_score: 0.8090 - val_loss: 0.3175\n",
      "Epoch 17/100\n",
      "\u001b[1m15/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.8112 - loss: 0.2369\n",
      "Epoch 17: val_loss did not improve from 0.31745\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - f1_score: 0.8117 - loss: 0.2335 - val_f1_score: 0.8182 - val_loss: 0.3284\n",
      "Epoch 18/100\n",
      "\u001b[1m15/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.8204 - loss: 0.2074\n",
      "Epoch 18: val_loss improved from 0.31745 to 0.30270, saving model to best_model_TKCNN.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - f1_score: 0.8208 - loss: 0.2089 - val_f1_score: 0.8263 - val_loss: 0.3027\n",
      "Epoch 19/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.8281 - loss: 0.2023\n",
      "Epoch 19: val_loss did not improve from 0.30270\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - f1_score: 0.8284 - loss: 0.2024 - val_f1_score: 0.8335 - val_loss: 0.3038\n",
      "Epoch 20/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.8351 - loss: 0.2042\n",
      "Epoch 20: val_loss improved from 0.30270 to 0.30054, saving model to best_model_TKCNN.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - f1_score: 0.8354 - loss: 0.2024 - val_f1_score: 0.8398 - val_loss: 0.3005\n",
      "Epoch 21/100\n",
      "\u001b[1m15/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.8413 - loss: 0.1759\n",
      "Epoch 21: val_loss improved from 0.30054 to 0.28317, saving model to best_model_TKCNN.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - f1_score: 0.8416 - loss: 0.1787 - val_f1_score: 0.8455 - val_loss: 0.2832\n",
      "Epoch 22/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.8469 - loss: 0.2036\n",
      "Epoch 22: val_loss did not improve from 0.28317\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.8471 - loss: 0.1998 - val_f1_score: 0.8506 - val_loss: 0.2934\n",
      "Epoch 23/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.8519 - loss: 0.1728\n",
      "Epoch 23: val_loss did not improve from 0.28317\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.8520 - loss: 0.1740 - val_f1_score: 0.8553 - val_loss: 0.2853\n",
      "Epoch 24/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.8567 - loss: 0.1658\n",
      "Epoch 24: val_loss did not improve from 0.28317\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.8567 - loss: 0.1670 - val_f1_score: 0.8595 - val_loss: 0.2857\n",
      "Epoch 25/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.8605 - loss: 0.1981\n",
      "Epoch 25: val_loss did not improve from 0.28317\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - f1_score: 0.8607 - loss: 0.1939 - val_f1_score: 0.8634 - val_loss: 0.2849\n",
      "Epoch 26/100\n",
      "\u001b[1m15/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.8642 - loss: 0.1875 \n",
      "Epoch 26: val_loss improved from 0.28317 to 0.28230, saving model to best_model_TKCNN.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - f1_score: 0.8644 - loss: 0.1846 - val_f1_score: 0.8670 - val_loss: 0.2823\n",
      "Epoch 27/100\n",
      "\u001b[1m12/19\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.8677 - loss: 0.1717 \n",
      "Epoch 27: val_loss did not improve from 0.28230\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - f1_score: 0.8681 - loss: 0.1687 - val_f1_score: 0.8703 - val_loss: 0.2853\n",
      "Epoch 28/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.8713 - loss: 0.1572\n",
      "Epoch 28: val_loss improved from 0.28230 to 0.28111, saving model to best_model_TKCNN.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - f1_score: 0.8713 - loss: 0.1579 - val_f1_score: 0.8735 - val_loss: 0.2811\n",
      "Epoch 29/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.8741 - loss: 0.1722\n",
      "Epoch 29: val_loss did not improve from 0.28111\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.8742 - loss: 0.1701 - val_f1_score: 0.8764 - val_loss: 0.2908\n",
      "Epoch 30/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.8771 - loss: 0.1787\n",
      "Epoch 30: val_loss improved from 0.28111 to 0.27744, saving model to best_model_TKCNN.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - f1_score: 0.8772 - loss: 0.1777 - val_f1_score: 0.8790 - val_loss: 0.2774\n",
      "Epoch 31/100\n",
      "\u001b[1m13/19\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.8796 - loss: 0.1600\n",
      "Epoch 31: val_loss did not improve from 0.27744\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - f1_score: 0.8798 - loss: 0.1616 - val_f1_score: 0.8814 - val_loss: 0.2874\n",
      "Epoch 32/100\n",
      "\u001b[1m15/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.8820 - loss: 0.1675\n",
      "Epoch 32: val_loss did not improve from 0.27744\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - f1_score: 0.8821 - loss: 0.1660 - val_f1_score: 0.8838 - val_loss: 0.2870\n",
      "Epoch 33/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.8843 - loss: 0.1600\n",
      "Epoch 33: val_loss improved from 0.27744 to 0.27335, saving model to best_model_TKCNN.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - f1_score: 0.8844 - loss: 0.1618 - val_f1_score: 0.8858 - val_loss: 0.2734\n",
      "Epoch 34/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.8863 - loss: 0.1651\n",
      "Epoch 34: val_loss did not improve from 0.27335\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - f1_score: 0.8863 - loss: 0.1648 - val_f1_score: 0.8877 - val_loss: 0.2885\n",
      "Epoch 35/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.8881 - loss: 0.1557\n",
      "Epoch 35: val_loss did not improve from 0.27335\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - f1_score: 0.8882 - loss: 0.1544 - val_f1_score: 0.8896 - val_loss: 0.2937\n",
      "Epoch 36/100\n",
      "\u001b[1m 9/19\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.8899 - loss: 0.1462 \n",
      "Epoch 36: val_loss did not improve from 0.27335\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.8901 - loss: 0.1583 - val_f1_score: 0.8914 - val_loss: 0.2939\n",
      "Epoch 37/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.8919 - loss: 0.1374\n",
      "Epoch 37: val_loss did not improve from 0.27335\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - f1_score: 0.8919 - loss: 0.1401 - val_f1_score: 0.8930 - val_loss: 0.2797\n",
      "Epoch 38/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.8935 - loss: 0.1496\n",
      "Epoch 38: val_loss improved from 0.27335 to 0.27171, saving model to best_model_TKCNN.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - f1_score: 0.8935 - loss: 0.1501 - val_f1_score: 0.8946 - val_loss: 0.2717\n",
      "Epoch 39/100\n",
      "\u001b[1m15/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.8949 - loss: 0.1421\n",
      "Epoch 39: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - f1_score: 0.8950 - loss: 0.1434 - val_f1_score: 0.8959 - val_loss: 0.2777\n",
      "Epoch 40/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.8963 - loss: 0.1392\n",
      "Epoch 40: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.8964 - loss: 0.1405 - val_f1_score: 0.8973 - val_loss: 0.2861\n",
      "Epoch 41/100\n",
      "\u001b[1m15/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.8976 - loss: 0.1342\n",
      "Epoch 41: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - f1_score: 0.8977 - loss: 0.1367 - val_f1_score: 0.8986 - val_loss: 0.2723\n",
      "Epoch 42/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.8990 - loss: 0.1335\n",
      "Epoch 42: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.8990 - loss: 0.1371 - val_f1_score: 0.8998 - val_loss: 0.3061\n",
      "Epoch 43/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - f1_score: 0.9002 - loss: 0.1299\n",
      "Epoch 43: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9002 - loss: 0.1300 - val_f1_score: 0.9011 - val_loss: 0.2732\n",
      "Epoch 44/100\n",
      "\u001b[1m10/19\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9012 - loss: 0.1576 \n",
      "Epoch 44: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9014 - loss: 0.1533 - val_f1_score: 0.9022 - val_loss: 0.3383\n",
      "Epoch 45/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9024 - loss: 0.1329\n",
      "Epoch 45: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9025 - loss: 0.1338 - val_f1_score: 0.9033 - val_loss: 0.2924\n",
      "Epoch 46/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9035 - loss: 0.1406\n",
      "Epoch 46: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9036 - loss: 0.1404 - val_f1_score: 0.9043 - val_loss: 0.2817\n",
      "Epoch 47/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9046 - loss: 0.1384\n",
      "Epoch 47: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - f1_score: 0.9046 - loss: 0.1383 - val_f1_score: 0.9054 - val_loss: 0.2800\n",
      "Epoch 48/100\n",
      "\u001b[1m15/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9056 - loss: 0.1250\n",
      "Epoch 48: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - f1_score: 0.9057 - loss: 0.1271 - val_f1_score: 0.9064 - val_loss: 0.2984\n",
      "Epoch 49/100\n",
      "\u001b[1m15/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9066 - loss: 0.1442\n",
      "Epoch 49: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - f1_score: 0.9066 - loss: 0.1409 - val_f1_score: 0.9074 - val_loss: 0.3005\n",
      "Epoch 50/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9075 - loss: 0.1410\n",
      "Epoch 50: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9076 - loss: 0.1399 - val_f1_score: 0.9082 - val_loss: 0.3271\n",
      "Epoch 51/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9084 - loss: 0.1377\n",
      "Epoch 51: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - f1_score: 0.9085 - loss: 0.1380 - val_f1_score: 0.9091 - val_loss: 0.2786\n",
      "Epoch 52/100\n",
      "\u001b[1m15/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9093 - loss: 0.1376\n",
      "Epoch 52: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - f1_score: 0.9094 - loss: 0.1342 - val_f1_score: 0.9100 - val_loss: 0.3041\n",
      "Epoch 53/100\n",
      "\u001b[1m15/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9101 - loss: 0.1285\n",
      "Epoch 53: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - f1_score: 0.9102 - loss: 0.1283 - val_f1_score: 0.9107 - val_loss: 0.2853\n",
      "Epoch 54/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9110 - loss: 0.1146\n",
      "Epoch 54: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - f1_score: 0.9110 - loss: 0.1159 - val_f1_score: 0.9115 - val_loss: 0.2746\n",
      "Epoch 55/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9117 - loss: 0.1149 \n",
      "Epoch 55: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - f1_score: 0.9117 - loss: 0.1160 - val_f1_score: 0.9123 - val_loss: 0.2856\n",
      "Epoch 56/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9124 - loss: 0.1178\n",
      "Epoch 56: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - f1_score: 0.9125 - loss: 0.1185 - val_f1_score: 0.9130 - val_loss: 0.2980\n",
      "Epoch 57/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9132 - loss: 0.1354 \n",
      "Epoch 57: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - f1_score: 0.9132 - loss: 0.1353 - val_f1_score: 0.9137 - val_loss: 0.2798\n",
      "Epoch 58/100\n",
      "\u001b[1m 9/19\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9138 - loss: 0.1169 \n",
      "Epoch 58: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9138 - loss: 0.1227 - val_f1_score: 0.9142 - val_loss: 0.2898\n",
      "Epoch 59/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9143 - loss: 0.1162\n",
      "Epoch 59: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9144 - loss: 0.1191 - val_f1_score: 0.9148 - val_loss: 0.3012\n",
      "Epoch 60/100\n",
      "\u001b[1m 9/19\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9149 - loss: 0.1208 \n",
      "Epoch 60: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9150 - loss: 0.1248 - val_f1_score: 0.9154 - val_loss: 0.3113\n",
      "Epoch 61/100\n",
      "\u001b[1m15/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9156 - loss: 0.1087\n",
      "Epoch 61: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - f1_score: 0.9156 - loss: 0.1115 - val_f1_score: 0.9161 - val_loss: 0.3095\n",
      "Epoch 62/100\n",
      "\u001b[1m15/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9162 - loss: 0.1222\n",
      "Epoch 62: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9163 - loss: 0.1237 - val_f1_score: 0.9166 - val_loss: 0.2905\n",
      "Epoch 63/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9168 - loss: 0.1126\n",
      "Epoch 63: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9168 - loss: 0.1132 - val_f1_score: 0.9173 - val_loss: 0.2931\n",
      "Epoch 64/100\n",
      "\u001b[1m15/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9174 - loss: 0.1170 \n",
      "Epoch 64: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - f1_score: 0.9175 - loss: 0.1160 - val_f1_score: 0.9179 - val_loss: 0.3120\n",
      "Epoch 65/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9180 - loss: 0.1164\n",
      "Epoch 65: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - f1_score: 0.9181 - loss: 0.1167 - val_f1_score: 0.9185 - val_loss: 0.2756\n",
      "Epoch 66/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9186 - loss: 0.1132\n",
      "Epoch 66: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - f1_score: 0.9186 - loss: 0.1128 - val_f1_score: 0.9191 - val_loss: 0.3066\n",
      "Epoch 67/100\n",
      "\u001b[1m13/19\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9192 - loss: 0.1073\n",
      "Epoch 67: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - f1_score: 0.9193 - loss: 0.1086 - val_f1_score: 0.9197 - val_loss: 0.3298\n",
      "Epoch 68/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9198 - loss: 0.1147\n",
      "Epoch 68: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - f1_score: 0.9198 - loss: 0.1143 - val_f1_score: 0.9202 - val_loss: 0.3068\n",
      "Epoch 69/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - f1_score: 0.9203 - loss: 0.1216\n",
      "Epoch 69: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - f1_score: 0.9203 - loss: 0.1199 - val_f1_score: 0.9208 - val_loss: 0.3191\n",
      "Epoch 70/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9209 - loss: 0.0961\n",
      "Epoch 70: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9209 - loss: 0.0968 - val_f1_score: 0.9213 - val_loss: 0.3086\n",
      "Epoch 71/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9214 - loss: 0.0988\n",
      "Epoch 71: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - f1_score: 0.9214 - loss: 0.0993 - val_f1_score: 0.9218 - val_loss: 0.2820\n",
      "Epoch 72/100\n",
      "\u001b[1m13/19\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9218 - loss: 0.1046 \n",
      "Epoch 72: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - f1_score: 0.9219 - loss: 0.1048 - val_f1_score: 0.9223 - val_loss: 0.3192\n",
      "Epoch 73/100\n",
      "\u001b[1m15/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9224 - loss: 0.0981\n",
      "Epoch 73: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9224 - loss: 0.0984 - val_f1_score: 0.9227 - val_loss: 0.2968\n",
      "Epoch 74/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9228 - loss: 0.1148\n",
      "Epoch 74: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9228 - loss: 0.1129 - val_f1_score: 0.9232 - val_loss: 0.3101\n",
      "Epoch 75/100\n",
      "\u001b[1m13/19\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - f1_score: 0.9233 - loss: 0.0902\n",
      "Epoch 75: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - f1_score: 0.9233 - loss: 0.0923 - val_f1_score: 0.9236 - val_loss: 0.3459\n",
      "Epoch 76/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9237 - loss: 0.1161\n",
      "Epoch 76: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9237 - loss: 0.1148 - val_f1_score: 0.9240 - val_loss: 0.4284\n",
      "Epoch 77/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9241 - loss: 0.0974\n",
      "Epoch 77: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - f1_score: 0.9241 - loss: 0.0976 - val_f1_score: 0.9244 - val_loss: 0.3113\n",
      "Epoch 78/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9245 - loss: 0.1162\n",
      "Epoch 78: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9246 - loss: 0.1135 - val_f1_score: 0.9249 - val_loss: 0.3458\n",
      "Epoch 79/100\n",
      "\u001b[1m10/19\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9250 - loss: 0.0738 \n",
      "Epoch 79: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9251 - loss: 0.0814 - val_f1_score: 0.9254 - val_loss: 0.3216\n",
      "Epoch 80/100\n",
      "\u001b[1m10/19\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9255 - loss: 0.1096 \n",
      "Epoch 80: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9256 - loss: 0.1036 - val_f1_score: 0.9258 - val_loss: 0.3312\n",
      "Epoch 81/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9259 - loss: 0.1105\n",
      "Epoch 81: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9259 - loss: 0.1083 - val_f1_score: 0.9262 - val_loss: 0.2921\n",
      "Epoch 82/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9263 - loss: 0.0828\n",
      "Epoch 82: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - f1_score: 0.9263 - loss: 0.0839 - val_f1_score: 0.9266 - val_loss: 0.3637\n",
      "Epoch 83/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9267 - loss: 0.0994\n",
      "Epoch 83: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9267 - loss: 0.0990 - val_f1_score: 0.9270 - val_loss: 0.2928\n",
      "Epoch 84/100\n",
      "\u001b[1m15/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9270 - loss: 0.0940\n",
      "Epoch 84: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - f1_score: 0.9271 - loss: 0.0936 - val_f1_score: 0.9273 - val_loss: 0.2959\n",
      "Epoch 85/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9274 - loss: 0.0964\n",
      "Epoch 85: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9274 - loss: 0.0964 - val_f1_score: 0.9277 - val_loss: 0.3333\n",
      "Epoch 86/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9277 - loss: 0.1017\n",
      "Epoch 86: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - f1_score: 0.9278 - loss: 0.1011 - val_f1_score: 0.9281 - val_loss: 0.3013\n",
      "Epoch 87/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9281 - loss: 0.0812\n",
      "Epoch 87: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - f1_score: 0.9281 - loss: 0.0817 - val_f1_score: 0.9284 - val_loss: 0.3403\n",
      "Epoch 88/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9285 - loss: 0.0803\n",
      "Epoch 88: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - f1_score: 0.9285 - loss: 0.0827 - val_f1_score: 0.9288 - val_loss: 0.3272\n",
      "Epoch 89/100\n",
      "\u001b[1m15/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9289 - loss: 0.0889\n",
      "Epoch 89: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9289 - loss: 0.0892 - val_f1_score: 0.9292 - val_loss: 0.3143\n",
      "Epoch 90/100\n",
      "\u001b[1m15/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9293 - loss: 0.1054\n",
      "Epoch 90: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9293 - loss: 0.1028 - val_f1_score: 0.9295 - val_loss: 0.3049\n",
      "Epoch 91/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9296 - loss: 0.1040\n",
      "Epoch 91: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - f1_score: 0.9296 - loss: 0.1023 - val_f1_score: 0.9299 - val_loss: 0.3516\n",
      "Epoch 92/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9299 - loss: 0.1011\n",
      "Epoch 92: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9299 - loss: 0.1008 - val_f1_score: 0.9301 - val_loss: 0.2918\n",
      "Epoch 93/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9302 - loss: 0.0862\n",
      "Epoch 93: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - f1_score: 0.9302 - loss: 0.0873 - val_f1_score: 0.9304 - val_loss: 0.2936\n",
      "Epoch 94/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9305 - loss: 0.0876\n",
      "Epoch 94: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9305 - loss: 0.0877 - val_f1_score: 0.9307 - val_loss: 0.3371\n",
      "Epoch 95/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9307 - loss: 0.0807\n",
      "Epoch 95: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9308 - loss: 0.0821 - val_f1_score: 0.9310 - val_loss: 0.3207\n",
      "Epoch 96/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - f1_score: 0.9311 - loss: 0.0840\n",
      "Epoch 96: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - f1_score: 0.9311 - loss: 0.0855 - val_f1_score: 0.9313 - val_loss: 0.3145\n",
      "Epoch 97/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9314 - loss: 0.1014\n",
      "Epoch 97: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - f1_score: 0.9314 - loss: 0.1008 - val_f1_score: 0.9317 - val_loss: 0.3165\n",
      "Epoch 98/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9317 - loss: 0.0776\n",
      "Epoch 98: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - f1_score: 0.9318 - loss: 0.0789 - val_f1_score: 0.9320 - val_loss: 0.3303\n",
      "Epoch 99/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9320 - loss: 0.0876\n",
      "Epoch 99: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9320 - loss: 0.0875 - val_f1_score: 0.9323 - val_loss: 0.3419\n",
      "Epoch 100/100\n",
      "\u001b[1m15/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - f1_score: 0.9323 - loss: 0.0836\n",
      "Epoch 100: val_loss did not improve from 0.27171\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - f1_score: 0.9324 - loss: 0.0848 - val_f1_score: 0.9326 - val_loss: 0.3109\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Conv1D, GlobalMaxPooling1D, Embedding, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "embedding_dim = 64\n",
    "dropout_ratio = 0.3\n",
    "num_filters = 128\n",
    "kernel_size = 5\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(Dropout(dropout_ratio))\n",
    "model.add(Conv1D(num_filters, kernel_size, padding='valid', activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dropout(dropout_ratio))\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(dropout_ratio))\n",
    "model.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(dropout_ratio))\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(dropout_ratio))\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(dropout_ratio))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=[f1_score])\n",
    "\n",
    "# EarlyStopping 및 ModelCheckpoint 설정\n",
    "es = EarlyStopping(monitor='val_f1_score', mode='max', verbose=1, patience=15)\n",
    "mc = ModelCheckpoint('best_model_TKCNN.keras', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "history = model.fit(X_train_padded, y_train, epochs=100, batch_size=64, validation_split=0.2, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - f1_score: 0.9324 - loss: 0.4034 \n",
      "\n",
      " 테스트 손실값: 0.4185, 점수: 0.9324\n"
     ]
    }
   ],
   "source": [
    "X_test_encoded = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_padded = pad_sequences(X_test_encoded, maxlen = max_len)\n",
    "loss_TK_CNN, f1_TK_CNN = model.evaluate(X_test_padded, y_test)\n",
    "print(\"\\n 테스트 손실값: %.4f, 점수: %.4f\" % (loss_TK_CNN, f1_TK_CNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(1, len(history.history['f1_score']) + 1)\n",
    "plt.plot(epochs, history.history['f1_score'])\n",
    "plt.plot(epochs, history.history['val_f1_score'])\n",
    "plt.title('Model F1-Score')\n",
    "plt.ylabel('F1-Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 06s]\n",
      "val_f1_score: 0.6753152012825012\n",
      "\n",
      "Best val_f1_score So Far: 0.6598064303398132\n",
      "Total elapsed time: 00h 02m 17s\n",
      "Best hyperparameters:\n",
      "embedding_dim: 64\n",
      "dropout_ratio: 0.30000000000000004\n",
      "num_filters: 128\n",
      "kernel_size: 5\n",
      "num_dense_layers: 4\n",
      "dense_units_0: 128\n",
      "optimizer: adam\n",
      "batch_size: 96\n",
      "dense_units_1: 256\n",
      "dense_units_2: 64\n",
      "dense_units_3: 128\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 2\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0011\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dropout, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "import keras_tuner as kt\n",
    "import os\n",
    "\n",
    "\n",
    "# 모델을 빌드하는 함수 정의\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, hp.Int('embedding_dim', min_value=16, max_value=128, step=16)))\n",
    "    model.add(Dropout(hp.Float('dropout_ratio', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "\n",
    "    # CNN 층\n",
    "    model.add(Conv1D(filters=hp.Int('num_filters', min_value=32, max_value=128, step=32),\n",
    "                     kernel_size=hp.Int('kernel_size', min_value=3, max_value=7, step=1),\n",
    "                     padding='valid', activation='relu'))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dropout(hp.Float('dropout_ratio', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "\n",
    "    # Dense 층\n",
    "    for i in range(hp.Int('num_dense_layers', 1, 4)):\n",
    "        model.add(Dense(units=hp.Int(f'dense_units_{i}', min_value=64, max_value=256, step=64),\n",
    "                        activation='relu',\n",
    "                        kernel_regularizer=regularizers.l2(0.01)))\n",
    "        model.add(Dropout(hp.Float('dropout_ratio', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "\n",
    "    # 출력층\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=hp.Choice('optimizer', values=['adam', 'rmsprop']),\n",
    "                  loss='binary_crossentropy', metrics=[f1_score])\n",
    "    batch_size = hp.Int('batch_size', min_value=32, max_value=128, step=32)\n",
    "    return model\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 튜너 설정\n",
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective='val_f1_score',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='C:\\keras_tuner',\n",
    "                     project_name='TK_CNN_c6')\n",
    "\n",
    "# EarlyStopping 및 ModelCheckpoint 설정\n",
    "es = EarlyStopping(monitor='val_f1_score', mode='max', verbose=1, patience=15)\n",
    "mc = ModelCheckpoint('best_model.keras', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "# 모델 학습\n",
    "tuner.search(X_train_padded, y_train, epochs=10, validation_split=0.2, callbacks=[es, mc])\n",
    "\n",
    "# 최적의 하이퍼파라미터와 모델 정보 출력\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Best hyperparameters:\")\n",
    "for param, value in best_hp.values.items():\n",
    "    print(f\"{param}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF + CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF 벡터화\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train).toarray()\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test).toarray()\n",
    "\n",
    "# TF-IDF 데이터를 Conv1D에 맞는 3D 배열로 변환\n",
    "X_train_tfidf = X_train_tfidf.reshape(X_train_tfidf.shape[0], X_train_tfidf.shape[1], 1)\n",
    "X_test_tfidf = X_test_tfidf.reshape(X_test_tfidf.shape[0], X_test_tfidf.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\양은석\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - f1_score: 0.1395 - loss: 4.5624\n",
      "Epoch 1: val_loss improved from inf to 3.72651, saving model to best_model_TFCNN.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - f1_score: 0.1293 - loss: 4.5139 - val_f1_score: 0.0291 - val_loss: 3.7265\n",
      "Epoch 2/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - f1_score: 0.0229 - loss: 3.5715\n",
      "Epoch 2: val_loss improved from 3.72651 to 3.10314, saving model to best_model_TFCNN.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - f1_score: 0.0223 - loss: 3.5480 - val_f1_score: 0.0145 - val_loss: 3.1031\n",
      "Epoch 3/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - f1_score: 0.0127 - loss: 2.9820\n",
      "Epoch 3: val_loss improved from 3.10314 to 2.61777, saving model to best_model_TFCNN.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - f1_score: 0.0125 - loss: 2.9634 - val_f1_score: 0.0097 - val_loss: 2.6178\n",
      "Epoch 4/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - f1_score: 0.0088 - loss: 2.5139\n",
      "Epoch 4: val_loss improved from 2.61777 to 2.21462, saving model to best_model_TFCNN.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - f1_score: 0.0087 - loss: 2.4985 - val_f1_score: 0.0072 - val_loss: 2.2146\n",
      "Epoch 5/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - f1_score: 0.0067 - loss: 2.1333\n",
      "Epoch 5: val_loss improved from 2.21462 to 1.87714, saving model to best_model_TFCNN.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - f1_score: 0.0067 - loss: 2.1185 - val_f1_score: 0.0058 - val_loss: 1.8771\n",
      "Epoch 6/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - f1_score: 0.0055 - loss: 1.7991\n",
      "Epoch 6: val_loss improved from 1.87714 to 1.59482, saving model to best_model_TFCNN.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - f1_score: 0.0054 - loss: 1.7877 - val_f1_score: 0.0048 - val_loss: 1.5948\n",
      "Epoch 6: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, Conv1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# 모델 정의\n",
    "num_filters = 64\n",
    "kernel_size = 5\n",
    "dropout_ratio = 0.4\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(num_filters, kernel_size, padding='valid', activation='relu', input_shape=(X_train_tfidf.shape[1], 1)))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dropout(dropout_ratio))\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(dropout_ratio))\n",
    "model.add(Dense(192, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(dropout_ratio))\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(dropout_ratio))\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(dropout_ratio))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=[f1_score])\n",
    "\n",
    "# EarlyStopping 및 ModelCheckpoint 설정\n",
    "es = EarlyStopping(monitor='val_f1_score', mode='max', verbose=1, patience=5)\n",
    "mc = ModelCheckpoint('best_model_TFCNN.keras', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(X_train_tfidf, y_train, epochs=100, batch_size=128, validation_split=0.2, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - f1_score: 0.0047 - loss: 1.5639\n",
      "\n",
      " 테스트 손실값: 1.5775, f1점수: 0.0047\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "loss_TF_CNN, f1_TF_CNN = model.evaluate(X_test_tfidf, y_test)\n",
    "print(\"\\n 테스트 손실값: %.4f, f1점수: %.4f\" % (loss_TF_CNN, f1_TF_CNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(1, len(history.history['f1_score']) + 1)\n",
    "plt.plot(epochs, history.history['f1_score'])\n",
    "plt.plot(epochs, history.history['val_f1_score'])\n",
    "plt.title('Model F1-Score')\n",
    "plt.ylabel('F1-Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 19s]\n",
      "val_f1_score: 0.0398867204785347\n",
      "\n",
      "Best val_f1_score So Far: 0.0398867204785347\n",
      "Total elapsed time: 00h 05m 39s\n",
      "Best hyperparameters:\n",
      "num_filters: 64\n",
      "kernel_size: 5\n",
      "dropout_ratio: 0.4\n",
      "num_dense_layers: 4\n",
      "dense_units_0: 128\n",
      "dense_units_1: 192\n",
      "dense_units_2: 64\n",
      "optimizer: rmsprop\n",
      "batch_size: 128\n",
      "dense_units_3: 128\n",
      "tuner/epochs: 10\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, Dropout, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "import keras_tuner as kt\n",
    "import os\n",
    "\n",
    "# TF-IDF 벡터화\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train).toarray()\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test).toarray()\n",
    "X_train_tfidf = X_train_tfidf.reshape(X_train_tfidf.shape[0], X_train_tfidf.shape[1], 1)\n",
    "X_test_tfidf = X_test_tfidf.reshape(X_test_tfidf.shape[0], X_test_tfidf.shape[1], 1)\n",
    "\n",
    "# 모델을 빌드하는 함수 정의\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=hp.Int('num_filters', min_value=32, max_value=128, step=32),\n",
    "                     kernel_size=hp.Int('kernel_size', min_value=3, max_value=7, step=1),\n",
    "                     activation='relu', input_shape=(X_train_tfidf.shape[1], 1)))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dropout(hp.Float('dropout_ratio', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "\n",
    "    # Dense 층\n",
    "    for i in range(hp.Int('num_dense_layers', 3, 4)):\n",
    "        model.add(Dense(units=hp.Int(f'dense_units_{i}', min_value=64, max_value=256, step=64),\n",
    "                        activation='relu',\n",
    "                        kernel_regularizer=regularizers.l2(0.01)))\n",
    "        model.add(Dropout(hp.Float('dropout_ratio', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "\n",
    "    # 출력층\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=hp.Choice('optimizer', values=['adam', 'rmsprop']),\n",
    "                  loss='binary_crossentropy', metrics=[f1_score])\n",
    "    batch_size = hp.Int('batch_size', min_value=32, max_value=128, step=32)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 튜너 설정\n",
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective='val_f1_score',\n",
    "                     max_epochs=10,\n",
    "                     factor=2,\n",
    "                     directory='C:\\keras_tuner',\n",
    "                     project_name='TF_Den_c5')\n",
    "\n",
    "# EarlyStopping 및 ModelCheckpoint 설정\n",
    "es = EarlyStopping(monitor='val_f1_score', mode='max', verbose=1, patience=15)\n",
    "mc = ModelCheckpoint('best_model.keras', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "# 모델 학습\n",
    "tuner.search(X_train_tfidf, y_train, epochs=10, validation_split=0.2, callbacks=[es, mc])\n",
    "\n",
    "# 최적의 하이퍼파라미터와 모델 정보 출력\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Best hyperparameters:\")\n",
    "for param, value in best_hp.values.items():\n",
    "    print(f\"{param}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer + RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_encoded = tokenizer.texts_to_sequences(X_train)\n",
    "word_to_index = tokenizer.word_index\n",
    "\n",
    "vocab_size = len(word_to_index) + 1\n",
    "max_len = max(len(sample) for sample in X_train_encoded)\n",
    "X_train_padded = pad_sequences(X_train_encoded, maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Tokenizer를 json 형식으로 저장\n",
    "tokenizer_json = tokenizer.to_json()\n",
    "with open('tokenizer.json', 'w') as f:\n",
    "    json.dump(tokenizer_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\양은석\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - f1_score: 0.2362 - loss: 2.7205\n",
      "Epoch 1: val_loss improved from inf to 1.93314, saving model to best_model_TKRNN.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - f1_score: 0.2269 - loss: 2.6912 - val_f1_score: 0.0530 - val_loss: 1.9331\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - f1_score: 0.0413 - loss: 1.7712\n",
      "Epoch 2: val_loss improved from 1.93314 to 1.38853, saving model to best_model_TKRNN.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - f1_score: 0.0411 - loss: 1.7652 - val_f1_score: 0.0267 - val_loss: 1.3885\n",
      "Epoch 3/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - f1_score: 0.0283 - loss: 1.2909\n",
      "Epoch 3: val_loss improved from 1.38853 to 0.96945, saving model to best_model_TKRNN.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - f1_score: 0.0315 - loss: 1.2727 - val_f1_score: 0.0961 - val_loss: 0.9695\n",
      "Epoch 4/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.1215 - loss: 0.9307\n",
      "Epoch 4: val_loss improved from 0.96945 to 0.70882, saving model to best_model_TKRNN.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - f1_score: 0.1257 - loss: 0.9181 - val_f1_score: 0.2272 - val_loss: 0.7088\n",
      "Epoch 5/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.2698 - loss: 0.6511\n",
      "Epoch 5: val_loss improved from 0.70882 to 0.56529, saving model to best_model_TKRNN.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - f1_score: 0.2760 - loss: 0.6419 - val_f1_score: 0.3640 - val_loss: 0.5653\n",
      "Epoch 6/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.3922 - loss: 0.4562\n",
      "Epoch 6: val_loss improved from 0.56529 to 0.40420, saving model to best_model_TKRNN.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - f1_score: 0.3974 - loss: 0.4521 - val_f1_score: 0.4697 - val_loss: 0.4042\n",
      "Epoch 7/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - f1_score: 0.4938 - loss: 0.3342\n",
      "Epoch 7: val_loss improved from 0.40420 to 0.37909, saving model to best_model_TKRNN.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - f1_score: 0.4972 - loss: 0.3335 - val_f1_score: 0.5491 - val_loss: 0.3791\n",
      "Epoch 8/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - f1_score: 0.5671 - loss: 0.2920\n",
      "Epoch 8: val_loss improved from 0.37909 to 0.30929, saving model to best_model_TKRNN.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - f1_score: 0.5690 - loss: 0.2899 - val_f1_score: 0.6059 - val_loss: 0.3093\n",
      "Epoch 9/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - f1_score: 0.6210 - loss: 0.2461\n",
      "Epoch 9: val_loss did not improve from 0.30929\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - f1_score: 0.6214 - loss: 0.2458 - val_f1_score: 0.6477 - val_loss: 0.3236\n",
      "Epoch 10/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.6565 - loss: 0.2206\n",
      "Epoch 10: val_loss improved from 0.30929 to 0.26175, saving model to best_model_TKRNN.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - f1_score: 0.6579 - loss: 0.2211 - val_f1_score: 0.6797 - val_loss: 0.2617\n",
      "Epoch 11/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - f1_score: 0.6882 - loss: 0.2049\n",
      "Epoch 11: val_loss did not improve from 0.26175\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - f1_score: 0.6890 - loss: 0.2030 - val_f1_score: 0.7074 - val_loss: 0.2680\n",
      "Epoch 12/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - f1_score: 0.7136 - loss: 0.2086\n",
      "Epoch 12: val_loss improved from 0.26175 to 0.24094, saving model to best_model_TKRNN.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - f1_score: 0.7144 - loss: 0.2051 - val_f1_score: 0.7300 - val_loss: 0.2409\n",
      "Epoch 13/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.7355 - loss: 0.1845\n",
      "Epoch 13: val_loss improved from 0.24094 to 0.23803, saving model to best_model_TKRNN.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - f1_score: 0.7361 - loss: 0.1832 - val_f1_score: 0.7485 - val_loss: 0.2380\n",
      "Epoch 14/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.7533 - loss: 0.1618\n",
      "Epoch 14: val_loss improved from 0.23803 to 0.23306, saving model to best_model_TKRNN.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - f1_score: 0.7538 - loss: 0.1604 - val_f1_score: 0.7639 - val_loss: 0.2331\n",
      "Epoch 15/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - f1_score: 0.7664 - loss: 0.3317\n",
      "Epoch 15: val_loss did not improve from 0.23306\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.7669 - loss: 0.3156 - val_f1_score: 0.7741 - val_loss: 0.2523\n",
      "Epoch 16/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - f1_score: 0.7778 - loss: 0.1557\n",
      "Epoch 16: val_loss did not improve from 0.23306\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - f1_score: 0.7779 - loss: 0.1561 - val_f1_score: 0.7849 - val_loss: 0.2589\n",
      "Epoch 17/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - f1_score: 0.7877 - loss: 0.1448\n",
      "Epoch 17: val_loss improved from 0.23306 to 0.22829, saving model to best_model_TKRNN.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - f1_score: 0.7880 - loss: 0.1454 - val_f1_score: 0.7949 - val_loss: 0.2283\n",
      "Epoch 18/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - f1_score: 0.7977 - loss: 0.1399\n",
      "Epoch 18: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - f1_score: 0.7979 - loss: 0.1391 - val_f1_score: 0.8041 - val_loss: 0.2319\n",
      "Epoch 19/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - f1_score: 0.8065 - loss: 0.1388\n",
      "Epoch 19: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - f1_score: 0.8066 - loss: 0.1398 - val_f1_score: 0.8112 - val_loss: 0.2709\n",
      "Epoch 20/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - f1_score: 0.8130 - loss: 0.1459\n",
      "Epoch 20: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.8131 - loss: 0.1449 - val_f1_score: 0.8179 - val_loss: 0.2323\n",
      "Epoch 21/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - f1_score: 0.8200 - loss: 0.1369\n",
      "Epoch 21: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.8201 - loss: 0.1361 - val_f1_score: 0.8248 - val_loss: 0.2334\n",
      "Epoch 22/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - f1_score: 0.8265 - loss: 0.1220\n",
      "Epoch 22: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - f1_score: 0.8266 - loss: 0.1216 - val_f1_score: 0.8308 - val_loss: 0.2683\n",
      "Epoch 23/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - f1_score: 0.8320 - loss: 0.1432\n",
      "Epoch 23: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.8323 - loss: 0.1383 - val_f1_score: 0.8362 - val_loss: 0.2409\n",
      "Epoch 24/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - f1_score: 0.8375 - loss: 0.1092\n",
      "Epoch 24: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - f1_score: 0.8378 - loss: 0.1079 - val_f1_score: 0.8410 - val_loss: 0.3005\n",
      "Epoch 25/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - f1_score: 0.8422 - loss: 0.1202\n",
      "Epoch 25: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.8423 - loss: 0.1194 - val_f1_score: 0.8454 - val_loss: 0.2711\n",
      "Epoch 26/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - f1_score: 0.8465 - loss: 0.0976\n",
      "Epoch 26: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.8466 - loss: 0.0977 - val_f1_score: 0.8497 - val_loss: 0.2447\n",
      "Epoch 27/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - f1_score: 0.8510 - loss: 0.1149\n",
      "Epoch 27: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - f1_score: 0.8511 - loss: 0.1142 - val_f1_score: 0.8534 - val_loss: 0.2706\n",
      "Epoch 28/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - f1_score: 0.8544 - loss: 0.1002\n",
      "Epoch 28: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.8545 - loss: 0.1006 - val_f1_score: 0.8569 - val_loss: 0.2405\n",
      "Epoch 29/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - f1_score: 0.8578 - loss: 0.0804\n",
      "Epoch 29: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - f1_score: 0.8580 - loss: 0.0826 - val_f1_score: 0.8602 - val_loss: 0.2592\n",
      "Epoch 30/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.8610 - loss: 0.0823\n",
      "Epoch 30: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - f1_score: 0.8611 - loss: 0.0842 - val_f1_score: 0.8635 - val_loss: 0.2391\n",
      "Epoch 31/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.8643 - loss: 0.1006\n",
      "Epoch 31: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - f1_score: 0.8644 - loss: 0.0987 - val_f1_score: 0.8666 - val_loss: 0.2563\n",
      "Epoch 32/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - f1_score: 0.8674 - loss: 0.0930\n",
      "Epoch 32: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - f1_score: 0.8675 - loss: 0.0921 - val_f1_score: 0.8695 - val_loss: 0.2582\n",
      "Epoch 33/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.8701 - loss: 0.0782\n",
      "Epoch 33: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - f1_score: 0.8703 - loss: 0.0792 - val_f1_score: 0.8721 - val_loss: 0.2574\n",
      "Epoch 34/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.8729 - loss: 0.0775\n",
      "Epoch 34: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - f1_score: 0.8730 - loss: 0.0805 - val_f1_score: 0.8747 - val_loss: 0.2390\n",
      "Epoch 35/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - f1_score: 0.8753 - loss: 0.0915\n",
      "Epoch 35: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - f1_score: 0.8754 - loss: 0.0893 - val_f1_score: 0.8772 - val_loss: 0.2816\n",
      "Epoch 36/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - f1_score: 0.8778 - loss: 0.0941\n",
      "Epoch 36: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - f1_score: 0.8780 - loss: 0.0914 - val_f1_score: 0.8794 - val_loss: 0.2773\n",
      "Epoch 37/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - f1_score: 0.8799 - loss: 0.0803\n",
      "Epoch 37: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - f1_score: 0.8800 - loss: 0.0802 - val_f1_score: 0.8814 - val_loss: 0.2586\n",
      "Epoch 38/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.8820 - loss: 0.0748\n",
      "Epoch 38: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - f1_score: 0.8820 - loss: 0.0752 - val_f1_score: 0.8834 - val_loss: 0.2335\n",
      "Epoch 39/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - f1_score: 0.8840 - loss: 0.0758\n",
      "Epoch 39: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - f1_score: 0.8840 - loss: 0.0758 - val_f1_score: 0.8854 - val_loss: 0.2297\n",
      "Epoch 40/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - f1_score: 0.8859 - loss: 0.0654\n",
      "Epoch 40: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - f1_score: 0.8859 - loss: 0.0663 - val_f1_score: 0.8872 - val_loss: 0.2293\n",
      "Epoch 41/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.8876 - loss: 0.0795\n",
      "Epoch 41: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - f1_score: 0.8877 - loss: 0.0777 - val_f1_score: 0.8889 - val_loss: 0.3053\n",
      "Epoch 42/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - f1_score: 0.8894 - loss: 0.0604\n",
      "Epoch 42: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - f1_score: 0.8895 - loss: 0.0640 - val_f1_score: 0.8904 - val_loss: 0.2620\n",
      "Epoch 43/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - f1_score: 0.8906 - loss: 0.1180\n",
      "Epoch 43: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - f1_score: 0.8907 - loss: 0.1126 - val_f1_score: 0.8918 - val_loss: 0.3041\n",
      "Epoch 44/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - f1_score: 0.8922 - loss: 0.0643\n",
      "Epoch 44: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - f1_score: 0.8923 - loss: 0.0664 - val_f1_score: 0.8933 - val_loss: 0.2690\n",
      "Epoch 45/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - f1_score: 0.8938 - loss: 0.0750\n",
      "Epoch 45: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - f1_score: 0.8938 - loss: 0.0746 - val_f1_score: 0.8948 - val_loss: 0.2760\n",
      "Epoch 46/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - f1_score: 0.8952 - loss: 0.0614\n",
      "Epoch 46: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - f1_score: 0.8952 - loss: 0.0618 - val_f1_score: 0.8961 - val_loss: 0.3126\n",
      "Epoch 47/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - f1_score: 0.8964 - loss: 0.0744\n",
      "Epoch 47: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - f1_score: 0.8965 - loss: 0.0720 - val_f1_score: 0.8975 - val_loss: 0.2839\n",
      "Epoch 48/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - f1_score: 0.8978 - loss: 0.0624\n",
      "Epoch 48: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - f1_score: 0.8979 - loss: 0.0629 - val_f1_score: 0.8988 - val_loss: 0.2660\n",
      "Epoch 49/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - f1_score: 0.8992 - loss: 0.0640\n",
      "Epoch 49: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - f1_score: 0.8992 - loss: 0.0640 - val_f1_score: 0.8999 - val_loss: 0.3790\n",
      "Epoch 50/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - f1_score: 0.9001 - loss: 0.0887\n",
      "Epoch 50: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - f1_score: 0.9001 - loss: 0.0879 - val_f1_score: 0.9009 - val_loss: 0.3076\n",
      "Epoch 51/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.9012 - loss: 0.0543\n",
      "Epoch 51: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - f1_score: 0.9013 - loss: 0.0562 - val_f1_score: 0.9020 - val_loss: 0.2531\n",
      "Epoch 52/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - f1_score: 0.9023 - loss: 0.0779\n",
      "Epoch 52: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - f1_score: 0.9023 - loss: 0.0776 - val_f1_score: 0.9030 - val_loss: 0.2776\n",
      "Epoch 53/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.9032 - loss: 0.0590\n",
      "Epoch 53: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - f1_score: 0.9033 - loss: 0.0597 - val_f1_score: 0.9039 - val_loss: 0.4204\n",
      "Epoch 54/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.9041 - loss: 0.0709\n",
      "Epoch 54: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - f1_score: 0.9041 - loss: 0.0690 - val_f1_score: 0.9049 - val_loss: 0.2823\n",
      "Epoch 55/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - f1_score: 0.9051 - loss: 0.0549\n",
      "Epoch 55: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - f1_score: 0.9052 - loss: 0.0556 - val_f1_score: 0.9058 - val_loss: 0.3145\n",
      "Epoch 56/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - f1_score: 0.9060 - loss: 0.0693\n",
      "Epoch 56: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - f1_score: 0.9060 - loss: 0.0687 - val_f1_score: 0.9067 - val_loss: 0.3050\n",
      "Epoch 57/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.9069 - loss: 0.0507\n",
      "Epoch 57: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - f1_score: 0.9069 - loss: 0.0528 - val_f1_score: 0.9075 - val_loss: 0.2400\n",
      "Epoch 58/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.9077 - loss: 0.0592\n",
      "Epoch 58: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - f1_score: 0.9078 - loss: 0.0581 - val_f1_score: 0.9085 - val_loss: 0.2843\n",
      "Epoch 59/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - f1_score: 0.9087 - loss: 0.0463\n",
      "Epoch 59: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - f1_score: 0.9087 - loss: 0.0472 - val_f1_score: 0.9093 - val_loss: 0.2888\n",
      "Epoch 60/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - f1_score: 0.9095 - loss: 0.0535\n",
      "Epoch 60: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - f1_score: 0.9096 - loss: 0.0538 - val_f1_score: 0.9102 - val_loss: 0.3132\n",
      "Epoch 61/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.9104 - loss: 0.0497\n",
      "Epoch 61: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - f1_score: 0.9104 - loss: 0.0508 - val_f1_score: 0.9110 - val_loss: 0.2815\n",
      "Epoch 62/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.9112 - loss: 0.0575\n",
      "Epoch 62: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - f1_score: 0.9112 - loss: 0.0571 - val_f1_score: 0.9118 - val_loss: 0.3778\n",
      "Epoch 63/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - f1_score: 0.9119 - loss: 0.0747\n",
      "Epoch 63: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - f1_score: 0.9120 - loss: 0.0722 - val_f1_score: 0.9125 - val_loss: 0.3215\n",
      "Epoch 64/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - f1_score: 0.9126 - loss: 0.0693\n",
      "Epoch 64: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - f1_score: 0.9127 - loss: 0.0659 - val_f1_score: 0.9133 - val_loss: 0.2991\n",
      "Epoch 65/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - f1_score: 0.9135 - loss: 0.0552\n",
      "Epoch 65: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - f1_score: 0.9135 - loss: 0.0554 - val_f1_score: 0.9139 - val_loss: 0.3166\n",
      "Epoch 66/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - f1_score: 0.9140 - loss: 0.0615\n",
      "Epoch 66: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - f1_score: 0.9141 - loss: 0.0611 - val_f1_score: 0.9145 - val_loss: 0.2769\n",
      "Epoch 67/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - f1_score: 0.9147 - loss: 0.0561\n",
      "Epoch 67: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - f1_score: 0.9147 - loss: 0.0553 - val_f1_score: 0.9151 - val_loss: 0.3185\n",
      "Epoch 68/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.9153 - loss: 0.0645\n",
      "Epoch 68: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - f1_score: 0.9153 - loss: 0.0624 - val_f1_score: 0.9158 - val_loss: 0.3391\n",
      "Epoch 69/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - f1_score: 0.9159 - loss: 0.0555\n",
      "Epoch 69: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - f1_score: 0.9159 - loss: 0.0552 - val_f1_score: 0.9164 - val_loss: 0.3276\n",
      "Epoch 70/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.9166 - loss: 0.0462\n",
      "Epoch 70: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - f1_score: 0.9166 - loss: 0.0464 - val_f1_score: 0.9170 - val_loss: 0.3349\n",
      "Epoch 71/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - f1_score: 0.9171 - loss: 0.0530\n",
      "Epoch 71: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - f1_score: 0.9172 - loss: 0.0530 - val_f1_score: 0.9176 - val_loss: 0.2874\n",
      "Epoch 72/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.9178 - loss: 0.0444\n",
      "Epoch 72: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - f1_score: 0.9178 - loss: 0.0448 - val_f1_score: 0.9182 - val_loss: 0.2873\n",
      "Epoch 73/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - f1_score: 0.9184 - loss: 0.0440\n",
      "Epoch 73: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - f1_score: 0.9184 - loss: 0.0443 - val_f1_score: 0.9188 - val_loss: 0.2954\n",
      "Epoch 74/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.9189 - loss: 0.0457\n",
      "Epoch 74: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - f1_score: 0.9190 - loss: 0.0460 - val_f1_score: 0.9194 - val_loss: 0.3214\n",
      "Epoch 75/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.9195 - loss: 0.0548\n",
      "Epoch 75: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - f1_score: 0.9195 - loss: 0.0547 - val_f1_score: 0.9199 - val_loss: 0.2969\n",
      "Epoch 76/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - f1_score: 0.9200 - loss: 0.0530\n",
      "Epoch 76: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - f1_score: 0.9200 - loss: 0.0522 - val_f1_score: 0.9204 - val_loss: 0.3146\n",
      "Epoch 77/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.9206 - loss: 0.0581\n",
      "Epoch 77: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - f1_score: 0.9206 - loss: 0.0562 - val_f1_score: 0.9210 - val_loss: 0.3812\n",
      "Epoch 78/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - f1_score: 0.9211 - loss: 0.0475\n",
      "Epoch 78: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - f1_score: 0.9211 - loss: 0.0475 - val_f1_score: 0.9215 - val_loss: 0.3200\n",
      "Epoch 79/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - f1_score: 0.9217 - loss: 0.0498\n",
      "Epoch 79: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - f1_score: 0.9217 - loss: 0.0495 - val_f1_score: 0.9220 - val_loss: 0.4012\n",
      "Epoch 80/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - f1_score: 0.9221 - loss: 0.0467\n",
      "Epoch 80: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - f1_score: 0.9221 - loss: 0.0467 - val_f1_score: 0.9225 - val_loss: 0.3449\n",
      "Epoch 81/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.9226 - loss: 0.0602\n",
      "Epoch 81: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - f1_score: 0.9226 - loss: 0.0583 - val_f1_score: 0.9230 - val_loss: 0.3522\n",
      "Epoch 82/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.9231 - loss: 0.0480\n",
      "Epoch 82: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - f1_score: 0.9231 - loss: 0.0479 - val_f1_score: 0.9233 - val_loss: 0.5323\n",
      "Epoch 83/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - f1_score: 0.9233 - loss: 0.0706\n",
      "Epoch 83: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - f1_score: 0.9233 - loss: 0.0698 - val_f1_score: 0.9236 - val_loss: 0.3676\n",
      "Epoch 84/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.9237 - loss: 0.0340\n",
      "Epoch 84: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - f1_score: 0.9238 - loss: 0.0367 - val_f1_score: 0.9240 - val_loss: 0.3410\n",
      "Epoch 85/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.9241 - loss: 0.0463\n",
      "Epoch 85: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - f1_score: 0.9241 - loss: 0.0459 - val_f1_score: 0.9245 - val_loss: 0.3014\n",
      "Epoch 86/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.9245 - loss: 0.0499\n",
      "Epoch 86: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - f1_score: 0.9246 - loss: 0.0492 - val_f1_score: 0.9249 - val_loss: 0.3129\n",
      "Epoch 87/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - f1_score: 0.9250 - loss: 0.0399\n",
      "Epoch 87: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - f1_score: 0.9251 - loss: 0.0402 - val_f1_score: 0.9254 - val_loss: 0.3114\n",
      "Epoch 88/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.9254 - loss: 0.0471\n",
      "Epoch 88: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - f1_score: 0.9255 - loss: 0.0470 - val_f1_score: 0.9257 - val_loss: 0.2999\n",
      "Epoch 89/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.9259 - loss: 0.0383\n",
      "Epoch 89: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - f1_score: 0.9259 - loss: 0.0396 - val_f1_score: 0.9262 - val_loss: 0.3109\n",
      "Epoch 90/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.9263 - loss: 0.0490\n",
      "Epoch 90: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - f1_score: 0.9263 - loss: 0.0487 - val_f1_score: 0.9266 - val_loss: 0.3152\n",
      "Epoch 91/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.9267 - loss: 0.0356\n",
      "Epoch 91: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - f1_score: 0.9267 - loss: 0.0380 - val_f1_score: 0.9269 - val_loss: 0.2634\n",
      "Epoch 92/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.9270 - loss: 0.0376\n",
      "Epoch 92: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - f1_score: 0.9271 - loss: 0.0380 - val_f1_score: 0.9273 - val_loss: 0.2824\n",
      "Epoch 93/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.9274 - loss: 0.0506\n",
      "Epoch 93: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - f1_score: 0.9274 - loss: 0.0499 - val_f1_score: 0.9277 - val_loss: 0.3472\n",
      "Epoch 94/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.9278 - loss: 0.0387\n",
      "Epoch 94: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - f1_score: 0.9278 - loss: 0.0394 - val_f1_score: 0.9281 - val_loss: 0.3203\n",
      "Epoch 95/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - f1_score: 0.9282 - loss: 0.0563\n",
      "Epoch 95: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - f1_score: 0.9282 - loss: 0.0558 - val_f1_score: 0.9284 - val_loss: 0.3390\n",
      "Epoch 96/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - f1_score: 0.9285 - loss: 0.0501\n",
      "Epoch 96: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - f1_score: 0.9285 - loss: 0.0485 - val_f1_score: 0.9288 - val_loss: 0.3043\n",
      "Epoch 97/100\n",
      "\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - f1_score: 0.9289 - loss: 0.0504\n",
      "Epoch 97: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - f1_score: 0.9289 - loss: 0.0497 - val_f1_score: 0.9292 - val_loss: 0.3511\n",
      "Epoch 98/100\n",
      "\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - f1_score: 0.9293 - loss: 0.0346\n",
      "Epoch 98: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - f1_score: 0.9293 - loss: 0.0360 - val_f1_score: 0.9295 - val_loss: 0.3232\n",
      "Epoch 99/100\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - f1_score: 0.9296 - loss: 0.0462\n",
      "Epoch 99: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - f1_score: 0.9296 - loss: 0.0456 - val_f1_score: 0.9299 - val_loss: 0.3265\n",
      "Epoch 100/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - f1_score: 0.9300 - loss: 0.0386\n",
      "Epoch 100: val_loss did not improve from 0.22829\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - f1_score: 0.9300 - loss: 0.0389 - val_f1_score: 0.9302 - val_loss: 0.3180\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "embedding_dim = 64\n",
    "dropout_ratio = 0.3\n",
    "units = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
    "model.add(Dropout(dropout_ratio))\n",
    "model.add(LSTM(units, return_sequences=False, kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(dropout_ratio))\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(dropout_ratio))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=[f1_score])\n",
    "\n",
    "# EarlyStopping 및 ModelCheckpoint 설정\n",
    "es = EarlyStopping(monitor='val_f1_score', mode='max', verbose=1, patience=15)\n",
    "mc = ModelCheckpoint('best_model_TKRNN.keras', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "history = model.fit(X_train_padded, y_train, epochs=100, batch_size=64, validation_split=0.2, callbacks=[es, mc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - f1_score: 0.9293 - loss: 0.2224\n",
      "\n",
      " 테스트 손실값: 0.2595, 점수: 0.9292\n"
     ]
    }
   ],
   "source": [
    "X_test_encoded = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_padded = pad_sequences(X_test_encoded, maxlen = max_len)\n",
    "loss_TK_RNN, f1_TK_RNN = model.evaluate(X_test_padded, y_test)\n",
    "print(\"\\n 테스트 손실값: %.4f, 점수: %.4f\" % (loss_TK_RNN, f1_TK_RNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(1, len(history.history['f1_score']) + 1)\n",
    "plt.plot(epochs, history.history['f1_score'])\n",
    "plt.plot(epochs, history.history['val_f1_score'])\n",
    "plt.title('Model F1-Score')\n",
    "plt.ylabel('F1-Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "64                |64                |embedding_dim\n",
      "0.2               |0.2               |lstm_dropout\n",
      "64                |64                |units\n",
      "0.3               |0.3               |dense_dropout\n",
      "1                 |1                 |num_dense_layers\n",
      "64                |64                |dense_units_0\n",
      "rmsprop           |rmsprop           |optimizer\n",
      "96                |96                |batch_size\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - f1_score: 0.9213 - loss: 1.9708 - val_f1_score: 0.9180 - val_loss: 1.3346\n",
      "Epoch 2/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - f1_score: 0.9166 - loss: 1.1881 - val_f1_score: 0.9137 - val_loss: 0.8528\n",
      "Epoch 3/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - f1_score: 0.9126 - loss: 0.7779 - val_f1_score: 0.9113 - val_loss: 0.5600\n",
      "Epoch 4/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - f1_score: 0.9110 - loss: 0.5017 - val_f1_score: 0.9104 - val_loss: 0.4185\n",
      "Epoch 5/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - f1_score: 0.9102 - loss: 0.3796 - val_f1_score: 0.9100 - val_loss: 0.3332\n",
      "Epoch 6/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - f1_score: 0.9100 - loss: 0.2630 - val_f1_score: 0.9100 - val_loss: 0.2951\n",
      "Epoch 7/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - f1_score: 0.9100 - loss: 0.2375 - val_f1_score: 0.9099 - val_loss: 0.3338\n",
      "Epoch 8/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - f1_score: 0.9099 - loss: 0.2132 - val_f1_score: 0.9100 - val_loss: 0.2707\n",
      "Epoch 9/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - f1_score: 0.9100 - loss: 0.1906 - val_f1_score: 0.9102 - val_loss: 0.2455\n",
      "Epoch 10/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - f1_score: 0.9103 - loss: 0.1667 - val_f1_score: 0.9104 - val_loss: 0.2576\n",
      "Epoch 11/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - f1_score: 0.9105 - loss: 0.1379 - val_f1_score: 0.9106 - val_loss: 0.2918\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 52\u001b[0m\n\u001b[0;32m     49\u001b[0m es \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_padded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# 최적의 하이퍼파라미터와 모델 정보 출력\u001b[39;00m\n\u001b[0;32m     55\u001b[0m best_model \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mget_best_models(num_models\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\양은석\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:234\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[1;32mc:\\Users\\양은석\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:274\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m    275\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\양은석\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:239\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m--> 239\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m    242\u001b[0m     ):\n\u001b[0;32m    243\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[0;32m    245\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[0;32m    246\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    254\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    255\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\양은석\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[0;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[1;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_and_fit_model(trial, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[1;32mc:\\Users\\양은석\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[0;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[1;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhypermodel\u001b[38;5;241m.\u001b[39mfit(hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "File \u001b[1;32mc:\\Users\\양은석\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\양은석\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\양은석\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    322\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Embedding, Dropout, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "import keras_tuner as kt\n",
    "import os\n",
    "\n",
    "\n",
    "# 모델을 빌드하는 함수 정의\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    embedding_dim = hp.Int('embedding_dim', min_value=32, max_value=128, step=32)\n",
    "    model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
    "    lstm_dropout = hp.Float('lstm_dropout', min_value=0.2, max_value=0.5, step=0.1)\n",
    "    model.add(Dropout(lstm_dropout))\n",
    "\n",
    "    # LSTM 층\n",
    "    units = hp.Int('units', min_value=64, max_value=256, step=64)\n",
    "    model.add(LSTM(units, return_sequences=False, kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dropout(lstm_dropout))\n",
    "\n",
    "    # Dense 층 및 Dropout\n",
    "    dense_dropout = hp.Float('dense_dropout', min_value=0.2, max_value=0.5, step=0.1)\n",
    "    num_dense_layers = hp.Int('num_dense_layers', 1, 4)\n",
    "    for i in range(num_dense_layers):\n",
    "        model.add(Dense(units=hp.Int(f'dense_units_{i}', min_value=64, max_value=256, step=64),\n",
    "                        activation='relu',\n",
    "                        kernel_regularizer=regularizers.l2(0.01)))\n",
    "        model.add(Dropout(dense_dropout))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=hp.Choice('optimizer', values=['adam', 'rmsprop']),\n",
    "                  loss='binary_crossentropy', metrics=[f1_score])\n",
    "    \n",
    "    batch_size = hp.Int('batch_size', min_value=32, max_value=128, step=32)\n",
    "    return model\n",
    "\n",
    "# 하이퍼파라미터 튜너 설정 (Hyperband)\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_f1_score',\n",
    "    max_epochs=100,\n",
    "    factor=3,\n",
    "    directory='C:\\keras_tuner',\n",
    "    project_name='TK_RNN_c7'\n",
    ")\n",
    "\n",
    "# EarlyStopping 및 ModelCheckpoint 설정\n",
    "es = EarlyStopping(monitor='val_f1_score', mode='max', verbose=1, patience=15)\n",
    "mc = ModelCheckpoint('best_model.keras', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "# 모델 학습\n",
    "tuner.search(X_train_padded, y_train, epochs=100, validation_split=0.2, callbacks=[es, mc])\n",
    "\n",
    "# 최적의 하이퍼파라미터와 모델 정보 출력\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Best hyperparameters:\")\n",
    "for param, value in best_hp.values.items():\n",
    "    print(f\"{param}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 15s]\n",
      "val_f1_score: 0.8664000630378723\n",
      "\n",
      "Best val_f1_score So Far: 0.8652507066726685\n",
      "Total elapsed time: 00h 08m 39s\n",
      "Best hyperparameters:\n",
      "embedding_dim: 128\n",
      "lstm_dropout: 0.2\n",
      "units: 64\n",
      "dense_dropout: 0.4\n",
      "dense_units_1: 128\n",
      "optimizer: adam\n",
      "batch_size: 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\양은석\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding, Dropout, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "import keras_tuner as kt\n",
    "import os\n",
    "\n",
    "\n",
    "# 모델을 빌드하는 함수 정의\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    embedding_dim = hp.Int('embedding_dim', min_value=32, max_value=128, step=32)\n",
    "    model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
    "    lstm_dropout = hp.Float('lstm_dropout', min_value=0.2, max_value=0.5, step=0.1)\n",
    "    model.add(Dropout(lstm_dropout))\n",
    "\n",
    "    # LSTM 층\n",
    "    units = hp.Int('units', min_value=64, max_value=256, step=64)\n",
    "    model.add(LSTM(units, return_sequences=False, kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dropout(lstm_dropout))\n",
    "\n",
    "    # Dense 층 및 Dropout\n",
    "    dense_dropout = hp.Float('dense_dropout', min_value=0.2, max_value=0.5, step=0.1)\n",
    "    model.add(Dense(units=hp.Int(f'dense_units_1', min_value=64, max_value=256, step=64),\n",
    "                        activation='relu',\n",
    "                        kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dropout(dense_dropout))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=hp.Choice('optimizer', values=['adam', 'rmsprop']),\n",
    "                  loss='binary_crossentropy', metrics=[f1_score])\n",
    "    \n",
    "    batch_size = hp.Int('batch_size', min_value=32, max_value=128, step=32)\n",
    "    return model\n",
    "\n",
    "# 하이퍼파라미터 튜너 설정 (BayesianOptimization)\n",
    "tuner = kt.BayesianOptimization(\n",
    "    build_model,\n",
    "    objective='val_f1_score',\n",
    "    max_trials=30,\n",
    "    executions_per_trial=1,\n",
    "    directory='C:\\keras_tuner',\n",
    "    project_name='TK_RNN_c9'\n",
    ")\n",
    "\n",
    "# EarlyStopping 및 ModelCheckpoint 설정\n",
    "es = EarlyStopping(monitor='val_f1_score', mode='max', verbose=1, patience=15)\n",
    "mc = ModelCheckpoint('best_model.keras', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "# 모델 학습\n",
    "tuner.search(X_train_padded, y_train, epochs=100, validation_split=0.2, callbacks=[es, mc])\n",
    "\n",
    "# 최적의 하이퍼파라미터와 모델 정보 출력\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Best hyperparameters:\")\n",
    "for param, value in best_hp.values.items():\n",
    "    print(f\"{param}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF + RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF 벡터화\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=2000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train).toarray()\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test).toarray()\n",
    "\n",
    "# TF-IDF 데이터를 LSTM에 맞는 3D 배열로 변환\n",
    "X_train_tfidf = X_train_tfidf.reshape(X_train_tfidf.shape[0], X_train_tfidf.shape[1], 1)\n",
    "X_test_tfidf = X_test_tfidf.reshape(X_test_tfidf.shape[0], X_test_tfidf.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\양은석\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756ms/step - f1_score: 0.0493 - loss: 1.0340\n",
      "Epoch 1: val_loss improved from inf to 0.89904, saving model to best_model.keras\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 823ms/step - f1_score: 0.0486 - loss: 1.0326 - val_f1_score: 0.0045 - val_loss: 0.8990\n",
      "Epoch 2/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737ms/step - f1_score: 0.0034 - loss: 0.8619\n",
      "Epoch 2: val_loss improved from 0.89904 to 0.80285, saving model to best_model.keras\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 785ms/step - f1_score: 0.0034 - loss: 0.8611 - val_f1_score: 0.0022 - val_loss: 0.8029\n",
      "Epoch 3/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744ms/step - f1_score: 0.0019 - loss: 0.7587\n",
      "Epoch 3: val_loss improved from 0.80285 to 0.73946, saving model to best_model.keras\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 792ms/step - f1_score: 0.0019 - loss: 0.7585 - val_f1_score: 0.0014 - val_loss: 0.7395\n",
      "Epoch 4/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740ms/step - f1_score: 0.0013 - loss: 0.7173\n",
      "Epoch 4: val_loss improved from 0.73946 to 0.69971, saving model to best_model.keras\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 789ms/step - f1_score: 0.0013 - loss: 0.7168 - val_f1_score: 0.0011 - val_loss: 0.6997\n",
      "Epoch 4: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.layers import Dense, Dropout, GRU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# 모델 정의\n",
    "num_units = 32\n",
    "dropout_ratio = 0.4\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GRU(num_units, return_sequences=False, input_shape=(X_train_tfidf.shape[1], 1)))\n",
    "model.add(Dropout(dropout_ratio))\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(dropout_ratio))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=[f1_score])\n",
    "\n",
    "# EarlyStopping 및 ModelCheckpoint 설정\n",
    "es = EarlyStopping(monitor='val_f1_score', mode='max', verbose=1, patience=3)\n",
    "mc = ModelCheckpoint('best_model_TFRNN.keras', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(X_train_tfidf, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 201ms/step - f1_score: 9.5406e-04 - loss: 0.6675\n",
      "\n",
      " 테스트 손실값: 0.6819, f1점수: 0.0009\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "loss_TF_RNN, f1_TF_RNN = model.evaluate(X_test_tfidf, y_test)\n",
    "print(\"\\n 테스트 손실값: %.4f, f1점수: %.4f\" % (loss_TF_RNN, f1_TF_RNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(1, len(history.history['f1_score']) + 1)\n",
    "plt.plot(epochs, history.history['f1_score'])\n",
    "plt.plot(epochs, history.history['val_f1_score'])\n",
    "plt.title('Model F1-Score')\n",
    "plt.ylabel('F1-Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 08m 41s]\n",
      "val_f1_score: 0.0008955238154157996\n",
      "\n",
      "Best val_f1_score So Far: 0.0008595056715421379\n",
      "Total elapsed time: 01h 41m 59s\n",
      "Best hyperparameters:\n",
      "num_units: 64\n",
      "dropout_ratio: 0.30000000000000004\n",
      "dense_units: 128\n",
      "optimizer: adam\n",
      "batch_size: 64\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 2\n",
      "tuner/round: 0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, Dropout, GRU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "import keras_tuner as kt\n",
    "import os\n",
    "\n",
    "# 모델을 빌드하는 함수 정의\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(\n",
    "        hp.Int('num_units', min_value=32, max_value=128, step=32), \n",
    "        return_sequences=False, \n",
    "        input_shape=(X_train_tfidf.shape[1], 1)\n",
    "    ))\n",
    "    model.add(Dropout(hp.Float('dropout_ratio', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    # Dense 층\n",
    "    model.add(Dense(\n",
    "        hp.Int('dense_units', min_value=64, max_value=256, step=64), \n",
    "        activation='relu', \n",
    "        kernel_regularizer=regularizers.l2(0.01)\n",
    "    ))\n",
    "    model.add(Dropout(hp.Float('dropout_ratio', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "\n",
    "    # 출력층\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=hp.Choice('optimizer', values=['adam', 'rmsprop']),\n",
    "                  loss='binary_crossentropy', metrics=[f1_score])\n",
    "    batch_size = hp.Int('batch_size', min_value=32, max_value=128, step=32)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 튜너 설정\n",
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective='val_f1_score',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='C:\\keras_tuner',\n",
    "                     project_name='TF_RNN_c1')\n",
    "\n",
    "# EarlyStopping 콜백 정의\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', patience=3)\n",
    "mc = ModelCheckpoint('best_model.keras', monitor='f1_score', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "\n",
    "# 모델 학습\n",
    "tuner.search(X_train_tfidf, y_train, epochs=10, validation_split=0.2, callbacks=[es])\n",
    "\n",
    "# 최적의 하이퍼파라미터와 모델 정보 출력\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Best hyperparameters:\")\n",
    "for param, value in best_hp.values.items():\n",
    "    print(f\"{param}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF + Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB(alpha=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB(alpha=0.1)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB(alpha=0.1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# TF-IDF 벡터화\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "model = MultinomialNB(alpha=0.1, fit_prior=True)\n",
    "model.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.01, F1-score: 0.8991596638655462, loss: 0.21605626237679926\n",
      "Alpha: 0.1, F1-score: 0.8925619834710744, loss: 0.21605626237679926\n",
      "Alpha: 0.5, F1-score: 0.8879668049792531, loss: 0.21605626237679926\n",
      "Alpha: 1.0, F1-score: 0.8870292887029289, loss: 0.21605626237679926\n",
      "Alpha: 10.0, F1-score: 0.6979166666666666, loss: 0.21605626237679926\n"
     ]
    }
   ],
   "source": [
    "alpha_values = [0.01, 0.1, 0.5, 1.0, 10.0]\n",
    "for alpha in alpha_values:\n",
    "    model = MultinomialNB(alpha=alpha, fit_prior=True)\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f\"Alpha: {alpha}, F1-score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 테스트 손실값: 0.2161, f1 점수: 0.8926\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, log_loss\n",
    "\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "y_pred_proba = model.predict_proba(X_test_tfidf)\n",
    "\n",
    "f1_TF_NB = f1_score(y_test, y_pred)\n",
    "loss_TF_NB = log_loss(y_test, y_pred_proba)\n",
    "print(\"\\n 테스트 손실값: %.4f, f1 점수: %.4f\" % (loss_TF_NB, f1_TF_NB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, 'best_model_TFNB.pkl')\n",
    "joblib.dump(tfidf_vectorizer, 'best_model_TFNB_vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import fasttext\n",
    "\n",
    "# FastText 학습을 위한 파일로 변환\n",
    "with open(\"train.txt\", \"w\") as f:\n",
    "    for text, label in zip(X_train, y_train):\n",
    "        f.write(f'__label__{label} {text}\\n')\n",
    "\n",
    "# FastText 모델 학습\n",
    "model = fasttext.train_supervised(input=\"train.txt\", lr=0.1, epoch=100, wordNgrams=2, dim=200, minCount=5, verbose=2)\n",
    "\n",
    "# 학습된 모델로 예측 수행\n",
    "y_pred = []\n",
    "for text in X_test:\n",
    "    cleaned_text = text.strip().replace(\"\\n\", \"\")\n",
    "    predicted_label = model.predict(cleaned_text)[0][0].replace(\"__label__\", \"\")\n",
    "    y_pred.append(predicted_label)\n",
    "\n",
    "# f1_score 계산\n",
    "y_test = [str(label) for label in y_test]\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"best_model_FT.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10, max_iter=1000, random_state=0, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=10, max_iter=1000, random_state=0, solver=&#x27;liblinear&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=10, max_iter=1000, random_state=0, solver='liblinear')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# TF-IDF 벡터화\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=2000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words='english',\n",
    "    min_df=1\n",
    ")\n",
    "\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Logistic Regression 모델 학습\n",
    "model = LogisticRegression(\n",
    "    C=10,\n",
    "    penalty='l2',\n",
    "    solver='liblinear',\n",
    "    max_iter=1000,\n",
    "    random_state=0\n",
    ")\n",
    "model.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측\n",
    "y_pred = model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9270384907722473\n"
     ]
    }
   ],
   "source": [
    "# f1_score 계산\n",
    "f1_TF_LR = f1_score(y_test, y_pred)\n",
    "print(f\"F1 Score: {f1_TF_LR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(model, 'best_model_TFLR.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'lr__C': 10, 'lr__penalty': 'l2', 'lr__solver': 'liblinear', 'tfidf__max_features': 2000, 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': 'english'}\n",
      "F1 Score: 0.927038626609442\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# TfidfVectorizer와 LogisticRegression을 결합한 파이프라인\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('lr', LogisticRegression(max_iter=1000, random_state=0))\n",
    "])\n",
    "\n",
    "# TfidfVectorizer 하이퍼파라미터 그리드\n",
    "tfidf_params = {\n",
    "    'tfidf__max_features': [2000, 5000, 10000],\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'tfidf__stop_words': [None, 'english'],\n",
    "    'tfidf__min_df': [1, 5],\n",
    "}\n",
    "\n",
    "# LogisticRegression 하이퍼파라미터 그리드\n",
    "lr_params = {\n",
    "    'lr__C': [0.1, 1, 10],\n",
    "    'lr__penalty': ['l2'],\n",
    "    'lr__solver': ['liblinear', 'saga'],\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "param_grid = {**tfidf_params, **lr_params}\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='f1')\n",
    "\n",
    "# 모델 학습\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적 하이퍼파라미터와 성능 확인\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# 예측 및 F1 Score 계산\n",
    "y_pred = grid_search.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f1_TK_CNN = 0.9324  \n",
    "f1_TF_CNN = 0.0047\n",
    "\n",
    "f1_TK_RNN = 0.9330  \n",
    "f1_TF_RNN = 0.0009\n",
    "\n",
    "f1_TF_NB =  0.8926  \n",
    "f1_FT    =  0.9363  \n",
    "f1_TF_LR =  0.9270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "models = ['f1_TK_CNN', 'f1_TF_CNN', 'f1_TK_RNN', 'f1_TF_RNN', 'f1_TF_NB', 'f1_FT', 'f1_TF_LR']\n",
    "f1_scores = [0.9324, 0.0047, 0.9330, 0.0009, 0.8926, 0.9363, 0.9270]\n",
    "\n",
    "# 그래프 크기 설정\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# 막대그래프 그리기\n",
    "plt.bar(models, f1_scores, color=['blue', 'blue', 'green', 'green', 'orange', 'red', 'purple'])\n",
    "\n",
    "# 그래프 제목과 축 레이블 추가\n",
    "plt.title('result')\n",
    "plt.xlabel('model')\n",
    "plt.ylabel('F1 Score')\n",
    "\n",
    "# 그래프 출력\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# 그래프 출력\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 메일함 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import socket\n",
    "import time\n",
    "\n",
    "precision_metric = Precision()\n",
    "recall_metric = Recall()\n",
    "\n",
    "# F1-score 계산 함수\n",
    "def f1_score(y_true, y_pred):\n",
    "    precision = precision_metric(y_true, y_pred)\n",
    "    recall = recall_metric(y_true, y_pred)\n",
    "    \n",
    "    # F1-score 계산: 2 * (precision * recall) / (precision + recall)\n",
    "    return 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "\n",
    "\n",
    "# 타임아웃이 발생할 경우 재시도\n",
    "def search_with_retry(mail, search_condition, retries=3, delay=5):\n",
    "    attempt = 0\n",
    "    while attempt < retries:\n",
    "        try:\n",
    "            # 검색 조건을 UTF-8로 인코딩하여 바이트 형식으로 전달\n",
    "            status, messages = mail.search(None, search_condition.encode('utf-8'))\n",
    "            if status == \"OK\":\n",
    "                return messages\n",
    "            else:\n",
    "                print(\"검색 실패. 다시 시도 중...\")\n",
    "                time.sleep(delay)\n",
    "        except (imaplib.IMAP4.abort, socket.error) as e:\n",
    "            print(f\"IMAP 서버 오류 또는 네트워크 오류 발생: {e}. 재시도 중...\")\n",
    "            time.sleep(delay)\n",
    "        attempt += 1\n",
    "    raise Exception(\"검색에 실패했습니다. 재시도 횟수를 초과했습니다.\")\n",
    "\n",
    "\n",
    "# 텍스트 전처리\n",
    "def predict_spam(subject):\n",
    "    processed_subject = subject.lower()\n",
    "    processed_subject = tokenizer.texts_to_sequences([processed_subject])\n",
    "    \n",
    "    # 시퀀스가 비어있는지 확인\n",
    "    if len(processed_subject[0]) == 0:\n",
    "        return 0\n",
    "        \n",
    "    # 패딩 적용\n",
    "    processed_subject = pad_sequences(processed_subject, maxlen=19)\n",
    "    \n",
    "    # 예측\n",
    "    prediction = model.predict(processed_subject)\n",
    "    \n",
    "    if prediction[0][0] > 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# 날짜변환 \n",
    "def convert_date(date_str):\n",
    "    month_map = {\n",
    "        '01': 'Jan', '02': 'Feb', '03': 'Mar', '04': 'Apr',\n",
    "        '05': 'May', '06': 'Jun', '07': 'Jul', '08': 'Aug',\n",
    "        '09': 'Sep', '10': 'Oct', '11': 'Nov', '12': 'Dec'\n",
    "    }\n",
    "\n",
    "    # 날짜 입력 형식: 2022-01-31\n",
    "    try:\n",
    "        year, month, day = date_str.split('-')\n",
    "\n",
    "        if len(year) != 4 or not year.isdigit():\n",
    "            raise ValueError(\"잘못된 연도입니다.\")\n",
    "\n",
    "        if not month.isdigit() or int(month) not in range(1, 13):\n",
    "            raise ValueError(\"잘못된 월입니다.\")\n",
    "        \n",
    "        if len(day) != 2 or not day.isdigit() or not (1 <= int(day) <= 31):\n",
    "            raise ValueError(\"잘못된 날짜입니다.\")\n",
    "        \n",
    "        # 숫자 월을 영어로 변환\n",
    "        month_name = month_map.get(month)\n",
    "        if not month_name:\n",
    "            raise ValueError(\"잘못된 월입니다.\")\n",
    "\n",
    "        # 변환된 날짜 반환\n",
    "        return f\"{day}-{month_name}-{year}\"\n",
    "\n",
    "    except ValueError as e:\n",
    "        return f\"오류: {e}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"날짜 형식이 잘못되었습니다. {str(e)}\"\n",
    "\n",
    "\n",
    "# 메일함 선택\n",
    "def select_search_condition():\n",
    "    print(\"메일 검색 조건을 선택하세요:\")\n",
    "    print(\"1. 모든 메일 (ALL)\")\n",
    "    print(\"2. 읽지 않은 메일 (UNSEEN)\")\n",
    "    print(\"3. 최근 메일 (RECENT)\")\n",
    "    print(\"4. 읽은 메일 (SEEN)\")\n",
    "    print(\"5. 답장한 메일 (ANSWERED)\")\n",
    "    print(\"6. 삭제된 메일 (DELETED)\")\n",
    "    print(\"7. 초안 메일 (DRAFT)\")\n",
    "    print(\"8. 중요 표시된 메일 (FLAGGED)\")\n",
    "    print(\"9. 특정 날짜 이후 받은 메일 (SINCE)\")\n",
    "    print(\"10. 특정 날짜 이전 받은 메일 (BEFORE)\")\n",
    "    print(\"11. 특정 날짜에 받은 메일 (ON)\")\n",
    "    print(\"12. 본문에 특정단어가가 포함된 메일 (BODY)\")\n",
    "\n",
    "    while True:\n",
    "        search_condition = input(\"검색 조건을 선택 (1~12): \")\n",
    "        \n",
    "        if search_condition == '1':\n",
    "            print(\"모든 메일을 선택\")\n",
    "            return \"ALL\"\n",
    "        elif search_condition == '2':\n",
    "            print(\"읽지 않은 메일을 선택\")\n",
    "            return \"UNSEEN\"\n",
    "        elif search_condition == '3':\n",
    "            print(\"최근 메일을 선택\")\n",
    "            return \"RECENT\"\n",
    "        elif search_condition == '4':\n",
    "            print(\"읽은 메일을 선택\")\n",
    "            return \"SEEN\"\n",
    "        elif search_condition == '5':\n",
    "            print(\"답장한 메일을 선택\")\n",
    "            return \"ANSWERED\"\n",
    "        elif search_condition == '6':\n",
    "            print(\"삭제된 메일을 선택\")\n",
    "            return \"DELETED\"\n",
    "        elif search_condition == '7':\n",
    "            print(\"초안 메일을 선택\")\n",
    "            return \"DRAFT\"\n",
    "        elif search_condition == '8':\n",
    "            print(\"중요 표시된 메일을 선택\")\n",
    "            return \"FLAGGED\"\n",
    "        elif search_condition == '9':\n",
    "            data = input(\"날짜를 입력하세요 (예: 2022-01-31): \")\n",
    "            formatted_date = convert_date(data)\n",
    "            if \"오류\" in formatted_date:\n",
    "                print(formatted_date)\n",
    "                continue\n",
    "            print(f'\"{formatted_date}\" 이후 받은 메일을 선택')\n",
    "            return f'SINCE \"{formatted_date}\"'\n",
    "        elif search_condition == '10':\n",
    "            data = input(\"날짜를 입력하세요 (예: 2022-01-31): \")\n",
    "            formatted_date = convert_date(data)\n",
    "            if \"오류\" in formatted_date:\n",
    "                print(formatted_date)\n",
    "                continue\n",
    "            print(f'\"{formatted_date}\" 이전 받은 메일을 선택')\n",
    "            return f'BEFORE \"{formatted_date}\"'\n",
    "        elif search_condition == '11':\n",
    "            data = input(\"날짜를 입력하세요 (예: 2022-01-31): \")\n",
    "            formatted_date = convert_date(data)\n",
    "            if \"오류\" in formatted_date:\n",
    "                print(formatted_date)\n",
    "                continue\n",
    "            print(f'\"{formatted_date}\"에 받은 메일을 선택')\n",
    "            return f'ON \"{formatted_date}\"'\n",
    "        elif search_condition == '12':\n",
    "            data = input(\"특정단어를 입력하세요 : \")\n",
    "            print(f'\"{data}\"가 포함된 메일을 선택')\n",
    "            return f'BODY \"{data}\"'\n",
    "        else:\n",
    "            print(\"잘못된 입력입니다. 다시 입력하세요.\")\n",
    "\n",
    "    \n",
    "# 메일 제목 디코딩\n",
    "def safe_decode_header(header_value):\n",
    "    decoded_parts = decode_header(header_value)\n",
    "    decoded_string = \"\"\n",
    "\n",
    "    for part, encoding in decoded_parts:\n",
    "        if isinstance(part, bytes):\n",
    "            try:\n",
    "                if encoding == \"cseuckr\":\n",
    "                    decoded_string += part.decode(\"euc-kr\", errors=\"ignore\")\n",
    "                elif encoding == \"unknown-8bit\":\n",
    "                    decoded_string += part.decode(\"utf-8\", errors=\"ignore\")\n",
    "                else:\n",
    "                    decoded_string += part.decode(encoding if encoding else \"utf-8\")\n",
    "            except (UnicodeDecodeError, TypeError):\n",
    "                print(f\"디코딩 오류: {e}\")\n",
    "                decoded_string += part.decode(\"utf-8\", errors=\"ignore\")\n",
    "        else:\n",
    "            decoded_string += part\n",
    "\n",
    "    return decoded_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Sequential name=sequential, built=True>\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
    "from tensorflow.keras.models import load_model\n",
    "import json\n",
    "\n",
    "# 저장된 Tokenizer를 json 형식으로 불러오기\n",
    "with open('tokenizer.json', 'r') as f:\n",
    "    tokenizer_json = json.load(f)\n",
    "    tokenizer = tokenizer_from_json(tokenizer_json)\n",
    "\n",
    "# 학습된 모델 불러오기\n",
    "model = load_model('best_model_TKRNN.keras', custom_objects={'f1_score': f1_score})\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "이 메일은 중요문서입니다.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "이 메일은 중요문서입니다.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "이 메일은 쓰레기기입니다.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "이 메일은 쓰레기기입니다.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "이 메일은 중요문서입니다.\n",
      "이 메일은 쓰레기기입니다.\n",
      "예측을 종료합니다.\n"
     ]
    }
   ],
   "source": [
    "# 모델 테스트\n",
    "while(True) :\n",
    "    subject = input(\"메일 제목을 입력하세요 (종료하려면 'exit' 입력): \")\n",
    "    \n",
    "    # 'exit'을 입력하면 종료\n",
    "    if subject.lower() == 'exit':\n",
    "        print(\"예측을 종료합니다.\")\n",
    "        break\n",
    "    \n",
    "    # 예측 실행\n",
    "    result = predict_spam(subject)\n",
    "    \n",
    "    # 예측 결과 출력\n",
    "    if result == 1:\n",
    "        print(\"이 메일은 중요문서입니다.\")\n",
    "    else:\n",
    "        print(\"이 메일은 쓰레기기입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로그인 성공!\n",
      "[b'(\\\\HasNoChildren \\\\Inbox) \"/\" \"INBOX\"', b'(\\\\HasNoChildren \\\\Sent) \"/\" \"Sent Messages\"', b'(\\\\HasNoChildren \\\\Drafts) \"/\" \"Drafts\"', b'(\\\\HasNoChildren \\\\Trash) \"/\" \"Deleted Messages\"', b'(\\\\HasNoChildren) \"/\" \"&sLSsjMT0ulTHfNVo-\"', b'(\\\\HasNoChildren) \"/\" \"&zK2tbAC3rLDIHA-\"', b'(\\\\HasNoChildren) \"/\" \"&znTTmA-\"', b'(\\\\HasNoChildren) \"/\" \"SNS\"', b'(\\\\HasNoChildren) \"/\" \"&1QS4XLqowVg-\"']\n"
     ]
    }
   ],
   "source": [
    "# IMAP 서버 및 메일 정보\n",
    "imap_server_input = input(\"사용할 메일서비스명 (gmail, naver): \").strip().lower()\n",
    "\n",
    "if imap_server_input == \"gmail\":\n",
    "    imap_server = \"imap.gmail.com\"\n",
    "    trash_folder = '\"[Gmail]/Trash\"'  # Gmail의 경우 휴지통 경로\n",
    "elif imap_server_input == \"naver\":\n",
    "    imap_server = \"imap.naver.com\"\n",
    "    trash_folder = \"Deleted Messages\"  # 네이버의 경우 휴지통 경로\n",
    "else:\n",
    "    print(\"지원하지 않는 메일 서비스입니다.\")\n",
    "    exit()\n",
    "\n",
    "email_user = input(\"계정 ID: \")\n",
    "email_pass = input(\"password: \")\n",
    "\n",
    "if '@' not in email_user:\n",
    "    if imap_server_input == \"gmail\":\n",
    "        email_user += '@gmail.com'\n",
    "    else :\n",
    "        email_user += '@naver.com'\n",
    "\n",
    "    # 예측 결과 카운트\n",
    "important_count = 0\n",
    "spam_count = 0\n",
    "\n",
    "\n",
    "        # IMAP 서버에 연결\n",
    "mail = imaplib.IMAP4_SSL(imap_server, 993)\n",
    "mail.login(email_user, email_pass)\n",
    "mail.timeout = 30\n",
    "print(\"로그인 성공!\")\n",
    "\n",
    "\n",
    "result, folders = mail.list()\n",
    "print(folders)  # 모든 폴더 목록 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로그인 성공!\n",
      "메일 검색 조건을 선택하세요:\n",
      "1. 모든 메일 (ALL)\n",
      "2. 읽지 않은 메일 (UNSEEN)\n",
      "3. 최근 메일 (RECENT)\n",
      "4. 읽은 메일 (SEEN)\n",
      "5. 답장한 메일 (ANSWERED)\n",
      "6. 삭제된 메일 (DELETED)\n",
      "7. 초안 메일 (DRAFT)\n",
      "8. 중요 표시된 메일 (FLAGGED)\n",
      "9. 특정 날짜 이후 받은 메일 (SINCE)\n",
      "10. 특정 날짜 이전 받은 메일 (BEFORE)\n",
      "11. 특정 날짜에 받은 메일 (ON)\n",
      "12. 본문에 특정단어가가 포함된 메일 (BODY)\n",
      "\"01-Jan-2025\" 이후 받은 메일을 선택\n",
      "1/3 번째 메일 처리 중...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "2/3 번째 메일 처리 중...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "메일 2번을 휴지통으로 이동시킴.\n",
      "3/3 번째 메일 처리 중...\n",
      "중요 메일 1개 확인됨.\n",
      "스팸 메일 1개 이동됨.\n"
     ]
    }
   ],
   "source": [
    "from email.header import decode_header\n",
    "import numpy as np\n",
    "import imaplib\n",
    "import email\n",
    "import csv\n",
    "\n",
    "try:\n",
    "    # IMAP 서버 및 메일 정보\n",
    "    imap_server_input = input(\"사용할 메일서비스명 (gmail, naver): \").strip().lower()\n",
    "\n",
    "    if imap_server_input == \"gmail\":\n",
    "        imap_server = \"imap.gmail.com\"\n",
    "        trash_folder = '\"[Gmail]/Trash\"'  # Gmail의 경우 휴지통 경로\n",
    "    elif imap_server_input == \"naver\":\n",
    "        imap_server = \"imap.naver.com\"\n",
    "        trash_folder = \"Trash\"  # 네이버의 경우 휴지통 경로\n",
    "    else:\n",
    "        print(\"지원하지 않는 메일 서비스입니다.\")\n",
    "        exit()\n",
    "\n",
    "    email_user = input(\"계정 ID: \")\n",
    "    email_pass = input(\"password: \")\n",
    "\n",
    "    if '@' not in email_user:\n",
    "        if imap_server_input == \"gmail\":\n",
    "            email_user += '@gmail.com'\n",
    "        else :\n",
    "            email_user += '@naver.com'\n",
    "\n",
    "    # 예측 결과 카운트\n",
    "    important_count = 0\n",
    "    spam_count = 0\n",
    "\n",
    "    try:\n",
    "        # IMAP 서버에 연결\n",
    "        mail = imaplib.IMAP4_SSL(imap_server, 993)\n",
    "        mail.login(email_user, email_pass)\n",
    "        mail.timeout = 30\n",
    "        print(\"로그인 성공!\")\n",
    "\n",
    "        # IMAP 서버에서 메일 제목 가져오기\n",
    "        if input(\"ㄱㄱ?: \") == 'ㄱㄱ':\n",
    "            \n",
    "            # 받은 편지함 선택\n",
    "            mail.select(\"inbox\")\n",
    "\n",
    "            # 조건에 맞는 메일 검색\n",
    "            search_condition = select_search_condition()\n",
    "            try:\n",
    "                messages = search_with_retry(mail, search_condition)\n",
    "                message_ids = messages[0].split()\n",
    "\n",
    "                # 메일 제목 가져오기\n",
    "                for index, msg_id in enumerate(message_ids, start=1):\n",
    "                    print(f\"{index}/{len(message_ids)} 번째 메일 처리 중...\")\n",
    "\n",
    "                    # 메일 가져오기\n",
    "                    status, msg_data = mail.fetch(msg_id, \"(RFC822)\")\n",
    "                    for response_part in msg_data:\n",
    "                        if isinstance(response_part, tuple):\n",
    "                            msg = email.message_from_bytes(response_part[1])\n",
    "                            \n",
    "                            # 메일 제목 디코딩\n",
    "                            subject = safe_decode_header(msg[\"Subject\"])\n",
    "\n",
    "                            # 예측 실행\n",
    "                            prediction = predict_spam(subject)\n",
    "\n",
    "                            # 메일을 휴지통으로 이동시키기\n",
    "                            if prediction == 0:\n",
    "                                spam_count += 1\n",
    "                                if imap_server_input == \"gmail\":\n",
    "                                    mail.store(msg_id, '+X-GM-LABELS', trash_folder)\n",
    "                                else :\n",
    "                                    mail.store(msg_id, '+FLAGS', '\\\\Deleted')\n",
    "                                print(f\"메일 {index}번을 휴지통으로 이동시킴.\")\n",
    "                            else:\n",
    "                                important_count += 1\n",
    "\n",
    "                print(f\"중요 메일 {important_count}개 확인됨.\")\n",
    "                print(f\"스팸 메일 {spam_count}개 이동됨.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"오류: {e}\")\n",
    "\n",
    "\n",
    "            if input(\"원상복구 ㄱㄱ?: \") == 'ㄱㄱ':\n",
    "                # 휴지통 폴더 선택\n",
    "                mail.select(trash_folder)\n",
    "\n",
    "                try:\n",
    "                    # 휴지통에서 모든 메일 검색\n",
    "                    messages = search_with_retry(mail, \"ALL\")\n",
    "                    message_ids = messages[0].split()\n",
    "\n",
    "\n",
    "                    # 휴지통에 있는 모든 메일 복구\n",
    "                    for msg_id in message_ids:\n",
    "                        # 메일을 받은 편지함으로 복구\n",
    "                        if imap_server_input == \"gmail\":\n",
    "                            mail.store(msg_id, '-X-GM-LABELS', trash_folder)\n",
    "                            mail.store(msg_id, '+X-GM-LABELS', 'INBOX')\n",
    "                        else :\n",
    "                            mail.store(msg_id, '-FLAGS', '\\\\Deleted')\n",
    "                            mail.store(msg_id, '+FLAGS', '\\\\Seen')\n",
    "\n",
    "                        print(f\"메일 {msg_id}을(를) 받은편지함으로 복구했습니다.\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"검색 실패: {e}\")\n",
    "            \n",
    "            # IMAP 서버에서 로그아웃\n",
    "            mail.expunge()\n",
    "            mail.close()\n",
    "            mail.logout()\n",
    "\n",
    "    except imaplib.IMAP4.error as e:\n",
    "        print(f\"IMAP 로그인 실패: {e}\")\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n프로그램이 사용자의 요청으로 종료되었습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
